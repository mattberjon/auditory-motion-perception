% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Abed1978,
  Title                    = {Low-pass digital filtering with the host windowing design technique},
  Author                   = {Abed, A. H. M. AND Cain, G. D.},
  Journal                  = {Radio and Electronic Engineer},
  Year                     = {1978},
  Number                   = {6},
  Pages                    = {293-300},
  Volume                   = {48},

  Doi                      = {10.1049/ree.1978.0042},
  File                     = {Abed1978.pdf:Abed1978.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.04}
}

@Article{Abed1984,
  Title                    = {The host windowing technique for FIR digital filter design},
  Author                   = {Abed, A.-E. AND Cain, G.},
  Journal                  = {Acoustics, Speech and Signal Processing},
  Year                     = {1984},
  Number                   = {4},
  Pages                    = {683-694},
  Volume                   = {32},

  Abstract                 = {A detailed description is given of a technique for designing finite duration impulse response digital filters in which one portion of the impulse response sequence is identified as a "host" filter which undergoes multiplication by a simple trigonometric window in order to implement the final "object" filter. This partitioning is found to be useful, both from the viewpoint of insight into error and transition width characteristics, and from the practical implementation aspect when variation of a frequency parameter (cutoff frequency for a low-pass filter or center frequency for a bandpass filter) is desired. Design results for families of variable filters are presented under conditions where the host filter has been preoptimized to give a close approximation to minimax behavior over a whole range of values for the variable frequency parameter-all for the price of a single initial host optimization procedure for the entire family, followed by a computationally easy modification method for any one member of the family. It is seen that useful performance guarantees can be offered to the user across a range of operating conditions, and that the penalty incurred is never more than a doubling of the peak error (and often much less) over that of minimax designs specifically and laboriously computed for each condition of the variable frequency. Therefore, high speed filter coefficient variation is found to be compatible with good quality filtering in a theoretical framework which readily admits extension to non-standard filter types such as arbitrary multiband filters. A glossary of terms is included at the end of the paper.},
  Doi                      = {10.1109/TASSP.1984.1164414},
  File                     = {Abed1984.pdf:Abed1984.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.04}
}

@Article{Adelson1985,
  Title                    = {Spatiotemporal energy models for the perception of motion},
  Author                   = {Adelson, Edward H. AND Bergen, James R.},
  Journal                  = {Journal of the Optical Society of America},
  Year                     = {1985},
  Number                   = {2},
  Pages                    = {284-299},
  Volume                   = {2},

  Doi                      = {10.1364/JOSAA.2.000284},
  File                     = {Adelson1985.pdf:Adelson1985.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.11}
}

@Book{Aggarwal2014,
  Title                    = {Flask framework cookbook},
  Author                   = {Aggarwal, Shalabh},
  Publisher                = {Packt Publishing Ltd.},
  Year                     = {2014},

  File                     = {Aggarwal2014.pdf:Aggarwal2014.pdf:PDF},
  Keywords                 = {dev; flask, python}
}

@Article{Ahissar1992,
  Title                    = {Encoding of sound-source location and movement: activity of single neurons and interactions between adjacent neurons in the monkey auditory-cortex},
  Author                   = {Ahissar, M. AND Ahissar, E. AND Bergman, H. AND Vaadia, E.},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {1992},
  Number                   = {1},
  Pages                    = {203--215},
  Volume                   = {67},

  File                     = {Ahissar1992.pdf:Ahissar1992.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Altman2005,
  Title                    = {The effects of moving sound images on postural responses and the head rotation illusion in humans},
  Author                   = {Al'tman, Ya. A. and Varyagina, O. V. and Gurfinkel', V. S. and Levik, Yu. S.},
  Journal                  = {Neuroscience and Behavioral Physiology},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {103-106},
  Volume                   = {35},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The results of pilot studies on the effects of sound images moving in the horizontal plane on poststimulus responses and the head rotation illusion are presented. These phenomena are demonstrated to occur.},
  Doi                      = {10.1023/B:NEAB.0000049657.63118.74},
  File                     = {Altman2005.pdf:Altman2005.pdf:PDF},
  Keywords                 = {motion; head motion; azimuth; neuroscience; source motion;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Alais2004,
  Title                    = {No direction-specific bimodal facilitation for audiovisual motion detection},
  Author                   = {Alais, D. and Burr, D.},
  Journal                  = {Cognitive Brain Research},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {185-194},
  Volume                   = {19},

  Abstract                 = {After several decades of unimodal perceptual research, interest is turning increasingly to cross-modal interactions. At a physiological level, the existence of bimodal cells is well documented and it is known that correlated audiovisual input enhances localisation and orienting behaviours. Audiovisual perceptual interactions have also been demonstrated (e.g., the well-known McGurk effect). The present study explores motion perception and asks whether correlated audiovisual motion signals would be better detected than unimodal motions or bimodal motions in opposing directions. Using a dynamic random-dot field with variable motion coherence as a visual stimulus, together with an auditory motion defined by a stereo noise source smoothly translating along a horizontal trajectory, we find that correlated bimodal motion yields only a slight improvement (approximately a square root of two advantage) in detection threshold relative to unimodal detection. The size of this benefit is consistent with a statistical advantage rather than a bimodal facilitation account. Moreover, anticorrelated bimodal motion showed the same modest improvement, again speaking against linear summation but consistent with statistical combination of visual and auditory signals. These findings were replicated in peripheral as well as in central vision, and with translating visual objects as well as with spatially distributed visual motion. The superadditivity observed neurally (especially in deep-layer superior collicular cells), when weak unimodal signals are combined in bimodal cells does not apply to the detection of linear translational motion.},
  Doi                      = {10.1016/j.cogbrainres.2003.11.011},
  File                     = {Alais2004.pdf:Alais2004.pdf:PDF},
  Keywords                 = {audiovisual; neuroscience; motion; source motion; azimuth;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.27}
}

@Article{Alais2004a,
  Title                    = {The ventriloquist effect results from near-optimal bimodal integration},
  Author                   = {Alais, D. and Burr, D.},
  Journal                  = {Current Biology},
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {257-262},
  Volume                   = {14},

  Abstract                 = {Ventriloquism is the ancient art of making one's voice appear to come from elsewhere, an art exploited by the Greek and Roman oracles, and possibly earlier [1]. We regularly experience the effect when watching television and movies, where the voices seem to emanate from the actors' lips rather than from the actual sound source. Originally, ventriloquism was explained by performers projecting sound to their puppets by special techniques [1], but more recently it is assumed that ventriloquism results from vision "capturing" sound [2-5]. In this study we investigate spatial localization of audio-visual stimuli. When visual localization is good, vision does indeed dominate and capture sound. However, for severely blurred visual stimuli (that are poorly localized), the reverse holds: sound captures vision. For less blurred stimuli, neither sense dominates and perception follows the mean position. Precision of bimodal localization is usually better than either the visual or the auditory unimodal presentation. All the results are well explained not by one sense capturing the other, but by a simple model of optimal combination of visual and auditory information.},
  Doi                      = {10.1016/j.cub.2004.01.029},
  File                     = {Alais2004a.pdf:Alais2004a.pdf:PDF},
  Keywords                 = {audiovisual; source motion; azimuth; perception; localisation;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.27}
}

@Article{Alais2010,
  Title                    = {Multisensory Perceptual Learning of Temporal Order: Audiovisual Learning Transfers to Vision but Not Audition},
  Author                   = {Alais, David and Cass, John},
  Journal                  = {Plos One},
  Year                     = {2010},
  Number                   = {6},
  Pages                    = {1-9},
  Volume                   = {5},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Background

An outstanding question in sensory neuroscience is whether the perceived timing of events is mediated by a central supra-modal timing mechanism, or multiple modality-specific systems. We use a perceptual learning paradigm to address this question.

Methodology/Principal Findings

Three groups were trained daily for 10 sessions on an auditory, a visual or a combined audiovisual temporal order judgment (TOJ). Groups were pre-tested on a range TOJ tasks within and between their group modality prior to learning so that transfer of any learning from the trained task could be measured by post-testing other tasks. Robust TOJ learning (reduced temporal order discrimination thresholds) occurred for all groups, although auditory learning (dichotic 500/2000 Hz tones) was slightly weaker than visual learning (lateralised grating patches). Crossmodal TOJs also displayed robust learning. Post-testing revealed that improvements in temporal resolution acquired during visual learning transferred within modality to other retinotopic locations and orientations, but not to auditory or crossmodal tasks. Auditory learning did not transfer to visual or crossmodal tasks, and neither did it transfer within audition to another frequency pair. In an interesting asymmetry, crossmodal learning transferred to all visual tasks but not to auditory tasks. Finally, in all conditions, learning to make TOJs for stimulus onsets did not transfer at all to discriminating temporal offsets. These data present a complex picture of timing processes.

Conclusions/Significance

The lack of transfer between unimodal groups indicates no central supramodal timing process for this task; however, the audiovisual-to-visual transfer cannot be explained without some form of sensory interaction. We propose that auditory learning occurred in frequency-tuned processes in the periphery, precluding interactions with more central visual and audiovisual timing processes. Functionally the patterns of featural transfer suggest that perceptual learning of temporal order may be optimised to object-centered rather than viewer-centered constraints.},
  Doi                      = {10.1371/journal.pone.0011283},
  File                     = {Alais2010.pdf:Alais2010.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.27}
}

@Article{Alink2012,
  Title                    = {Auditory motion direction encoding in auditory cortex and high-level visual cortex},
  Author                   = {Alink, Arjen and Euler, Felix and Kriegeskorte, Nikolaus and Singer, Wolf and Kohler, Axel},
  Journal                  = {Human Brain Mapping},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {969–978},
  Volume                   = {33},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The aim of this functional magnetic resonance imaging (fMRI) study was to identify human brain areas that are sensitive to the direction of auditory motion. Such directional sensitivity was assessed in a hypothesis-free manner by analyzing fMRI response patterns across the entire brain volume using a spherical-searchlight approach. In addition, we assessed directional sensitivity in three predefined brain areas that have been associated with auditory motion perception in previous neuroimaging studies. These were the primary auditory cortex, the planum temporale and the visual motion complex (hMT/V5+). Our whole-brain analysis revealed that the direction of sound-source movement could be decoded from fMRI response patterns in the right auditory cortex and in a high-level visual area located in the right lateral occipital cortex. Our region-of-interest-based analysis showed that the decoding of the direction of auditory motion was most reliable with activation patterns of the left and right planum temporale. Auditory motion direction could not be decoded from activation patterns in hMT/V5+. These findings provide further evidence for the planum temporale playing a central role in supporting auditory motion perception. In addition, our findings suggest a cross-modal transfer of directional information to high-level visual cortex in healthy humans},
  Doi                      = {10.1002/hbm.21263},
  File                     = {Alink2012.pdf:Alink2012.pdf:PDF},
  Keywords                 = {neuroscience; motion; audio; source motion; azimuth;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.16}
}

@Article{Altman1968,
  Title                    = {Are there neurons detecting direction of sound source motion?},
  Author                   = {Altman, Jacob A.},
  Journal                  = {Experimental Neurology},
  Year                     = {1968},
  Number                   = {1},
  Pages                    = {13–25},
  Volume                   = {22},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The activity of inferior colliculus single neurons was recorded extracellularly in cats anesthetized with chloralose and urethane. Binaurally presented trains of clicks were used as a sound signal, the time interval within each pair of clicks being diminished and then raised gradually. The use of the signal, which has some special features of a moving sound, models motion of the sound from one ear to the midline and backwards. It was possible to isolate units, which can fix some special features of this signal and respond to the direction of sound “motion” with a specific response. Different types of responses of these neurons are presented.},
  Doi                      = {10.1016/0014-4886(68)90016-2},
  File                     = {Altman1968.pdf:Altman1968.pdf:PDF},
  Keywords                 = {neuroscience; source motion; motion; audio; azimuth;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.30}
}

@Article{Altman1988,
  Title                    = {Psychophysical characteristics of the auditory image movement perception during dichotic stimulation},
  Author                   = {Altman, J. A. AND Romanov, V. P.},
  Journal                  = {International journal of Neuroscience},
  Year                     = {1988},
  Number                   = {3-4},
  Pages                    = {369-379},
  Volume                   = {38},

  Doi                      = {10.1007/978-1-4684-3908-3_32},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Altman1970,
  Title                    = {Neuronal activity in the medial geniculate body of the cat during monaural and binaural stimulation},
  Author                   = {Altman, Jacob A. AND Syka, J. AND Shmigidina, G. N.},
  Journal                  = {Experimental Brain Research},
  Year                     = {1970},
  Number                   = {1},
  Pages                    = {81-93},
  Volume                   = {10},

  Doi                      = {10.1007/BF00340520},
  File                     = {Altman1970.pdf:Altman1970.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.11}
}

@Article{Arena2012,
  Title                    = {The effects of age on the spatial and temporal integration of global motion},
  Author                   = {Arena, A. and Hutchinson, C.V. and Shimozaki, S.S.},
  Journal                  = {Vision Res.},
  Year                     = {2012},
  Pages                    = {27–32},
  Volume                   = {58},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The purpose of this study was to determine the relative contributions of local element speed and/or spatial displacement to age-related deficits in global motion processing. Motion coherence thresholds (79 percent correct) were measured for discriminating the direction of translational random dot kinematograms (RDKs) as a function of dot speed and spatial displacement across the adult lifespan (20-79 years). Age-related impairments in global motion processing were only apparent in observers 70–79 years of age. In agreement with previous studies, we found an age-related impairment at low (0.625 deg/s) and high speeds (10 deg/s). However, these effects were heavily mediated by dot spatial displacement. Motion coherence thresholds were also most markedly elevated in women aged over 70 years. These findings suggest a prominent role of spatial integration in global motion processing. Moreover, global motion perception appears to be relatively well preserved until around 70 years of age.},
  Doi                      = {10.1016/j.visres.2012.02.004},
  File                     = {Arena2012.pdf:Arena2012.pdf:PDF},
  Keywords                 = {vision; perception; source motion; azimuth; motion;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.16}
}

@Article{Ascher2000,
  Title                    = {A bayesian model for the measurement of visual velocity},
  Author                   = {Ascher, David AND Grzywacz, Norberto M.},
  Journal                  = {Vision Res.},
  Year                     = {2000},
  Number                   = {34},
  Pages                    = {3427-3434},
  Volume                   = {40},

  Doi                      = {10.1016/S0042-6989(00)00176-0},
  File                     = {Ascher2000.pdf:Ascher2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.02}
}

@Article{Ashmead1995,
  Title                    = {Contribution of Listeners' Approaching Motion to Auditory Distance Perception},
  Author                   = {Ashmead, Daniel H. AND Davis, DeFord L. AND Northington, Anna},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1995},
  Number                   = {2},
  Pages                    = {239–256},
  Volume                   = {21},

  Doi                      = {10.1037/0096-1523.21.2.239},
  File                     = {Ashmead1995.pdf:Ashmead1995.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.22}
}

@Article{Ashmead2012,
  Title                    = {Auditory Perception of Motor Vehicle Travel Paths},
  Author                   = {Ashmead, Daniel H. and Grantham, D. Wesley and Maloff, Erin S. and Hornsby, Benjamin and Nakamura, Takabun and Davis, Timothy J. and Pampel, Faith and Rushing, Erin G.},
  Journal                  = {Human Factors},
  Year                     = {2012},
  Number                   = {3},
  Pages                    = {437-453},
  Volume                   = {54},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Objective: These experiments address concerns that motor vehicles in electric engine mode are so quiet that they pose a risk to pedestrians, especially those with visual impairments.

Background: The "quiet car" issue has focused on hybrid and electric vehicles, although it also applies to internal combustion engine vehicles. Previous research has focused on detectability of vehicles, mostly in quiet settings. Instead, we focused on the functional ability to perceive vehicle motion paths.

Method: Participants judged whether simulated vehicles were traveling straight or turning, with emphasis on the impact of background traffic sound.

Results: In quiet, listeners made the straight-or-turn judgment soon enough in the vehicle's path to be useful for deciding whether to start crossing the street. This judgment is based largely on sound level cues rather than the spatial direction of the vehicle. With even moderate background traffic sound, the ability to tell straight from turn paths is severely compromised. The signal-to-noise ratio needed for the straight-or-turn judgment is much higher than that needed to detect a vehicle.

Conclusion: Although a requirement for a minimum vehicle sound level might enhance detection of vehicles in quiet settings, it is unlikely that this requirement would contribute to pedestrian awareness of vehicle movements in typical traffic settings with many vehicles present.

Application: The findings are relevant to deliberations by government agencies and automobile manufacturers about standards for minimum automobile sounds and, more generally, for solutions to pedestrians' needs for information about traffic, especially for pedestrians with sensory impairments.},
  Doi                      = {10.1177/0018720811436083},
  File                     = {Ashmead2012.pdf:Ashmead2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.27}
}

@Article{Aubert1886,
  Title                    = {Die Bewegungsempfindung},
  Author                   = {Aubert, Hermann},
  Journal                  = {Archiv für die gesamte Physiologie des Menschen und der Tiere},
  Year                     = {1886},
  Number                   = {1},
  Pages                    = {347-370},
  Volume                   = {39},

  Doi                      = {10.1007/BF01612166},
  File                     = {Aubert1886.pdf:Aubert1886.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.19}
}

@Article{Bandini2015,
  Title                    = {Markerless Analysis of Articulatory Movements in Patients With Parkinson's Disease},
  Author                   = {Bandini, Andrea AND Orlandi, Silvia AND Giovannelli, Fabio AND Felici, Andrea AND Cincotta, Massimo AND Clemente, Daniela AND Vanni,Paola AND Zaccara, Gaetano AND Manfredi, Claudia},
  Journal                  = {Journal of Voice},
  Year                     = {2015},

  __markedentry            = {[mattberjon:1]},
  Doi                      = {10.1016/j.jvoice.2015.10.014},
  File                     = {Bandini2015.pdf:Bandini2015.pdf:PDF}
}

@Article{Barlow1963,
  Title                    = {Selective sensitivity to direction of motion in ganglion cells in the rabbits retina},
  Author                   = {Barlow, H. B. and Hill, R. M.},
  Journal                  = {Science},
  Year                     = {1963},
  Number                   = {3553},
  Pages                    = {412-414},
  Volume                   = {139},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Among the ganglion cells in the rabbit's retina there is a class that responds to movement of a stimulus in one direction, and does not respond to movement in the opposite direction. The same directional selectivity holds over the whole receptive field of one such cell, but the selected direction differs in different cells. The discharge is almost uninfluenced by the intensity of the stimulus spot, and the response occurs for the same direction of movement when a black spot is substituted for a light spot.},
  Doi                      = {10.1126/science.139.3553.412},
  File                     = {Barlow1963.pdf:Barlow1963.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.05}
}

@Article{Barlow1965,
  Title                    = {The mechanism of directionally selective units in rabbit's retina},
  Author                   = {Barlow, H. B. and Lewick, W. R.},
  Journal                  = {The journal of Physiology},
  Year                     = {1965},
  Pages                    = {477-504},
  Volume                   = {178},

  __markedentry            = {[mattberjon:]},
  File                     = {Barlow1965.pdf:Barlow1965.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.05}
}

@Article{Barnett-Cowan2009,
  Title                    = {Perceived timing of vestibular stimulation relative to touch, light and sound},
  Author                   = {Barnett-Cowan, Michael AND Harris, Laurence R.},
  Journal                  = {Experimental Brain Research},
  Year                     = {2009},
  Number                   = {2-3},
  Pages                    = {221-231},
  Volume                   = {198},

  Doi                      = {10.1007/s00221-009-1779-4},
  File                     = {Barnett-Cowan2009.pdf:Barnett-Cowan2009.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.12}
}

@Article{Barnett-Cowan2012,
  Title                    = {Persistent perceptual delay for head movement onset relative to auditory stimuli of different durations and rise times},
  Author                   = {Barnett-Cowan, Michael and Raeder, Sophie M. and Bülthoff, Heinrich H.},
  Journal                  = {Experimental Brain Research},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {41-50},
  Volume                   = {220},

  Abstract                 = {The perception of simultaneity between auditory and vestibular information is crucially important for maintaining a coherent representation of the acoustic environment whenever the head moves. It has been recently reported, however, that despite having similar transduction latencies, vestibular stimuli are perceived significantly later than auditory stimuli when simultaneously generated. This suggests that perceptual latency of a head movement is longer than a co-occurring sound. However, these studies paired a vestibular stimulation of long duration (~1 s) and of a continuously changing temporal envelope with a brief (10–50 ms) sound pulse. In the present study, the stimuli were matched for temporal envelope duration and shape. Participants judged the temporal order of the two stimuli, the onset of an active head movement and the onset of brief (50 ms) or long (1,400 ms) sounds with a square- or raised-cosine-shaped envelope. Consistent with previous reports, head movement onset had to precede the onset of a brief sound by about 73 ms in order for the stimuli to be perceived as simultaneous. Head movements paired with long square sounds (~100 ms) were not significantly different than brief sounds. Surprisingly, head movements paired with long raised-cosine sound (~115 ms) had to be presented even earlier than brief stimuli. This additional lead time could not be accounted for by differences in the comparison stimulus characteristics (temporal envelope duration and shape). Rather, differences between sound conditions were found to be attributable to variability in the time for head movement to reach peak velocity: the head moved faster when paired with a brief sound. The persistent lead time required for vestibular stimulation provides further evidence that the perceptual latency of vestibular stimulation is greater than the other senses.},
  Doi                      = {10.1007/s00221-012-3112-x},
  File                     = {Barnett-Cowan2012.pdf:Barnett-Cowan2012.pdf:PDF},
  Keywords                 = {audio; head motion; azimuth; perception; motion},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.26}
}

@Proceedings{Batteau1967,
  Title                    = {The role of the pinna in human localization},
  Year                     = {1967},
  Publisher                = {The Royal Society of London},
  Series                   = {B, Biological Sciences},
  Volume                   = {168},

  Author                   = {Batteau, Dwight W.},
  Doi                      = {10.1098/rspb.1967.0058},
  File                     = {Batteau1967.pdf:Batteau1967.pdf:PDF},
  Journal                  = {Proceedings of the Royal Society of London},
  Owner                    = {mattberjon},
  Pages                    = {158-180},
  Part                     = {Series B, Biological Sciences},
  Quality                  = {1},
  Timestamp                = {2013.04.19}
}

@Article{Baumgart1999,
  Title                    = {A movement-sensitive area in auditory cortex},
  Author                   = {Baumgart, F AND Gaschler-Markefski, B. AND Woldorff, M. G AND Heinze, H. J AND Scheich, H},
  Journal                  = {Nature},
  Year                     = {1999},
  Number                   = {6746},
  Pages                    = {724-726},
  Volume                   = {400},

  Doi                      = {10.1038/23390},
  File                     = {Baumgart1999.pdf:Baumgart1999.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Conference{Bech1994,
  Title                    = {Perception of Reproduced Sound: Audibility of Individual Reflections in a Complete Sound Field},
  Author                   = {Bech, Søren},
  Booktitle                = {Audio Engineering Society Convention 96},
  Year                     = {1994},
  Month                    = {2},
  Publisher                = {Audio Engineering Society},

  File                     = {Bech1994.pdf:Bech1994.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.12}
}

@Book{Begault2000,
  Title                    = {3-D sound for virtual reality and multimedia},
  Author                   = {Begault, Durand R},
  Publisher                = {Moffett Field, Calif. : National Aeronautics and Space Administration, Ames Research Center.},
  Year                     = {2000},

  Abstract                 = {This paper gives HRTF magnitude data in numerical form for 43 frequencies between 0.2---12 kHz, the average of 12 studies representing 100 different subjects. However, no phase data is included in the tables; group delay simulation would need to be included in order to account for ITD. In 3-D sound applications intended for many users, we want might want to use HRTFs that represent the common features of a number of individuals. But another approach might be to use the features of a person who has desirable HRTFs, based on some criteria. (One can sense a future 3-D sound system where the pinnae of various famous musicians are simulated.) A set of HRTFs from a good localizer (discussed in Chapter 2) could be used if the criterion were localization performance. If the localization ability of the person is relatively accurate or more accurate than average, it might be reasonable to use these HRTF measurements for other individuals. The Convolvotron 3-D audio system (Wenzel, Wightman, and Foster, 1988) has used such sets particularly because elevation accuracy is affected negatively when listening through a bad localizers ears (see Wenzel, et al., 1988). It is best when any single nonindividualized HRTF set is psychoacoustically validated using a 113 statistical sample of the intended user population, as shown in Chapter 2. Otherwise, the use of one HRTF set over another is a purely subjective judgment based on criteria other than localization performance. The technique used by Wightman and Kistler (1989a) exemplifies a laboratory-based HRTF measurement procedure where accuracy and replicability of results were deemed crucial. A comparison of their techniques with those described in Blauert (1983), Shaw (1974), Mehrgardt and Mellert (1977), Middlebrooks, Makous, and Gree...},
  Doi                      = {10.1.1.20.8443},
  File                     = {Begault2000.pdf:Begault2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.07.21}
}

@Article{Bekesy1938,
  Title                    = {Über die Entstehung der Entfernungsempfindung beim Hören},
  Author                   = {Békésy, G. von},
  Journal                  = {Akustiche Zeitschrift},
  Year                     = {1938},
  Note                     = {Available in English in Békésy, G. v. (1960). Experiments in hearing (E. G. Wever, Ed.) (pp. 301-313). New York: McGraw-Hill.},
  Pages                    = {21-31},
  Volume                   = {3},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.25}
}

@Article{Bizley2010,
  Title                    = {Sensitivity and selectivity of neurons in auditory cortex to the pitch, timbre and location of sounds},
  Author                   = {Bizley, J. K. AND Walker, K. M. M.},
  Journal                  = {Neuriscientist},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {453-469},
  Volume                   = {16},

  Doi                      = {10.1177/1073858410371009},
  File                     = {Bizley2010.pdf:Bizley2010.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Book{Blake2006,
  Title                    = {Perception},
  Author                   = {Blake, R. AND Sekuler, R.},
  Publisher                = {McGraw-Hill},
  Year                     = {2006},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.13}
}

@Book{Blauert1983,
  Title                    = {Spatial Hearing: the psychophysics of human sound localization},
  Author                   = {Blauert, Jens},
  Editor                   = {MIT Press},
  Publisher                = {MIT Press},
  Year                     = {1983},
  Edition                  = {Second (Revised in 1997)},
  Month                    = {november},

  Abstract                 = {The field of spatial hearing has exploded in the decade or so since Jens Blauert's classic work on acoustics was first published in English. This revised edition adds a new chapter that describes developments in such areas as auditory virtual reality (an important field of application that is based mainly on the physics of spatial hearing), binaural technology (modeling speech enhancement by binaural hearing), and spatial sound-field mapping. The chapter also includes recent research on the precedence effect that provides clear experimental evidence that cognition plays a significant role in spatial hearing.

The remaining four chapters in this comprehensive reference cover auditory research procedures and psychometric methods, spatial hearing with one sound source, spatial hearing with multiple sound sources and in enclosed spaces, and progress and trends from 1972 (the first German edition) to 1983 (the first English edition)—work that includes research on the physics of the external ear, and the application of signal processing theory to modeling the spatial hearing process. There is an extensive bibliography of more than 900 items.},
  Keywords                 = {audio; localisation; azimut; elevation; perception; review},
  Owner                    = {mattberjon},
  Pages                    = {508},
  Timestamp                = {2011.11.24},
  Url                      = {http://books.google.co.uk/books?id=wBiEKPhw7r0C&lpg=PR1&pg=PR1#v=onepage&q&f=false}
}

@Article{Blauert1972,
  Title                    = {Lag of lateralization caused by interaural time and intensity differences},
  Author                   = {Blauert, J.},
  Journal                  = {Audiology},
  Year                     = {1972},
  Number                   = {5-6},
  Pages                    = {265-270},
  Volume                   = {11},

  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Boucher2004,
  Title                    = {Ocular tracking as a measure of auditory motion perception},
  Author                   = {Boucher, Leanne AND Lee, Anna AND Cohen, Yale E. AND Hughes, Howard C.},
  Journal                  = {Journal of Physiology - Paris},
  Year                     = {2004},
  Number                   = {1-3},
  Pages                    = {235-248},
  Volume                   = {98},

  Doi                      = {10.1016/j.jphysparis.2004.03.010},
  File                     = {Boucher2004.pdf:Boucher2004.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27}
}

@InProceedings{Boymans2006,
  Title                    = {Evidence for Benefits of Bilateral Hearing Aids},
  Author                   = {Boymans, Monique AND Dresher, Wouter A.},
  Booktitle                = {Hearing care for adults},
  Year                     = {2006},
  Editor                   = {Phonak},
  Pages                    = {287-298},

  File                     = {Boymans2006.pdf:Boymans2006.pdf:PDF}
}

@Conference{Bradter2005,
  Title                    = {Head movements: an approach to their significance for localization tasks},
  Author                   = {Bradter, Cornelius and Hobhm, Klaus},
  Booktitle                = {Audio Engineering Society Convention 118},
  Year                     = {2005},

  Abstract                 = {We asked 25 test persons to locate real and virtual sound sources within a 360 degree environment. During the tasks head movements were recorded by an head tracker with a time resolution of 20ms. We categorized the success of locating the sound sources and related the outcome to criteria deduced from the head movement data. Contrary to the assumption that stronger head movements support localisation ability, we could not establish a simple relationship between head movements and good localisation.},
  File                     = {Bradter2005.pdf:Bradter2005.pdf:PDF},
  Journal                  = {Audio Engineering Society},
  Keywords                 = {head motion; audio; localisation; perception; azimuth;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.21}
}

@Book{Bregman1990,
  Title                    = {Auditory scene analysis: the perceptual organization of sound},
  Author                   = {Bregman, Albert S.},
  Editor                   = {Cambridge, MA},
  Publisher                = {MIT Press},
  Year                     = {1990},

  File                     = {Bregman1990.pdf:Bregman1990.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27},
  Url                      = {https://mitpress.mit.edu/books/auditory-scene-analysis}
}

@Article{Bregman2005,
  Title                    = {Auditory scene analysis and the role of phenomenology in experimental psychology},
  Author                   = {Bregman, Albert S.},
  Journal                  = {Canadian Psychology},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {32-40},
  Volume                   = {46},

  Doi                      = {10.1037/h0085822},
  File                     = {Bregman2005.pdf:Bregman2005.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27}
}

@Article{Brenner2001,
  Title                    = {Smooth eye movements and spatial localisation},
  Author                   = {Brenner, Eli and JSmeets, eroen B. J. and Van Den Berg, A. V.},
  Journal                  = {Vision Res.},
  Year                     = {2001},
  Number                   = {17},
  Pages                    = {2253-2259},
  Volume                   = {41},

  Doi                      = {10.1016/S0042-6989(01)00018-9},
  File                     = {Brenner2001.pdf:Brenner2001.pdf:PDF},
  Keywords                 = {vision; localisation; eyes movement; azimuth; perception;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.08}
}

@Article{Bronkhorst1999,
  Title                    = {Auditory distance perception in rooms},
  Author                   = {Bronkhorst, Adelbert W. AND Houtgast, Tammo},
  Journal                  = {Nature},
  Year                     = {1999},
  Pages                    = {517-520},
  Volume                   = {397},

  Doi                      = {10.1038/17374},
  File                     = {Bronkhorst1999.pdf:Bronkhorst1999.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.22}
}

@Article{Brooks2007,
  Title                    = {Auditory motion affects visual biological motion processing},
  Author                   = {Brooks, A. and van der Zwan, R. and Billard, A. and Clarke, S. and Blanke, O.},
  Journal                  = {Neuropsychologia},
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {523-530},
  Volume                   = {3},

  Abstract                 = {The processing of biological motion is a critical, everyday task performed with remarkable efficiency by human sensory systems. Interest in this ability has focused to a large extent on biological motion processing in the visual modality (see, for example, Cutting, J. E., Moore, C., & Morrison, R. (1988). Masking the motions of human gait. Perception and Psychophysics, 44(4), 339-347). In naturalistic settings, however, it is often the case that biological motion is defined by input to more than one sensory modality. For this reason, here in a series of experiments we investigate behavioural correlates of multisensory, in particular audiovisual, integration in the processing of biological motion cues. More specifically, using a new psychophysical paradigm we investigate the effect of suprathreshold auditory motion on perceptions of visually defined biological motion. Unlike data from previous studies investigating audiovisual integration in linear motion processing [Meyer, G. F. & Wuerger, S. M. (2001). Cross-modal integration of auditory and visual motion signals. Neuroreport, 12(11), 2557-2560; Wuerger, S. M., Hofbauer, M., & Meyer, G. F. (2003). The integration of auditory and motion signals at threshold. Perception and Psychophysics, 65(8), 1188-1196; Alais, D. & Burr, D. (2004). No direction-specific bimodal facilitation for audiovisual motion detection. Cognitive Brain Research, 19, 185-194], we report the existence of direction-selective effects: relative to control (stationary) auditory conditions, auditory motion in the same direction as the visually defined biological motion target increased its detectability, whereas auditory motion in the opposite direction had the inverse effect. Our data suggest these effects do not arise through general shifts in visuo-spatial attention, but instead are a consequence of motion-sensitive, direction-tuned integration mechanisms that are, if not unique to biological visual motion, at least not common to all types of visual motion. Based on these data and evidence from neurophysiological and neuroimaging studies we discuss the neural mechanisms likely to underlie this effect.},
  Doi                      = {10.1016/j.neuropsychologia.2005.12.012},
  File                     = {Brooks2007.pdf:Brooks2007.pdf:PDF},
  Keywords                 = {neuroscience; source motion; audiovisual; azimuth; motion;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@Article{Burger1958,
  Title                    = {Front-back discrimination of the hearing system},
  Author                   = {Burger, J.F.},
  Journal                  = {Acustica},
  Year                     = {1958},
  Pages                    = {301-302},
  Volume                   = {8},

  __markedentry            = {[mattberjon:]},
  File                     = {Burger1958.pdf:Burger1958.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.25}
}

@Article{Burr2011,
  Title                    = {Motion psychophysics},
  Author                   = {Burr, D. AND Thompson, Peter},
  Journal                  = {Vision Res.},
  Year                     = {2011},
  Number                   = {13},
  Pages                    = {1431-1456},
  Volume                   = {51},

  Doi                      = {10.1016/j.visres.2011.01.008},
  File                     = {Burr2011.pdf:Burr2011.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@PhdThesis{Busson2006,
  Title                    = {Individualisation d'indices acoustiques pour la synthèse binaurale},
  Author                   = {Busson, Sylvain},
  School                   = {Université de la Méditerranée - Aix-Marseille II},
  Year                     = {2006},

  Abstract                 = {La synthèse binaurale est la technique de spatialisation sonore la plus proche de
l'écoute naturelle. Elle permet un rendu spatialisé d'une source monophonique à une po-
sition donnée avec seulement deux filtres qui correspondent aux oreilles gauche et droite :
les HRTF (Head Related Transfer Function). L'inconvénient majeur de la technique bi-
naurale repose sur le fait que les HRTF, liées à la morphologie de l'auditeur, sont propres
à chaque utilisateur. Une écoute avec des HRTF non-individuelles comporte des artefacts
audibles. Il faut donc acquérir des HRTF individuelles. Cette thèse aborde le problème
de l'individualisation de la synthèse binaurale dans le cadre de son implémentation en un
retard pur, la différence interaurale de temps (ITD), et un filtre à phase minimale déter-
miné par le module de la HRTF. Le travail sur l'ITD permet de valider l'implémentation
choisie même pour les positions où les HRTF sont mal décrites par des filtres à phase
minimale et permet de déterminer, parmi les méthodes classiques de calcul de l'ITD,
celles qui estiment une ITD proche de la perception. Une étude expérimentale est aussi
menée pour établir la résolution de l'ITD avec l'angle d'élévation. Les résultats indiquent
la nécessité perceptive de reproduire les variations de l'ITD en élévation. Une nouvelle
formule d'estimation de l'ITD créée sur la base d'un modèle de tête sphérique, la formule
de déplacement des oreilles (FDO), est développée pour rendre compte de ces variations.
L'optimisation des paramètres de cette formule aux ITD de toute une base de données
de HRTF permet d'entrevoir une formulation moyenne convenant pour un grand nombre
de personne et pour de nombreuses applications. L'étude s'est ensuite focalisée sur la
modélisation du module spectral (filtre à phase minimale). Le travail réalisé sur l'appli-
cation des méthodes de calcul par éléments de frontière (BEM pour Boundary Element
Method) pour l'acquisition de HRTF, indique que cette méthode, peut notamment être
utilisée en complément des mesures pour l'acquisition de la partie basse fréquence des
HRTF. Une approche originale, qui applique des techniques d'apprentissage statistique,
est proposée et étudiée pour la modélisation de HRTF. Un réseau de neurones artificiels
(RNA) est entra^³né pour calculer des HRTF d'un individu à partir de la connaissance
des HRTF mesurées en un nombre réduit de positions. Les premiers résultats sont en-
courageants : le modèle permet d'atteindre un degré assez fin d'individualisation, ce qui
suggère un protocole simplifié d'acquisition de HRTF. Un faible nombre de mesures est
acquis et les autres sont prédites par le modèle.},
  File                     = {Busson2006.pdf:Busson2006.pdf:PDF},
  Keywords                 = {localisation; motion; signal processing; audio; perception; phd},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.30}
}

@Article{Byrne2001,
  Title                    = {NAL-NL1 Procedure for Fitting Nonlinear Hearing Aids: Characteristics and Comparisons with Other Procedure},
  Author                   = {Byrne, Denis AND Dillon, Harvey AND Ching, Teresa AND Katsch, Richard AND Keidser, Gitte},
  Journal                  = {Journal of the American Academy of Audiolo},
  Year                     = {2001},

  Month                    = {January},
  Number                   = {1},
  Pages                    = {37-51},
  Volume                   = {12},

  File                     = {Byrne2001.pdf:Byrne2001.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Campbell1981,
  Title                    = {The influence of spatial frequency and contrast on the perception of moving patterns},
  Author                   = {Campbell, F. W. aand Mafei, L.},
  Journal                  = {Vision Res.},
  Year                     = {1981},
  Number                   = {5},
  Pages                    = {713-721},
  Volume                   = {21},

  Doi                      = {10.1016/0042-6989(81)90080-8},
  File                     = {Campbell1981.pdf:Campbell1981.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.15}
}

@Book{Carlile1996,
  Title                    = {Virtual auditory space: generation and applications},
  Author                   = {Simon Carlile},
  Editor                   = {Simon Carlile},
  Publisher                = {R.G. Landes},
  Year                     = {1996},

  File                     = {Carlile1996.pdf:Carlile1996.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.04.14}
}

@Article{Carlile2002,
  Title                    = {Discrimination of sound velocity in human listeners},
  Author                   = {Carlile, S. and Best, C.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {1026-1035},
  Volume                   = {111},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The ability of six human subjects to discriminate the velocity of moving sound sources was examined using broadband stimuli presented in virtual auditory space. Subjects were presented with two successive stimuli moving in the frontal horizontal plane level with the ears, and were required to judge which moved the fastest. Discrimination thresholds were calculated for reference velocities of 15, 30, and 60 degrees/s under three stimulus conditions. In one condition, stimuli were centered on 0° azimuth and their duration varied randomly to prevent subjects from using displacement as an indicator of velocity. Performance varied between subjects giving median thresholds of 5.5, 9.1, and 14.8 degrees/s for the three reference velocities, respectively. In a second condition, pairs of stimuli were presented for a constant duration and subjects would have been able to use displacement to assist their judgment as faster stimuli traveled further. It was found that thresholds decreased significantly for all velocities (3.8, 7.1, and 9.8 degrees/s), suggesting that the subjects were using the additional displacement cue. The third condition differed from the second in that the stimuli were “anchored” on the same starting location rather than centered on the midline, thus doubling the spatial offset between stimulus endpoints. Subjects showed the lowest thresholds in this condition (2.9, 4.0, and 7.0 degrees/s). The results suggested that the auditory system is sensitive to velocity per se, but velocity comparisons are greatly aided if displacement cues are present.},
  Doi                      = {10.1121/1.1436067},
  File                     = {Carlile2002.pdf:Carlile2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.12}
}

@Article{Cavanagh1984,
  Title                    = {Perceived velocity of moving chromatic gratings},
  Author                   = {Cavanagh, P. AND Tyler, C. W. AND Favreau, O. E.},
  Journal                  = {Journal of the Optical Society of America},
  Year                     = {1984},
  Number                   = {8},
  Pages                    = {893-899},
  Volume                   = {1},

  Doi                      = {10.1364/JOSAA.1.000893},
  File                     = {Cavanagh1984.pdf:Cavanagh1984.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.15}
}

@Article{Chandler1992,
  Title                    = {Minimum audible movement angle in the horizontal plane as a function of stimulus frequency and bandwidth, source azimuth, and velocity},
  Author                   = {Chandler, David W. and Grantham, D. Wesley},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1992},
  Number                   = {3},
  Pages                    = {1624-1636},
  Volume                   = {91},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Minimum audible movement angles (MAMAs) were measured in the horizontal plane for four normal‐hearing adult subjects in a darkened anechoic chamber. On each trial, a single stimulus was presented, and the subject had to say whether it came from a stationary loudspeaker or from a loudspeaker that was moving at a constant angular velocity around him. Thresholds were established by adaptively varying stimulus duration. In experiment 1, MAMAs were measured as a function of center frequency (500–5000 Hz), velocity (10°–180°/s), and direction of motion (left versus right). There was no effect of direction of motion. MAMAs increased with velocity, from an average of 8.8° of arc for a target moving at 10°/s to an average of 20.2° of arc for a target moving at 180°/s. MAMAs were higher for a 3000‐Hz tone than for tones of lower or higher frequencies, as has been previously reported [D. R. Perrott and J. Tucker, J. Acoust. Soc. Am. 83, 1522–1527 (1988)]. In experiment 2, minimum audible angles (MAAs) were measured with sequentially presented stationary tone pulses (500–5000 Hz), and were shown to exhibit the same dependence on signal frequency that the MAMAs showed (average MAA at 3000 Hz: 8.4°; average MAA at the other frequencies: 3.4°).
In experiment 3, MAMAs and MAAs were measured as a function of stimulus bandwidth (centered at 3000 Hz) and listening azimuth (0° vs 60°). Average MAAs decreased monotonically as stimulus bandwidth increased from 0 Hz to wideband (from 8.4° to 1.2° at 0° azimuth; from 11.3° to 1.5° at 60° azimuth). As in experiment 1, MAMAs increased with stimulus velocity, from values comparable to the MAAs for the slowest‐velocity (10°/s) targets to 70° of arc or more in the poorest condition (third‐octave band of noise presented at a velocity of 180°/s and an azimuth of 60°). MAMAs obtained in the slower‐velocity conditions depended in the same way on stimulus bandwidth and listening azimuth that MAAs depended on these variables. In no case was the MAMA ever smaller than the MAA. It is hypothesized that a minimum integration time is required to achieve optimal performance in a dynamic spatial resolution task. Average estimates of this minimum time based on the current data vary from 336 ms (for targets presented at midline) to 1116 ms (for narrow‐band targets presented at 60° azimuth). The relatively large magnitudes of these minimum integration times are consistent with the view of the binaural processor as a sluggish system.},
  Doi                      = {10.1121/1.402443},
  File                     = {Chandler1992.pdf:Chandler1992.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{Ching2015,
  Title                    = {Comparing NAL-NL1 and DSL v5 in Hearing Aids Fit to Children with Severe or Profound Hearing Loss: Goodness of Fit-to-Targets, Impacts on Predicted Loudness and Speech Intelligibility},
  Author                   = {Ching, Teresa Y.C. AND Quar, Tian Kar AND Johnson, Earl E. AND Newall, Philip AND Sharma, Mridula},
  Journal                  = {Journal of the American Academy of Audiology},
  Year                     = {2015},

  Month                    = {March},
  Number                   = {3},
  Pages                    = {260-274},
  Volume                   = {26},

  Doi                      = {10.3766/jaaa.26.3.6},
  File                     = {Ching2015.pdf:Ching2015.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Cochran1968,
  Title                    = {Estimation of distance of a source of sound},
  Author                   = {Cochran, Paul AND Throop, Janet AND Simpson, W. E.},
  Journal                  = {The American Journal of Psychology},
  Year                     = {1968},
  Number                   = {2},
  Pages                    = {198-206},
  Volume                   = {81},

  File                     = {Cochran1968.pdf:Cochran1968.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27},
  Url                      = {http://www.jstor.org/stable/1420327}
}

@Article{Coleman1968,
  Title                    = {Dual role of frequency spectrum in determination of auditory distance},
  Author                   = {Coleman, Paul D.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1968},
  Number                   = {2},
  Pages                    = {631-634},
  Volume                   = {44},

  Doi                      = {10.1121/1.1911132},
  File                     = {Coleman1968.pdf:Coleman1968.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27}
}

@Book{Cormen2009,
  Title                    = {Introduction to algorithms},
  Author                   = {Cormen, Thomas H. AND Leiserson, Charles E. AND Rivest, Ronald L. AND Stein, Clifford},
  Editor                   = {MIT Press},
  Publisher                = {MIT Press},
  Year                     = {2009},
  Edition                  = {3rd edition},

  File                     = {Cormen2009.pdf:Cormen2009.pdf:PDF},
  Keywords                 = {development; data structures; algorithms},
  Owner                    = {mattberjon},
  Timestamp                = {2016.10.14}
}

@PhdThesis{Corteel2004,
  Title                    = {Caractérisation et Extensions de la Wave Field Synthesis en conditions réelles},
  Author                   = {Corteel, Etienne},
  School                   = {Université Pierre et Marie Curie},
  Year                     = {2004},

  Abstract                 = {La Wave Field Synthesis est une technique de reproduction sonore qui vise à reproduire les caractéristiques physiques du champ acoustique dans une zone d'écoute étendue. Elle dépasse ainsi les limites des techniques stéréophoniques et permet la restitution d'une véritable perspective sonore à l'aide d'un réseau linéaire de haut-parleurs. Cette technique repose sur un ensemble d'approximations des principes physiques sous-jacents qui n'assure cependant pas une restitution exacte. Le travail réalisé a consisté à compléter le cadrethéorique et, à analyser et à valider de manière systématique la qualité du champ acoustique synthétisé en termes perceptifs (indices de localisation, coloration). Au-delà de cette analyse, nous proposons des techniques d'égalisation multicanal pour compenser les caractéristiques réelles des transducteurs et tenir compte de celles des parois de la pièce de restitution. Enfin, nous présentons une chaîne de production qui permet la gestion de la perspective sonore par le créateur de contenu.},
  File                     = {Corteel2004.pdf:Corteel2004.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.12}
}

@Article{Culling1996,
  Title                    = {Signal-processing software for teaching and research in psychoacoustics under UNIX and X-Windows},
  Author                   = {Culling, J. F.},
  Journal                  = {Behavior Research Methods},
  Year                     = {1996},
  Number                   = {3},
  Pages                    = {376-382},
  Volume                   = {28},

  File                     = {Culling1996.pdf:Culling1996.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.04}
}

@PhdThesis{Daniel2011,
  Title                    = {Spatial auditory blurring and applications to multichannel audio coding},
  Author                   = {Daniel, Adrien},
  School                   = {Université Pierre et Marie Curie},
  Year                     = {2011},

  File                     = {Daniel2011.pdf:Daniel2011.pdf:PDF},
  Keywords                 = {localisation; audio; signal processing; perception; azimuth; phd},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.30}
}

@PhdThesis{Daniel2000,
  Title                    = {Représentation de champs acoustiques, application à la transmission et la reproduction de scènes sonores complexes dans un contexte multimédia},
  Author                   = {Daniel, Jérome},
  School                   = {Université de Paris- AND France Telecom Recherche et Développment},
  Year                     = {2000},
  Type                     = {Thèse CIFRE},

  File                     = {Daniel2000.pdf:Daniel2000.pdf:PDF},
  Keywords                 = {signal processing; audio; localisation; phd;}
}

@Article{Dawes2015,
  Title                    = {Hearing Loss and Cognition: The Role of Hearing Aids, Social Isolation and Depression},
  Author                   = {Dawes, Piers AND Emsley, Richard AND Cruickshanks, Karen J. AND Moore, David R. AND Fortnum, Heather AND Edmondson-Jones, Mark AND McCormack, Abby AND Munro, Kevin J.},
  Journal                  = {PLOS ONE},
  Year                     = {2015},

  Month                    = {March},
  Pages                    = {1-9},

  Doi                      = {10.1371/journal.pone.0119616},
  File                     = {Dawes2015.pdf:Dawes2015.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Daye2012,
  Title                    = {Target motion direction influence on tracking performance and head tracking strategies in head-unrestrained conditions},
  Author                   = {Daye, Pierre M. and Blohm, Gunnar and Lefevre, Philippe},
  Journal                  = {Journal of Vision},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {1-12},
  Volume                   = {12},

  Doi                      = {10.1167/12.1.23},
  Eprint                   = {http://www.journalofvision.org/content/12/1/23.full.pdf+html},
  File                     = {Daye2012.pdf:Daye2012.pdf:PDF},
  Keywords                 = {vision; head motion; source motion; azimut; perception; motion;}
}

@PhdThesis{Deprez2012,
  Title                    = {Optimisation perceptive de la restitution sonore multicanale par une analyse spatio-temporelle des premières réﬂexions},
  Author                   = {Romain Deprez},
  School                   = {Université d’Aix-Marseille},
  Year                     = {2012},

  File                     = {Deprez2012.pdf:Deprez2012.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.04.15}
}

@Book{DiGiovanni2011,
  Title                    = {Hearing aid handbook},
  Author                   = {DiGiovanni, Jeffrey J.},
  Editor                   = {Cengage Learning},
  Publisher                = {Cengage Learning},
  Year                     = {2011}
}

@Article{Dillon1999,
  Title                    = {NAL-NL1: A new procedure for fitting non-linear hearing aids.},
  Author                   = {Dillon, Harvey},
  Journal                  = {Hearing Journal},
  Year                     = {1999},

  Month                    = {April},
  Number                   = {4},
  Pages                    = {10-12-14-16},
  Volume                   = {52},

  File                     = {Dillon1999.pdf:Dillon1999.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Dimmick1930,
  Title                    = {The effect of the exposure time upon the Reiz Limen of visible motion},
  Author                   = {Dimmick, F. L. AND Karl, J. C.},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1930},
  Number                   = {4},
  Pages                    = {365-369},
  Volume                   = {13},

  Doi                      = {10.1037/h0070559},
  File                     = {Dimmick1930.pdf:Dimmick1930.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Book{Downey2012,
  Title                    = {Think Python: How to think like a computer Scientist},
  Author                   = {Downey, Allen},
  Editor                   = {Green Tea Press},
  Publisher                = {Green Tea Press},
  Year                     = {2012},
  Number                   = {2.0.17},

  File                     = {Downey2012.pdf:Downey2012.pdf:PDF},
  Keywords                 = {development; programming; python},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.05}
}

@Book{Duplain2013,
  Title                    = {Instant Flask web development},
  Author                   = {Duplain, Ron},
  Publisher                = {Packt Publishing Ltd.},
  Year                     = {2013},

  File                     = {Duplain2013.pdf:Duplain2013.pdf:PDF},
  Keywords                 = {dev; flask; python}
}

@Article{Edwards1955,
  Title                    = {Accuracy of auditory depth perception},
  Author                   = {Edwards, Austin S.},
  Journal                  = {Journal of General Psychology},
  Year                     = {1955},
  Pages                    = {327-329},
  Volume                   = {52},

  Doi                      = {10.1080/00221309.1955.9920247},
  File                     = {Edwards1955.pdf:Edwards1955.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.25}
}

@Article{Edwards2007,
  Title                    = {The Future of Hearing Aid Technology},
  Author                   = {Edwards, Brent},
  Journal                  = {Trends in Hearing},
  Year                     = {2007},

  Month                    = {March},
  Number                   = {1},
  Pages                    = {31-46},
  Volume                   = {11},

  Doi                      = {10.1177/1084713806298004},
  File                     = {Edwards2007.pdf:Edwards2007.pdf:PDF},
  Keywords                 = {ewo}
}

@Conference{Ericson2001,
  Title                    = {The relative salience of auditory motion cues},
  Author                   = {Ericson, Mark A.},
  Booktitle                = {WASPAA 2001},
  Year                     = {2001},
  Pages                    = {111 - 114},

  Abstract                 = {The relative salience of auditory motion cues was measured in a series of four experiments. In the first three experiments, all combinations of three different auditory motion cues (intensity changes, Doppler frequency shifts and interaural time delays) were presented at various source trajectories, parallel to the listener's frontal plane. In the first experiment, the velocity of the source was varied from 7.5 to 100 miles per hour and the point of closest passing was varied from 1 to 100 meters. In the second experiment, the angular position of the source always moved from minus 30 degrees to plus 30 degrees and the minimal distance of the path was varied. In the third experiment, the simulated velocity was fixed at 33 miles per hour for all stimuli. The results of these experiments show that monaural acoustic cues of intensity and Doppler frequency changes had the greatest effect on the listeners' judgments of perceived velocity. The binaural cue of interaural time delays had little effect on the velocity judgments. The results also show that the distance traveled by the source was found to be a more salient velocity cue than actual sound source velocity. A fourth experiment was conducted to measure speed estimates of actual moving automotive sounds via dummy-head recordings. Actual sounds were estimated to travel at greater velocities than were simulated sounds, especially when the sounds were far away from the listener.},
  Doi                      = {10.1109/ASPAA.2001.969555},
  File                     = {Ericson2001.pdf:Ericson2001.pdf:PDF},
  Journal                  = {Workshop Applications of Signal Processing to Audio and Acoustics},
  Keywords                 = {audio; source motion; azimuth; perception; motion;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.24}
}

@Conference{Ericson2000,
  Title                    = {Magnitude Estimation of Sound Source Speed},
  Author                   = {Ericson, Mark A.},
  Booktitle                = {Audio Engineering Society Convention 109},
  Year                     = {2000},
  Month                    = {9},

  Abstract                 = {Linear motion of a harmonic sound source was simulated for various trajectory paths. The acoustic signal was processed with frequency and intensity changes because of Doppler shifts in frequency, overall intensity changes, and atmospheric absorption. While listening to these sounds over headphones, four participants were asked to make magnitude estimations of the sound source speed under various combinations of motion effects. The frequency and intensity changes were found to contribute to the ability of the listeners to judge sound source speed. Inclusion of these motion attributes produced a veridical simulation of sound source motion.},
  File                     = {Ericson2000.pdf:Ericson2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.20}
}

@Article{Erulkar1972,
  Title                    = {Comparative aspects of spatial localization of sound},
  Author                   = {Erulkar, S. D.},
  Journal                  = {Physiological Reviews},
  Year                     = {1972},
  Number                   = {1},
  Pages                    = {237-360},
  Volume                   = {52},

  File                     = {Erulkar1972.pdf:Erulkar1972.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01},
  Url                      = {http://physrev.physiology.org/content/52/1/237}
}

@Conference{Farina2000,
  Title                    = {Simultaneous measurement of impulse response and distortion with a swept-sine technique},
  Author                   = {Farina, Angelo},
  Booktitle                = {Audio Engineering Society Convention 108},
  Year                     = {2000},
  Month                    = {2},

  File                     = {Farina2000.pdf:Farina2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.08}
}

@TechReport{Faure2005,
  Title                    = {Evaluation de la synthèse binaurale dynamique},
  Author                   = {Faure, Julien},
  Institution              = {France Télécom R\&D},
  Year                     = {2005},
  Note                     = {rapport technique FT/DIVISION R\&D/TECH/SSTP/JF/2005-63},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08}
}

@Article{Feron2010,
  Title                    = {Upper limits of auditory rotational motion perception},
  Author                   = {Féron, François-Xavier and Frissen, Ilja and Boissinot, Julien and Guastavino, Catherine},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {2010},
  Number                   = {6},
  Pages                    = {3703-3714},
  Volume                   = {128},

  Abstract                 = {Three experiments are reported, which investigated the auditory velocity thresholds beyond which listeners are no longer able to perceptually resolve a smooth circular trajectory. These thresholds were measured for band-limited noises, white noise, and harmonic sounds (HS), and in different acoustical environments. Experiments 1 and 2 were conducted in an acoustically dry laboratory. Observed thresholds varied as a function of stimulus type and spectral content. Thresholds for band-limited noises were unaffected by center frequency and equal to that of white noise. For HS, however, thresholds decreased as the fundamental frequency of the stimulus increased. The third experiment was a replication of the second in a reverberant concert hall, which produced qualitatively similar results except that thresholds were significantly higher than in the acoustically dry laboratory.},
  Doi                      = {10.1121/1.3502456},
  File                     = {Feron2010.pdf:Feron2010.pdf:PDF},
  Keywords                 = {source motion; motion; azimuth; perception; audio;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.22}
}

@Article{Filehne1922,
  Title                    = {Uber das optische Wahrnehmen von Bewegungen},
  Author                   = {Filehne, W.},
  Journal                  = {Zeitschrift für Sinnephysiologie},
  Year                     = {1922},
  Pages                    = {134-145},
  Volume                   = {53},

  __markedentry            = {[mattberjon:]},
  File                     = {Filehne1922.pdf:Filehne1922.pdf:PDF},
  Keywords                 = {vision; motion; azimuth; perception; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.06}
}

@Book{Finney1971,
  Title                    = {Probit analysis},
  Author                   = {Finney, David J.},
  Editor                   = {Cambridge, UK},
  Publisher                = {Cambridge University Press},
  Year                     = {1971},
  Edition                  = {3rd edition},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.06}
}

@Article{Fisher1968,
  Title                    = {The role of the pinna in auditory localization},
  Author                   = {Fisher, H. Geoffrey AND Freedman, Sanford J.},
  Journal                  = {Journal of Auditory Research},
  Year                     = {1968},
  Number                   = {1},
  Pages                    = {15-26},
  Volume                   = {8},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {20 Ss made localization judgments of white noise stimuli under 6 different experimental conditions, which varied head movement (restricted vs. free) and pinna condition (own pinnae vs. "no pinnae," in which sealed earmuffs terminated in open 10-cm tubes, vs. "artificial pinnae," in which the tubes were terminated by casts of human pinnae). Results indicate no differences in localization ability for the free head condition, but that when head movement is restricted localization is better with pinnae, even when they are casts of another individual. Emphasis is thus placed on the role of the pinna in sound localization.},
  File                     = {Fisher1968.pdf:Fisher1968.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Article{Fleischl1882,
  Title                    = {Physiologisch-optische Notizen},
  Author                   = {Fleischl, E. V.},
  Journal                  = {Sitzung Wiener Bereich der Akademie der Wissenschaften},
  Year                     = {1882},
  Pages                    = {7-25},
  Volume                   = {3},

  Owner                    = {mattberjon},
  Timestamp                = {2012.11.19}
}

@Article{Fletcher1933,
  Title                    = {Loudness, Its Definition, Measurement and Calculation},
  Author                   = {Fletcher, Harvey AND Munson, W. A.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1933},
  Number                   = {2},
  Pages                    = {82-108},
  Volume                   = {5},

  Doi                      = {10.1121/1.1915637},
  File                     = {Fletcher1933.pdf:Fletcher1933.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.21}
}

@Book{Foster2015,
  Title                    = {The ultimate guide to remote work},
  Author                   = {Foster, Wade AND Schreiber, Danny AND Groves, Alison AND Guay, Matthew AND DuVall, Jeremy AND Cooper, Belle},
  Editor                   = {Zapier},
  Publisher                = {Zapier},
  Year                     = {2015},

  File                     = {Foster2015.pdf:Foster2015.pdf:PDF},
  Keywords                 = {work; remote},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.02}
}

@Article{Freeman2001,
  Title                    = {Transducer models of head-centred motion perception},
  Author                   = {Freeman, Thomas C. A.},
  Journal                  = {Vision Res.},
  Year                     = {2001},
  Number                   = {21},
  Pages                    = {2741-2755},
  Volume                   = {41},

  Abstract                 = {By adding retinal and pursuit eye-movement velocity one can determine the motion of an object with respect to the head. It would seem likely that the visual system carries out a similar computation by summing extra-retinal, eye-velocity signals with retinal motion signals. Perceived head-centred motion may therefore be determined by differences in the way these signals encode speed, For example, if extra-retinal signals provide the lower estimate of speed then moving objects will appear slower when pursued (Aubert-Fleischl phenomenon) and stationary objects will move opposite to an eye movement (Filehne illusion). Most previous work proposes that these illusions exist because retinal signals encode retinal motion accurately while extra-retinal signals under-estimate eye speed. A more general model is presented in which both signals could be in error. Two types of input/output speed relationship are examined. The first uses linear speed transducers and the second non-linear speed transducers, the latter based on power laws. It is shown that studies of the Aubert-Fleischl phenomenon and Filehne illusion reveal the gain ratio or power ratio alone. We also consider general velocity-matching and show that in theory matching functions are limited by gain ratio in the linear case. However, in the non-linear case individual transducer shapes are revealed albeit up to an unknown scaling factor. The experiments show that the Aubert-Fleischl phenomenon and Filehne illusion are adequately described by linear speed transducers with a gain ratio less than one. For some observers, this is also the case in general velocity-matching experiments. For other observers, however, behaviour is non-linear and, according to the transducer model, indicates the existence of expansive non-linearities in speed encoding. This surprising result is discussed in relation to other theories of head-centred motion perception and the possible strategies some observers might adopt when judging stimulus motion during an eye movement.},
  Doi                      = {10.1016/S0042-6989(01)00159-6},
  File                     = {Freeman2001.pdf:Freeman2001.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.07.18}
}

@Article{Freeman2009,
  Title                    = {Do we have direct access to retinal image motion during smooth pursuit eye movements?},
  Author                   = {Freeman, Tom C. A. AND Champion, Rebecca A. AND Sumnall, Jane H. AND Snowden, Robert J.},
  Journal                  = {Journal of Vision},
  Year                     = {2009},
  Number                   = {1},
  Pages                    = {1-11},
  Volume                   = {9},

  Abstract                 = {One way the visual system estimates object motion during pursuit is to combine estimates of eye velocity and retinal motion. This questions whether observers need direct access to retinal motion during pursuit. We tested this idea by varying the correlation between retinal motion and objective motion in a two-interval speed discrimination task. Responses were classified according to three motion cues: retinal speed (based on measured eye movements), objective speed, and the relative motion between pursuit target and stimulus. In the first experiment, feedback was based on relative motion and this cue fit the response curves best. In the second experiment, simultaneous relative motion was removed but observers still used the sequential relative motion between pursuit target and dot pattern to make their judgements. In a final experiment, feedback was given explicitly on the retinal motion, using online measurements of eye movements. Nevertheless, sequential relative motion still provided the best account of the data. The results suggest that observers do not have direct access to retinal motion when making perceptual judgements about movement during pursuit.},
  Doi                      = {10.1167/9.1.33},
  File                     = {Freeman2009.pdf:Freeman2009.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.10}
}

@Article{Freeman1998,
  Title                    = {Perceived head-centric speed is affected by both extra-retinal and retinal errors},
  Author                   = {Freeman, T. C. and Banks, Martin S.},
  Journal                  = {Vision Research},
  Year                     = {1998},
  Number                   = {7},
  Pages                    = {941-945},
  Volume                   = {38},

  Abstract                 = {When we make a smooth eye movement to track a moving object, the visual system must take the eye's movement into account in order to estimate the object's velocity relative to the head. This can be done by using extra-retinal signals to estimate eye velocity and then subtracting expected from observed retinal motion. Two familiar illusions of perceived velocity--the Filehne illusion and Aubert-Fleischl phenomenon--are thought to be the consequence of the extra-retinal signal underestimating eye velocity. These explanations assume that retinal motion is encoded accurately, which is questionable because perceived retinal speed is strongly affected by several stimulus properties. We develop and test a model of head-centric velocity perception that incorporates errors in estimating eye velocity and in retinal-motion sensing. The model predicts that the magnitude and direction of the Filehne illusion and Aubert-Fleischl phenomenon depend on spatial frequency and this prediction is confirmed experimentally.},
  Doi                      = {10.1016/S0042-6989(97)00395-7},
  File                     = {Freeman1998.pdf:Freeman1998.pdf:PDF},
  Keywords                 = {vision; motion; source motion; azimuth; perception; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.21}
}

@Article{Freeman2010,
  Title                    = {A bayesian model of perceived head-centered velocity during smooth pursuit eye movement},
  Author                   = {Freeman, Thomas C.A. AND Champion, Rebecca A. and Warren, Paul A.},
  Journal                  = {Current Biology},
  Year                     = {2010},
  Number                   = {8},
  Pages                    = {757-762},
  Volume                   = {20},

  Abstract                 = {During smooth pursuit eye movement, observers often misperceive velocity. Pursued stimuli appear slower (Aubert-Fleishl phenomenon [1, 2]), stationary objects appear to move (Filehne illusion [3]), the perceived direction of moving objects is distorted (trajectory misperception [4]), and self-motion veers away from its true path (e.g., the slalom illusion [5]). Each illusion demonstrates that eye speed is underestimated with respect to image speed, a finding that has been taken as evidence of early sensory signals that differ in accuracy [4, 6-11]. Here we present an alternative Bayesian account, based on the idea that perceptual estimates are increasingly influenced by prior expectations as signals become more uncertain [12-15]. We show that the speeds of pursued stimuli are more difficult to discriminate than fixated stimuli. Observers are therefore less certain about motion signals encoding the speed of pursued stimuli, a finding we use to quantify the Aubert-Fleischl phenomenon based on the assumption that the prior for motion is centered on zero [16-20]. In doing so, we reveal an important property currently overlooked by Bayesian models of motion perception. Two Bayes estimates are needed at a relatively early stage in processing, one for pursued targets and one for image motion.},
  Doi                      = {10.1016/j.cub.2010.02.059},
  File                     = {Freeman2010.pdf:Freeman2010.pdf:PDF},
  Journaltitle             = {Current Biology},
  Keywords                 = {vision; source motion; azimuth; perception; motion; eyes movement;}
}

@Article{Fryer2015,
  Title                    = {The Hearing-Loss Guide–A Review for the SLP},
  Author                   = {Fryer, Melissa P.},
  Journal                  = {Perspectives on Gerontology},
  Year                     = {2015},

  Month                    = {May},
  Pages                    = {47-48},
  Volume                   = {20},

  Doi                      = {10.1044/gero20.2.47},
  Keywords                 = {ewo}
}

@Article{Gahmry2012,
  Title                    = {An FPGA Implementation Of Hearing Aids based on Wavelet-Packets},
  Author                   = {Gahmry, Nivin},
  Journal                  = {Journal of Computers},
  Year                     = {2012},

  Month                    = {March},
  Number                   = {3},
  Pages                    = {680-684},
  Volume                   = {7},

  Doi                      = {10.4304/jcp.7.3.680-684},
  File                     = {Gahmry2012.pdf:Gahmry2012.pdf:PDF},
  Keywords                 = {ewo; hardware}
}

@Article{Ganz1984,
  Title                    = {Mechanism of directional selectivity in simple neurons of the cat's visual cortex analyzed with stationary flash sequences},
  Author                   = {Ganz, L. AND Felder, R.},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {1984},
  Number                   = {2},
  Pages                    = {294-324},
  Volume                   = {51},

  File                     = {Ganz1984.pdf:Ganz1984.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Article{Garcia-Perez2000,
  Title                    = {Optimal setups for forced-choice staircases with fixed step sizes},
  Author                   = {Garcia-Perez, M. A.},
  Journal                  = {Spatial Vision},
  Year                     = {2000},
  Number                   = {4},
  Pages                    = {431-448},
  Volume                   = {13},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Forced-choice staircases with fixed step sizes are used in a variety of formats whose relative merits have never been studied. This paper presents a comparative study aimed at determining their optimal format. Factors included in the study were the up/down rule, the length (number of reversals), and the size of the steps. The study also addressed the issue of whether a protocol involving three staircases running for N reversals each (with a subsequent average of the estimates provided by each individual staircase) has better statistical properties than an alternative protocol involving a single staircase running for 3N reversals. In all cases the size of a step up was different from that of a step down, in the appropriate ratio determined by García-Pérez (Vision Research, 1998, 38, 1861-1881). The results of a simulation study indicate that a) there are no conditions in which the 1-down/1-up rule is advisable; b) different combinations of up/down rule and number of reversals appear equivalent in terms of precision and cost; c) using a single long staircase with 3N reversals is more efficient than running three staircases with N reversals each; d) to avoid bias and attain sufficient accuracy, threshold estimates should be based on at least 30 reversals; and e) to avoid excessive cost and imprecision, the size of the step up should be between 2/3 and 3/3 the (known or presumed) spread of the psychometric function. An empirical study with human subjects confirmed the major characteristics revealed by the simulations.},
  Doi                      = {10.1163/156856800741306},
  File                     = {Garcia-Perez2000.pdf:Garcia-Perez2000.pdf:PDF},
  Keywords                 = {ADAPTIVE STAIRCASES; FORCED-CHOICE; THRESHOLD; SIMULATION},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Garcia-Perez1998,
  Title                    = {Forced-choicestaircases with fixed step sizes: asymptotic and small-sample properties},
  Author                   = {Garcia-Perez, Miguel A.},
  Journal                  = {Vision Res.},
  Year                     = {1998},
  Number                   = {12},
  Pages                    = {1861–1881},
  Volume                   = {38},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Visual detection and discrimination thresholds are often measured using adaptive staircases, and most studies use transformed (or weighted) up/down methods with fixedstepsizes—in the spirit of Wetherill and Levitt (Br J Mathemat Statist Psychol 1965;18:1–10) or Kaernbach (Percept Psychophys 1991;49:227–229)—instead of changing stepsize at each trial in accordance with best-placement rules—in the spirit of Watson and Pelli (Percept Psychophys 1983;47:87–91). It is generally assumed that a fixed-step-size (FSS) staircase converges on the stimulus level at which a correct response occurs with the probabilities derived by Wetherill and Levitt or Kaernbach, but this has never been proved rigorously. This work used simulation techniques to determine the asymptotic and small-sample convergence of FSS staircases as a function of such parameters as the up/down rule, the size of the steps up or down, the starting stimulus level, or the spread of the psychometric function. The results showed that the asymptotic convergence of FSS staircases depends much more on the sizes of the steps than it does on the up/down rule. Yet, if the size Δ+ of a step up differs from the size Δ− of a step down in a way that the ratio Δ−/Δ+ is constant at a specific value that changes with up/down rule, then convergence percent-correct is unaffected by the absolute sizes of the steps. For use with the popular one-, two-, three- and four-down/one-up rules, these ratios must respectively be set at 0.2845, 0.5488, 0.7393 and 0.8415, rendering staircases that converge on the 77.85%-, 80.35%-, 83.15%- and 85.84%-correct points. Wetherill and Levitt's transformed up/down rules—which require Δ−/Δ+=1—and the general version of Kaernbach's weighted up/down rule—which allows any Δ−/Δ+ ratio—fail to reach their presumed targets. The small-sample study showed that, even with the optimal settings, short FSS staircases (up to 20 reversals in length) are subject to some bias, and their precision is less than reasonable, but their characteristics improve when the size Δ+ of a step up is larger than half the spread of the psychometric function. Practical recommendations are given for the design of efficient and trustworthy FSS staircases.},
  Doi                      = {10.1016/S0042-6989(97)00340-4},
  File                     = {Garcia-Perez1998.pdf:Garcia-Perez1998.pdf:PDF},
  Keywords                 = {Forcedchoice; Adaptive staircases; Threshold estimates; Efficiency; Error; Simulation techniques},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Gatehouse2003,
  Title                    = {Benefits from hearing aids in relation to the interaction between the user and the environment},
  Author                   = {Gatehouse, Stuart AND Naylor, Graham AND Elberling, Clous},
  Journal                  = {International Journal of Audiology},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {77-85},
  Volume                   = {42},

  Doi                      = {10.3109/14992020309074627},
  File                     = {Gatehouse2003.pdf:Gatehouse2003.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Gegenfurtner1999,
  Title                    = {Seeing movement in the dark},
  Author                   = {Gegenfurtner, Karl R. AND Mayser, Heltmut AND Sharpe, Lindsay T.},
  Journal                  = {Nature},
  Year                     = {1999},
  Pages                    = {475-476},
  Volume                   = {398},

  Doi                      = {10.1038/19004},
  File                     = {Gegenfurtner1999.pdf:Gegenfurtner1999.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.02}
}

@Article{Getzmann2011a,
  Title                    = {Auditory motion perception: onset position and motion direction are encoded in discrete processing stages},
  Author                   = {Getzmann, Stephan},
  Journal                  = {European Journal of Neuroscience},
  Year                     = {2011},
  Number                   = {7},
  Pages                    = {1339-1350},
  Volume                   = {33},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The neural processing of auditory motion information shows a pronounced interhemispheric asymmetry. In previous electrophysiological studies, the so-called motion-onset response (MOR), a prominent auditory-evoked potential to the onset of sound motion, was stronger over the hemisphere contralateral to the side of motion. Here, effects of lateral-onset position and direction of motion on MOR contralaterality were investigated. Eighteen listeners were presented with free-field sound stimuli that, after an initial stationary phase at a lateral spatial position within the left or right hemifield, started to move either left- or rightward. The early part of the MOR, the so-called change-N1, exhibited contralaterality that depended on the lateral motion-onset position with stronger activations over the hemisphere contralateral to the side of motion onset, whereas the contralaterality of the later part of the MOR, the so-called change-P2, merely depended on the direction of motion. Cortical source localization indicated that this pattern of contralaterality primarily resulted from asymmetric activation in primary auditory cortex and insula. These findings suggest that the early and late parts of the MOR reflect different phases in auditory motion perception, supporting the notion of a modular organization of discrete processing stages.},
  Doi                      = {10.1111/j.1460-9568.2011.07617.x},
  File                     = {Getzmann2011a.pdf:Getzmann2011a.pdf:PDF},
  Keywords                 = {auditory localization; electroencephalography; motion perception; spatial hearing},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Getzmann2011,
  Title                    = {The effect of spatial adaptation on auditory motion processing},
  Author                   = {Getzmann, Stephan and Lewald, Joerg},
  Journal                  = {Hearing Research},
  Year                     = {2011},
  Number                   = {1-2},
  Pages                    = {21-29},
  Volume                   = {272},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The effect of acoustic pre-stimulation on cortical processing of subsequent sound motion was investigated in free-field space, using electroencephalography and a psychophysical motion-discrimination task. Subjects heard sound stimuli that moved from a central position (0 degrees) to the left or right. The onset of motion was preceded by either stationary sound at 0 degrees or spatially scattered sound on the left (0 to 32), right (0-32 degrees), or both (-32 to 32 degrees) sides. Following stationary sound, the start of auditory motion elicited a motion-specific onset response as described in previous studies. Following scattered sound, the amplitude of the motion-onset response was lower and reaction times in motion discrimination were longer than with the stationary pre-stimulus. Both these effects were most pronounced when the pre-stimulation by scattered sound was on the same side as the motion, whereas effects were only weak when pre-stimuli and motion were on different sides. These results are compatible with the view that spatial adaptation plays a role in auditory motion perception, and that motion processing could be triggered by release of adaptation of populations of location-specific neurons.},
  Doi                      = {10.1016/j.heares.2010.11.005},
  File                     = {Getzmann2011.pdf:Getzmann2011.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.03.01}
}

@Article{Grantham1986,
  Title                    = {Detection and discrimination of simulated motion of auditory targets in the horizontal plane},
  Author                   = {Grantham, D. Wesley},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1986},
  Number                   = {6},
  Pages                    = {1939-1949},
  Volume                   = {79},

  __markedentry            = {[mattberjon:]},
  Doi                      = {10.1121/1.393201},
  File                     = {Grantham1986.pdf:Grantham1986.pdf:PDF},
  Journaltitle             = {Journal of Acoustical Society of America},
  Keywords                 = {TODO}
}

@Article{Grantham1984,
  Title                    = {Discrimination of dynamic interaural intensity differences},
  Author                   = {Grantham, D. W.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1984},
  Number                   = {1},
  Pages                    = {71-76},
  Volume                   = {76},

  Doi                      = {10.1121/1.391009},
  File                     = {Grantham1984.pdf:Grantham1984.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Grantham1979,
  Title                    = {Auditory motion aftereffects},
  Author                   = {Grantham, D. W. and Wightman, F. L.},
  Journal                  = {Perception and Psychophysics},
  Year                     = {1979},
  Number                   = {5},
  Pages                    = {403-408},
  Volume                   = {26},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Observers were adapted to simulated auditory movement produced by dynamically varying the interaural time and intensity differences of tones (500 or 2,000 Hz) presented through headphones. At lO-sec intervals during adaptation, various probe tones were presented for 1 sec (the frequency of the probe was always the same as that of the adaptation stimulus). Observers judged the direction of apparent movement (“left” or “right”) of each probe tone. At 500 Hz, with a 200-deg/sec adaptation velocity, “stationary” probe tones were consistently judged to move in the direction opposite to that of the adaptation stimulus. We call this result an auditory motion aftereffect. In slower velocity adaptation conditions, progressively less aftereffect was demonstrated. In the higher frequency condition (2,000 Hz, 200-deg/sec adaptation velocity), we found no evidence of motion aftereffect. The data are discussed in relation to the well-known visual analog-the “waterfall effect.” Although the auditory aftereffect is weaker than the visual analog, the data suggest that auditory motion perception might be mediated, as is generally believed for the visual system, by direction-specific movement analyzers.},
  Doi                      = {10.3758/BF03204166},
  File                     = {Grantham1979.pdf:Grantham1979.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.22}
}

@Book{Grenning2011,
  Title                    = {Test Driven Development for Embedded C},
  Author                   = {Grenning, James W.},
  Editor                   = {Jacquelyn Carter},
  Publisher                = {Pragmatic Bookshelf},
  Year                     = {2011},
  Edition                  = {Edition 1},

  File                     = {Grenning2011.pdf:Grenning2011.pdf:PDF},
  Keywords                 = {programming; tdd; unit testing; embedded}
}

@Article{Griffiths1994,
  Title                    = {Human cortical areas selectivity activated by apparent sound movement},
  Author                   = {Griffiths, T. D. AND Bench, C. J. AND Frackowiak, R. S. J.},
  Journal                  = {Current biology},
  Year                     = {1994},
  Number                   = {10},
  Pages                    = {892-895},
  Volume                   = {4},

  Doi                      = {10.1016/S0960-9822(00)00198-6},
  File                     = {Griffiths1994.pdf:Griffiths1994.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Griffiths1996,
  Title                    = {Evidence for a sound movement area in the human cerebral cortex},
  Author                   = {Griffiths, T. D. AND Rees, A. AND Witton, C. AND Shakir, R. A. AND Henning, G. B. AND Green, G. G. R.},
  Journal                  = {Nature},
  Year                     = {1996},
  Number                   = {6599},
  Pages                    = {425-427},
  Volume                   = {383},

  Abstract                 = {HUMAN listeners can localize sounds by the difference in both arrival time (phase) and loudness between the two ears(1). Movement of the sound source modulates these cues, and responses to moving sounds have been detected in animals in primary auditory cortex(2,3) and in humans in other cortical areas(4). Here we show that detection of changes in the interaural phase or amplitude difference occurs through a mechanism distinct from that used to detect changes in one ear alone, Moreover, a patient with a right hemisphere stroke is unable to detect sound movement, regardless of whether it is defined by phase or by loudness cues. We propose that this deficit reflects damage to a distinct cortical area, outside the classical auditory areas, that is specialized for the detection of sound motion, The deficit is analagous to cerebral akinotopsia (motion blindness) in the visual system, and so the auditory system may, like the visual system(5), show localization of specialized functions to different cortical regions.},
  Doi                      = {10.1038/383425a0},
  File                     = {Griffiths1996.pdf:Griffiths1996.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Article{Griffiths1998,
  Title                    = {Right parietal cortex is involved in the perception of sound movement in humans},
  Author                   = {Griffiths, Timothy D. AND Rees1, Geraint AND Rees, Adrian AND Green, Gary G. R. AND Witton, Caroline AND Rowe, Dominic AND Büchel, Christian AND Turner, Robert AND Frackowiak, Richard S. J.},
  Journal                  = {Nature Neuroscience},
  Year                     = {1998},
  Pages                    = {74-78},
  Volume                   = {1},

  Doi                      = {10.1038/276},
  File                     = {Griffiths1998.pdf:Griffiths1998.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.08.18}
}

@Article{Grimm2009,
  Title                    = {The Personal Hearing System—A Software Hearing Aid for a Personal Communication System},
  Author                   = {Grimm, Giso AND Guilmin, Gwénaël AND Poppen, Frank AND Vlaming, Marcel S. M. G. AND Hohmann, Volker},
  Journal                  = {EURASIP Journal on Advances in Signal Processing},
  Year                     = {2009},

  Month                    = {July},
  Volume                   = {2009},

  Doi                      = {10.1155/2009/591921},
  File                     = {Grimm2009.pdf:Grimm2009.pdf:PDF},
  Keywords                 = {ewo}
}

@Book{Grinberg2014,
  Title                    = {Flask web development - Developing web application with python},
  Author                   = {Grinberg, Miguel},
  Editor                   = {Blanchette, Megan},
  Publisher                = {O'Reilly media Inc.},
  Year                     = {2014},

  File                     = {Grinberg2014.pdf:Grinberg2014.pdf:PDF},
  Keywords                 = {dev; python; flask}
}

@Article{Grutter1999,
  Title                    = {Perception of changes in loudness},
  Author                   = {Grutter, Alexandra S.},
  Journal                  = {Nature},
  Year                     = {1999},
  Pages                    = {673-674},
  Volume                   = {398},

  __markedentry            = {[mattberjon:]},
  File                     = {Grutter1999.pdf:Grutter1999.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@PhdThesis{Guillon2009,
  Title                    = {Individualisation des indices spectraux pour la synthèse binaurale : recherche et exploitation des similarités inter-individuelles pour l'adaptation ou la reconstruction de HRTF},
  Author                   = {Guillon, Pierre},
  School                   = {Université du Maine},
  Year                     = {2009},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Le travail de thèse qui est rapporté dans le présent document a porté sur le problème de l'individualisation des HRTF pour la synthèse binaurale. Les HRTF sont les filtres linéaires, chacun associé à une direction de l'espace, qui portent en eux l'expression de tous les indices physiques de localisation nécessaires pour une perception de l'espace par le système auditif. La synthèse binaurale utilise avantageusement ces filtres pour sculpter les signaux à présenter aux tympans de l'auditeur, afin de lui procurer l'illusion d'une scène sonore réaliste. Les HRTF étant très liées à la morphologie de la tête et des pavillons, la spatialisation n'est correctement assurée que si ces filtres sont bien adaptés à l'auditeur. Cependant, la mesure exhaustive des HRTF est coûteuse et inconfortable, et il s'agit donc de développer des moyens alternatifs pour les obtenir : c'est le problème de l'individualisation. On se focalise sur les indices spectraux de la localisation auditive, c'est-à-dire les colorations du spectre à dépendance directionnelle, qui constituent la part des HRTF la plus complexe et la plus variable d'un individu à l'autre. Le constat fondateur de nos investigations est le suivant: bien que les HRTF présentent des caractéristiques intrinsèquement individuelles, on peut dégager des évolutions spatiofréquentielles de leur spectre d'amplitude, communes d'un individu à l'autre, mais susceptibles d'être masquées par deux sources importantes de variabilité, que sont la taille et l'orientation des pavillons. Nous proposons des outils permettant de dépasser ces différences apparentes, afin de se focaliser sur ce qui est vraiment spécifique à chaque individu. Deux solutions techniques d'individualisation des HRTF sont développées en utilisant avantageusement la diversité des comportements offerte par les HRTF d'une base de données. La première solution proposée permet d'adapter, pour un nouvel auditeur, les HRTF d'un autre individu issues d'une base de données, en leur appliquant des transformations guidées par une comparaison morphologique entre les pavillons des deux sujets. Les hypothèses de travail et les outils proposés pour mettre en oeuvre la technique sont validés objectivement grâce aux données recueillies sur 6 sujets, et on montre que la méthode d'adaptation proposée dépasse les performances de l'état de l'art. La seconde solution permet de reconstruire les HRTF d'un nouvel auditeur pour une direction quelconque de l'espace à partir d'un nombre réduit de HRTF individuelles mesurées. La technique proposée est basée sur une base de données constituée des HRTF mesurées finement sur une centaine de sujets, à partir desquelles on génère des prototypes. La reconstruction des HRTF repose sur un processus de reconnaissance de formes entre les HRTF individuelles mesurées et ces prototypes. Une validation objective montre que, selon différents critères, les performances de reconstruction de la technique proposée dépassent celles de l'état de l'art. Ces résultats sont confirmés par une évaluation subjective, menée selon un protocole novateur en synthèse binaurale dynamique.

This Ph.D. thesis deals with the problem of Head-Related Transfer Functions (HRTFs) individualization, in the context of binaural synthesis. HRTFs embed ail the acoustical phenomena occurring on the path between a source at a given position in space and the listener's eardrums. As these linear filters convey all free field localization cues needed by the auditory system to perceive a 3D sound scene, HRTF can be used to sculpt the signals to be reproduced over headphones in order to create convincing spatialized auditory displays : this is the aim of binaural synthesis. HRTFs strongly depend on idiosyncratic morphological features (overall shape of the head, fine structure of the pinnae), and as a result, the use of non-individual HRTFs often leads to perceptual artifacts. Unfortunately, exhaustive acoustic measurements of individual HRTFs are long and uncomfortable for subjects, and it is therefore expected to develop alternative techniques to obtain customized HRTFs : this is the problem of individualization. As they represent the most complex and the most individual part of HRTFs, our study focusses on the colorations induced by pinna filtering, known as spectral cues. The founding assumption of our work is the following : although HRTFs contain intrinsically individual features, common spatio-frequential behaviours can be found from subject to subject. Such similarities may be hidden by the existence of two morphological sources of variability, being the size and orientation of ear pinnae. We develop tools whose aim is to go beyond apparent differences, and to focus on what is really specific of each individual. We propose two technical solutions for HRTF individualization, based on the use of a HRTF database. The first solution uses a 3D model-based morphological matching of pinnae shapes, to properly adapt existing non-individual HRTFs from a database, so that they fit to a new listener. To transform HRTF data, we propose a combination of frequency scaling and rotation shift, whose parameters are predicted by the result of the morphological comparison. The method is designed on the basis of data acquired from six subjects, and it is shown objectively that a better customization is achieved compared to the state-of-the-art technique. The second solut ion aims at reconstructing HRTF for any direction, from only sparse individual HRTF measurements. In order t o overcome the performance of classical blind interpolation techniques, additional knowledge is injected in the reconstruction process :HRTF prototypes are first extracted from the analysis of a large HRTF database, and serve as a well-informed background in a pattern recognition process. An objective assessment shows that , compared to previously developped techniques, HRTF reconstruction achieves a better spatial fidelity with the proposed method. FinaIly, this result is confirmed by a subjective evaluation based on a new protocol.},
  File                     = {Guillon2009.pdf:Guillon2009.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Conference{Guillon2008a,
  Title                    = {Head-Related Transfer Function customization by frequency scaling and rotation shift based on a new morphological matching method},
  Author                   = {Guillon, P. AND Guignard, Thomas AND Nicol, R.},
  Booktitle                = {Audio Engineering Society Convention 125},
  Year                     = {2008},
  Month                    = {10},

  File                     = {Guillon2008a.pdf:Guillon2008a.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.10}
}

@Conference{Guillon2008,
  Title                    = {Head-Related Transfer Function reconstruction from sparse measurements considering a priori knowledge from database analysis: a pattern recognition approach},
  Author                   = {Guillon, Pierre AND Nicol, Rozenn},
  Booktitle                = {Audio Engineering Society Convention 125},
  Year                     = {2008},
  Month                    = {10},

  File                     = {Guillon2008.pdf:Guillon2008.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Haarmeier1997,
  Title                    = {False perception of motion in a patient who cannot compensate for eye movements},
  Author                   = {Haarmeier, T. AND Thier, P. AND Repnow, M. AND Petersen, D.},
  Journal                  = {Nature},
  Year                     = {1997},
  Number                   = {6653},
  Pages                    = {849-852},
  Volume                   = {389},

  Abstract                 = {We are usually unaware of the motion of an image across our retina that results from our own movement. For instance, during slow-tracking eye movements we do not mistake the shift of the image projected onto the retina for motion of the world around us, but instead perceive a stable world. Following early suggestions by von Helmoltz(1), it is commonly believed that this spatial stability is achieved by subtracting the retinal motion signal from an internal reference signal, such as a copy of the movement command (efference copy)(2-4). Object motion is perceived only if the two differ. Although this concept is widely accepted, its anatomical underpinning remains unknown. Here we describe the case of a patient with bilateral extrastriate cortex lesions, suffering from false perception of motion due to an inability to take eye movements into account when faced with self-induced retinal image slip. This is indicated by the fact that during smooth-pursuit eye movements, he perceives motion of the stationary world at a velocity that corresponds to the velocity of his eye movement; that is, he perceives the raw retinal image slip uncorrected for his own eye movements. We suspect that this deficiency reflects damage of a distinct parieto-occipital region that disentangles self-induced and externally induced visual motion by comparing retinal signals with a reference signal encoding eye movements and possibly ego-motion in general.},
  Doi                      = {10.1038/39872},
  File                     = {Haarmeier1997.pdf:Haarmeier1997.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Article{Hamburger2012,
  Title                    = {Still motion? Motion illusions and luminance contrast},
  Author                   = {Hamburger, Kai},
  Journal                  = {Perception},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {113 – 116},
  Volume                   = {41},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The influence of different luminance contrasts and equiluminance on illusory motion in four inducing patterns was studied: Enigma, Rotating Snakes, Pinna, and Rotating-Tilted-Lines. At high luminance contrast the Pinna and the Rotating-Tilted-Lines illusions are significantly stronger than at low luminance contrast, whereas the Enigma and Rotating Snakes illusions are stronger at low luminance contrast. At equiluminance along the L – M axis the strength of all illusions is greatly reduced. Data suggest that luminance contrast constitutes one important factor for their occurrence.},
  Doi                      = {10.1068/p7005},
  File                     = {Hamburger2012.pdf:Hamburger2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Hammett2007,
  Title                    = {Perceptual distortions of speed at low luminance: evidence inconsistent with a Bayesian account of speed encoding.},
  Author                   = {Hammett, Stephen T. AND Champion, R. A. AND Thompson, Peter G. AND Morland, Antony B.},
  Journal                  = {Vision Res.},
  Year                     = {2007},
  Pages                    = {564-568},
  Volume                   = {47},

  Doi                      = {10.1016/j.visres.2006.08.013},
  File                     = {Hammett2007.pdf:Hammett2007.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Harris1971,
  Title                    = {Monaural/Binaural Minimum Audible Angles for a moving sound source},
  Author                   = {Harris, J. D. AND Sergeant, R. L.},
  Journal                  = {Journal of Speech and Hearing Research},
  Year                     = {1971},
  Number                   = {3},
  Pages                    = {618-629},
  Volume                   = {14},

  Doi                      = {10.1044/jshr.1403.618},
  File                     = {Harris1971.pdf:Harris1971.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Hawken1994,
  Title                    = {Constrast dependence of colour and luminance motion mechanisms in human vision},
  Author                   = {Hawken, Michael J. AND Gegenfurtner, Karl R. AND Tang, Chao},
  Journal                  = {Nature},
  Year                     = {1994},
  Pages                    = {268-270},
  Volume                   = {367},

  Doi                      = {10.1038/367268a0},
  File                     = {Hawken1994.pdf:Hawken1994.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.15}
}

@Article{Hebrank1974,
  Title                    = {Spectral cues used in the localization of sound sources on the median plane.},
  Author                   = {Hebrank, Jack and Wright, D.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1974},
  Number                   = {6},
  Pages                    = {1829-1834},
  Volume                   = {56},

  Doi                      = {10.1121/1.1903520},
  File                     = {Hebrank1974.pdf:Hebrank1974.pdf:PDF},
  Keywords                 = {audio; azimuth; perception; localisation;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.24}
}

@Article{Hidaka2012,
  Title                    = {Sound can enhance the suppression of visual target detection in apparent motion trajectory},
  Author                   = {Hidaka, Souta and Teramoto, Wataru and Nagai, Masayoshi s},
  Journal                  = {Vision Res.},
  Year                     = {2012},
  Pages                    = {25–33},
  Volume                   = {59},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Detection performance is impaired for a visual target presented in an apparent motion (AM) trajectory, and this AM interference weakens when orientation information is inconsistent between the target and AM stimuli. These indicate that the target is perceptually suppressed by internal object representations of AM stimuli established along the AM trajectory. Here, we showed that transient sounds presented together with AM stimuli could enhance the magnitude of AM interference. Furthermore, this auditory effect attenuated when frequencies of the sounds were inconsistent during AM. We also confirmed that the sounds wholly elevated the magnitude of AM interference irrespective of the inconsistency in orientation information between the target and AM stimuli when the saliency of the sounds was maintained. These results suggest that sounds can contribute to the robust establishment and spatiotemporal maintenance of the internal object representation of an AM stimulus.},
  Doi                      = {10.1016/j.visres.2012.02.008},
  File                     = {Hidaka2012.pdf:Hidaka2012.pdf:PDF},
  Keywords                 = {Visual target detection; Transient sounds; Audio-visual interaction; Object representation; Apparent motion},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.20}
}

@Article{Hidaka2011,
  Title                    = {Auditory Motion Information Drives Visual Motion Perception},
  Author                   = {Hidaka, Souta and Teramoto, Wataru and Sugita, Yoichi and Manaka, Yuko and Suzuki, Yoiti},
  Journal                  = {PLOS ONE},
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {1-9},
  Volume                   = {6},

  Abstract                 = {Background: Vision provides the most salient information with regard to the stimulus motion. However, it has recently been demonstrated that static visual stimuli are perceived as moving laterally by alternating left-right sound sources. The underlying mechanism of this phenomenon remains unclear; it has not yet been determined whether auditory motion signals, rather than auditory positional signals, can directly contribute to visual motion perception.

Methodology/Principal Findings: Static visual flashes were presented at retinal locations outside the fovea together with a lateral auditory motion provided by a virtual stereo noise source smoothly shifting in the horizontal plane. The flash appeared to move by means of the auditory motion when the spatiotemporal position of the flashes was in the middle of the auditory motion trajectory. Furthermore, the lateral auditory motion altered visual motion perception in a global motion display where different localized motion signals of multiple visual stimuli were combined to produce a coherent visual motion perception.

Conclusions/Significance: These findings suggest there exist direct interactions between auditory and visual motion signals, and that there might be common neural substrates for auditory and visual motion processing.},
  Doi                      = {10.1371/journal.pone.0017499},
  File                     = {Hidaka2011.pdf:Hidaka2011.pdf:PDF},
  Keywords                 = {audiovisual; motion; source motion; azimuth; perception;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.03.01}
}

@Conference{Hirata1981,
  Title                    = {Optimum Reverberation Times of Monitor Rooms and Listening Rooms},
  Author                   = {Hirata, Yoshimutsu AND Matsudaira, T. K. AND Nakajima, H.},
  Booktitle                = {Audio Engineering Society Convention 68},
  Year                     = {1981},
  Month                    = {3},

  File                     = {Hirata1981.pdf:Hirata1981.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.07.21}
}

@Article{Ho2013,
  Title                    = {Role of audiovisual synchrony in driving head orienting responses},
  Author                   = {Ho, Cristy AND Gray, Rob AND Spence, Charles},
  Journal                  = {Experimental Brain Research},
  Year                     = {2013},
  Number                   = {4},
  Pages                    = {467-476},
  Volume                   = {227},

  Doi                      = {10.1007/s00221-013-3522-4},
  File                     = {Ho2013.pdf:Ho2013.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2013.07.01}
}

@Article{Hubel1961,
  Title                    = {Receptive fields, binocular interaction and functional architecture in cats visual cortex},
  Author                   = {Hubel, D. H. AND Wiesel, T. N.},
  Journal                  = {Journal of Physiology},
  Year                     = {1961},
  Number                   = {1},
  Pages                    = {106-154},
  Volume                   = {160},

  File                     = {Hubel1961.pdf:Hubel1961.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Hurlimann2002,
  Title                    = {Testing the bayesian model of perceived speed},
  Author                   = {Hürlimann, Felix AND Kiper, Daniel C. AND Carandini Matteo},
  Journal                  = {Vision Res.},
  Year                     = {2002},
  Number                   = {19},
  Pages                    = {2253-2257},
  Volume                   = {42},

  Doi                      = {10.1016/S0042-6989(02)00119-0},
  File                     = {Hurlimann2002.pdf:Hurlimann2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.02}
}

@Article{Hutchinson2013,
  Title                    = {Binocular summation of second-order global motion signals in human vision},
  Author                   = {Hutchinson, Claire V. AND Ledgeway, Tim AND Allen, Harriet A. AND Long, Mike D. AND Arena, Amanda},
  Journal                  = {Vision Research},
  Year                     = {2013},
  Pages                    = {16--25},
  Volume                   = {84},

  Doi                      = {10.1016/j.visres.2013.03.004},
  File                     = {Hutchinson2013.pdf:Hutchinson2013 - Binocular summation of second-order global motion signals in human vision.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.15}
}

@Article{Ingaard1953,
  Title                    = {A Review of the Influence of Meteorological Conditions on Sound Propagation},
  Author                   = {Ingård, Uno},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1953},
  Number                   = {3},
  Pages                    = {405-411},
  Volume                   = {25},

  Doi                      = {10.1121/1.1907055},
  File                     = {Ingaard1953.pdf:Ingaard1953.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.22}
}

@Article{Jaekl2012,
  Title                    = {Perceived size change induced by audiovisual temporal delays},
  Author                   = {Jaekl, Philip and Soto-Faraco, Salvador and Harris, Laurence R},
  Journal                  = {Experimental Brain Research},
  Year                     = {2012},
  Number                   = {3},
  Pages                    = {457-462},
  Volume                   = {216},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The retinal image of an object does not contain information about its actual size. Size must instead be inferred from extraretinal cues for which distance information makes an essential contribution. Asynchronies in the arrival time across visual and auditory sensory components of an audiovisual event can reliably cue its distance, although this cue has been largely neglected in vision research. Here we demonstrate that audio-visual asynchronies can produce a shift in the apparent size of an object and attribute this shift to a change in perceived distance. In the present study participants were asked to match the perceived size of a test circle paired with an asynchronous sound to a variable-size probe circle paired with a simultaneous sound. The perceived size of the circle increased when the sound followed its onset with delays up to around 100 ms. For longer sound delays and sound leads, no effect was seen. We attribute this selective modulation in perceived visual size to audiovisual timing influences on the intrinsic relationship between size and distance. This previously unsuspected cue to distance reveals a surprisingly interactive system using multisensory information for size/distance perception.},
  Doi                      = {10.1007/s00221-011-2948-9},
  File                     = {Jaekl2012.pdf:Jaekl2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@Article{Jeffress1948,
  Title                    = {A place theory of sound localization},
  Author                   = {Jeffress, L. A.},
  Journal                  = {Journal of Comparative and Physiological Psychology},
  Year                     = {1948},
  Number                   = {1},
  Pages                    = {35-39},
  Volume                   = {41},

  Doi                      = {10.1037/h0061495},
  File                     = {Jeffress1948.pdf:Jeffress1948.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01}
}

@Article{Jenison1992,
  Title                    = {Kinematic synthesis of auditory motion},
  Author                   = {Jenison, Rick L. AND Lutfi, Robert A.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1992},
  Number                   = {4},
  Pages                    = {2458-2459},
  Volume                   = {92},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {A technique is presented for headphone simulation of sounds moving in auditory space using the mathematics of kinematics, or mechanics of pure motion. Doppler shifts, as well as changes in interaural time delays and interaural intensity differences can be shown to have transformation invariant dependencies based on kinematics. For example, the Doppler effect represents a pattern of change that is invariant for a particular velocity and distance, and independent of the frequency and amplitude of the sound pressure waveform. In principle, these invariants intrinsic to the sound pressure wave of a moving object are available to the listener. The continuous kinematic approach differs from the more traditional approach of considering static localization cues strung together to reconstruct the dynamic event, and allows programmatic simulation of arbitrary acoustic trajectories through the environment. A series of experiments was designed to assess the sufficiency of synthesized kinematic information for simulating sounds moving in the horizontal plane. Subjects were asked to judge the trajectory and direction of a simulated moving sound under headphones using the combination of a visual display of the path and a pointing device. Results support the sufficiency of kinematic information in judging trajectory and direction. Furthermore, the variability of judgments was comparable to other studies of headphone simulation of static free‐field listening.},
  Doi                      = {10.1121/1.404502},
  File                     = {Jenison1992.pdf:Jenison1992.pdf:PDF},
  Owner                    = {mattberjon},
  Review                   = {The paper is not really available. Online, it is just a kind of meeting description telling where and when the paper should have been presented.},
  Timestamp                = {2012.09.21}
}

@Article{Kaczmarek2005,
  Title                    = {Auditory perception of sound source velocity},
  Author                   = {Kaczmarek, Tomasz},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {2005},
  Number                   = {5},
  Pages                    = {3149-3156},
  Volume                   = {117},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {In this study we investigate the perception of the velocity of linearly moving sound sources passing in front of a listener. The binaural simulation of motion used in two psychoacoustical experiments includes changes in the overall sound pressure level, the Doppler effect, and changes in interaural time differences. These changes are considered as cues for the perception of velocity. The present experiments are an extension of the experiments performed by Lutfi and Wang [J. Acoust. Soc. Am. 106, 919-928 (1999)]. The results of Experiment I show that the differential velocity threshold is independent of the reference velocity (10, 20, 30, and 40 m/s), varying across listeners from 1.5 to 4.6 m/s. In Experiment II, a method based on the successive elimination of cues in compared pairs of signals was employed to estimate the weights of potential cues for velocity discrimination. The magnitudes of all underlying cues at thresholds are reported. The experimental results show the subject's preference for the Doppler cue and a weakest sensitivity to the cue related with interaural time differences. Finally, it was found that spatial differences in the source location at the endpoints of the motion trajectory are not a significant factor in the velocity discrimination task.},
  Doi                      = {10.1121/1.1880832},
  File                     = {Kaczmarek2005.pdf:Kaczmarek2005.pdf:PDF},
  Journaltitle             = {Kpirnal of Acoustical Society of America}
}

@Conference{Kapralos2004,
  Title                    = {Auditory Cues in the Perception of Self Motion},
  Author                   = {Kapralos, Bill AND Zikovitz, Daniel AND Jenkin, Michael R.AND Harris, Laurence R.},
  Booktitle                = {Audio Engineering Society Convention 116},
  Year                     = {2004},
  Month                    = {5},

  Abstract                 = {Despite its potential importance, few studies have methodically examined the role of auditory cues to the perception of self-motion. Here we describe a series of experiments that investigate the relative roles of various combinations of physical motion and decreasing sound source intensity cues to the perception of linear self-motion. Self-motion was simulated using either (i) physical motion only, (ii) moving audio-cues only, (iii) decreasing intensity cues, and (iv) physical motion coupled with moving audio-cues. In all conditions an over-estimation of self-motion of measures that varied systematically with the simulated acceleration. Of particular interest was that audio cues combined with physical motion cues resulted in more accurate estimates of self-motion than did either audio or physical motion cues in isolation.},
  File                     = {Kapralos2004.pdf:Kapralos2004.pdf:PDF},
  Owner                    = {mattberjon},
  Review                   = {Not in the subject but has some good references to look at},
  Timestamp                = {2012.09.20}
}

@Book{Kernighan1999,
  Title                    = {The practice of programming},
  Author                   = {Kernighan, B. W. AND Pike, Rob},
  Editor                   = {Addison and Wesley},
  Publisher                = {Addison - Wesley},
  Year                     = {1999},
  Edition                  = {2nd edition},

  File                     = {Kernighan1999.pdf:Kernighan1999.pdf:PDF},
  Keywords                 = {programming; development; data structures; algorithms},
  Owner                    = {mattberjon},
  Timestamp                = {2016.10.14}
}

@Book{Kernighan1988,
  Title                    = {The C programming language},
  Author                   = {Kernighan, Brian W. AND Ritchie, Dennis M.},
  Editor                   = {Prentice Hall},
  Publisher                = {Prentice Hall},
  Year                     = {1988},
  Edition                  = {2nd edition},
  Month                    = {April},

  File                     = {Kernighan1988.pdf:Kernighan1988.pdf:PDF},
  Keywords                 = {dev; C}
}

@Article{Klein2001,
  Title                    = {Measuring, estimating, and understanding the psychometric function: A commentary},
  Author                   = {Klein, Stanley A.},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2001},
  Number                   = {8},
  Pages                    = {1421-1455},
  Volume                   = {63},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The psychometric function, relating the subject’s response to the physical stimulus, is fundamental to psychophysics. This paper examines various psychometric function topics, many inspired by this special symposium issue ofPerception & Psychophysics: What are the relative merits of objective yes/no versus forced choice tasks (including threshold variance)? What are the relative merits of adaptive versus constant stimuli methods? What are the relative merits of likelihood versus up-down staircase adaptive methods? Is 2AFC free of substantial bias? Is there no efficient adaptive method for objective yes/no tasks? Should adaptive methods aim for 90% correct? Can adding more responses to forced choice and objective yes/no tasks reduce the threshold variance? What is the best way to deal with lapses? How is the Weibull function intimately related to thed’ function? What causes bias in the likelihood goodness-of-fit? What causes bias in slope estimates from adaptive methods? How good are nonparametric methods for estimating psychometric function parameters? Of what value is the psychometric function slope? How are various psychometric functions related to each other? The resolution of many of these issues is surprising.},
  Doi                      = {10.3758/BF03194552},
  File                     = {Klein2001.pdf:Klein2001.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@MastersThesis{Knowles2010,
  Title                    = {Software Defined Hearing Aid},
  Author                   = {Knowles, Richard AND Vaz, David},
  School                   = {The College of New Jersey},
  Year                     = {2010},
  Month                    = {May},
  Type                     = {Bachelor degree},

  Doi                      = {http://engineering.pages.tcnj.edu/files/2012/02/FINALSP2REPORT-DVandRK.doc},
  File                     = {Knowles2010.pdf:Knowles2010.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Kochkin2010,
  Title                    = {MarkeTrak VIII: Consumer satisfaction with hearing aids is slowly increasing},
  Author                   = {Kochkin, Sergei},
  Journal                  = {The Hearing Journal},
  Year                     = {2010},

  Month                    = {January},
  Number                   = {1},
  Pages                    = {19-27},
  Volume                   = {63},

  File                     = {Kochkin2010.pdf:Kochkin2010.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Kochkin2000,
  Title                    = {MarkeTrak V: "Why my hearing aids are in the drawer": The consumers’ perspective},
  Author                   = {Kochkin, Sergei},
  Journal                  = {The Hearing Journal},
  Year                     = {2000},

  Month                    = {February},
  Number                   = {2},
  Pages                    = {34-41},
  Volume                   = {53},

  File                     = {Kochkin2000.pdf:Kochkin2000.pdf:PDF},
  Keywords                 = {ewo}
}

@Proceedings{Koehnke2000,
  Title                    = {Effect of distance on localization of complex stimuli},
  Year                     = {2000},
  Publisher                = {The Association for Research in Otolaryngology},

  Author                   = {Koehnke, Janet AND Besing, Joan},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27}
}

@Article{Koenigs2010,
  Title                    = {Localization of visual and auditory stimuli during smooth pursuit eye movements},
  Author                   = {Königs, Kerstin and Bremmer, Frank},
  Journal                  = {Journal of Vision},
  Year                     = {2010},
  Number                   = {8},
  Pages                    = {1-14},
  Volume                   = {10},

  Abstract                 = {Humans move their eyes more often than their heart beats. Although these eye movements induce large retinal image shifts, we perceive our world as stable. Yet, this perceptual stability is not complete. A number of studies have shown that visual targets which are briefly presented during such eye movements are mislocalized in a characteristic manner. It is largely unknown, however, if auditory stimuli are also mislocalized, i.e. whether or not perception generalizes across senses and space is represented supramodally. In our current study subjects were asked to localize brief visual and auditory stimuli that were presented during smooth pursuit in the dark. In addition, we measured auditory and visual detection thresholds. Confirming previous studies, perceived visual positions were shifted in direction of the pursuit. This shift was stronger for the hemifield the eye was heading towards (foveopetal). Perceptual auditory space was compressed towards the pursuit target (ventriloquism effect). This perceptual error was slightly reduced during pursuit as compared to fixation and differed clearly from the mislocalization of visual targets. While we found an influence of pursuit on localization, we found no such effect on the detection of visual and auditory stimuli. Taken together, our results do not provide evidence for the hypothesis of a supramodal representation of space during active oculomotor behavior.},
  Doi                      = {10.1167/10.8.8},
  File                     = {Koenigs2010.pdf:Koenigs2010.pdf:PDF},
  Keywords                 = {audiovisual; localisation; azimuth; perception; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.08}
}

@Book{Kroah-Hartman2006,
  Title                    = {Linux Kernel in a Nutshell},
  Author                   = {Kroah-Hartman, Greg},
  Editor                   = {O'Reilly Media},
  Publisher                = {O'Reilly Media},
  Year                     = {2006},
  Month                    = {December},

  File                     = {Kroah-Hartman2006.pdf:Kroah-Hartman2006.pdf:PDF}
}

@Article{Krukowski2003,
  Title                    = {Human discrimination of visual direction of motion with and without smooth pursuit eye movements},
  Author                   = {Krukowski, Anton E. AND Pirog, Kathleen A. AND Beutter, Brent R. AND Brooks, Kevin R. AND Stone, Leland S.},
  Journal                  = {Journal of Vision},
  Year                     = {2003},
  Number                   = {11},
  Pages                    = {831-840},
  Volume                   = {3},

  Doi                      = {10.1167/3.11.16},
  File                     = {Krukowski2003.pdf:Krukowski2003.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.08.16}
}

@Article{Krumbholz2005,
  Title                    = {Hierarchical processing of sound location and motion in the human brainstem and planum temporale},
  Author                   = {Krumbholz, Katrin AND Schönwiesner, Marc AND Rübsamen, Rudolf AND Zilles, Karl AND Fink, Gereon R. AND Cramon, D. Yves Von},
  Journal                  = {European Journal of Neuroscience},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {230-238},
  Volume                   = {21},

  Doi                      = {10.1111/j.1460-9568.2004.03836.x},
  File                     = {Krumbholz2005.pdf:Krumbholz2005.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01}
}

@Article{Kuhn1977,
  Title                    = {Model for the interaural time differences in the azimuthal plane},
  Author                   = {Kuhn, G. F.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1977},
  Number                   = {1},
  Pages                    = {157-167},
  Volume                   = {62},

  __markedentry            = {[mattberjon:]},
  Doi                      = {10.1121/1.381498},
  File                     = {Kuhn1977.pdf:Kuhn1977.pdf:PDF},
  Journaltitle             = {Journal of Acoustical Society of America}
}

@Article{Lambert1974,
  Title                    = {Dynamic theory of sound‐source localization},
  Author                   = {Lambert, Robert M.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1974},
  Number                   = {1},
  Pages                    = {165-171},
  Volume                   = {56},

  Doi                      = {10.1121/1.1903248},
  File                     = {Lambert1974.pdf:Lambert1974.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.27}
}

@Article{Langendijk2002,
  Title                    = {Contribution of spectral cues to human sound localization},
  Author                   = {Langendijk, Erno H. A. AND Bronkhorst, Adelbert W.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {1583-1596},
  Volume                   = {112},

  Doi                      = {10.1121/1.1501901},
  File                     = {Langendijk2002.pdf:Langendijk2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.13}
}

@Article{Lappin1975,
  Title                    = {Relation between time and space in visual-discrimination of velocity},
  Author                   = {Lappin, J. S. AND Bell, H. H. AND Harm, O. J. AND Kottas, B.},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1975},
  Number                   = {4},
  Pages                    = {383-394},
  Volume                   = {1},

  Doi                      = {10.1037/0096-1523.1.4.383},
  File                     = {Lappin1975.pdf:Lappin1975.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Book{Laroche1995,
  Title                    = {Traitement des singaux audio-fréquences},
  Author                   = {Jean Laroche},
  Publisher                = {Ecole Nationale Supérieure de Télécommunication},
  Year                     = {1995},

  File                     = {Laroche1995.pdf:Laroche1995.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.10}
}

@Article{Lee1975,
  Title                    = {Visual proprioceptive control of stance},
  Author                   = {Lee, D. and Lishman, R.},
  Journal                  = {J. Hum. Movmt Studies},
  Year                     = {1975},
  Pages                    = {87-95},
  Volume                   = {1},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Conducted 2 experiments with 24 undergraduates and 30 15-29 yr olds. Results show that vision functions proprioceptively as an integral component of the control system for maintaining a stance. In several stances, Ss' body sway could be controlled by moving their surroundings (i.e., by manipulating their visual proprioceptive information about body sway). A previous experiment had shown the same for toddlers. Results also show that visual proprioceptive information is generally more sensitive than mechanical proprioceptive information from the vestibular system and the ankles and feet and is yet more sensitive if the person is facing a nearby object. Consequently, vision normally improves balance in normal standing and especially in less practiced stances where ankle-foot proprioception is impoverished; indeed, if it is too impoverished, balance is dependent on visual proprioception. This suggests that, in learning a new stance, visual proprioception normally plays a lead role in tuning up ankle-foot proprioception and muscular control.},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.05}
}

@Conference{Lehnert1993,
  Title                    = {Auditory Spatial Impression},
  Author                   = {Lehnert, Hilmar},
  Booktitle                = {Audio Engineering Society Conference: 12th International Conference: The Perception of Reproduced Sound},
  Year                     = {1993},
  Month                    = {6},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The auditory event perceived by a human is not only determined by the sound signal emitted by the source, but also by a variety of environmental parameters. These parameters include not only characteristics of the sound source such as directivity, position, and orientation, but also the physical parameters of the room, namely geometrical and acoustical properties of surrounding surfaces. Whereas the characteristics of the sound source mainly affect perceptive attributes such as localization and timbre, the later properties cause perceptive effects often referred to as -spatial impression.- Auditory spatial impression can be defined as the concept of the type and size of an actual or simulated space at which a listener arrives spontaneously, when he/she is exposed to an appropriate sound field. Two main perceptive attributes of the auditive event contributing to the spatial impression can be identified. These are reverberance and auditory spaciousness.: In the presentation, some psychoacoustical fundamentals of listening in reflective environments aredescribed. An attempt is made to define the terms introduced above in a consistent manner. Some examples of physical properties of the sound field that influence these perceptive attributes are given and the effect of room reflections on distance perception is discussed.: A computer model for the simulation of listening in spaces is introduced. These kinds of computer models can serve as flexible tools for psychoacoustical experiments, since the acoustical environment can be controlled completely, is highly reproducible, and can be varied in a systematic manner. Results of some early psychoacoustical studies with this system are presented by comparing subjective simulations to real-room measurements. An attempt is made to identify physical properties of the environment that show an influence on auditory spatial impression.},
  File                     = {Lehnert1993.pdf:Lehnert1993.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@PhdThesis{Lepauloux2010,
  Title                    = {Prise de son distante par système multimicro-phone. Application à la communication parlée en environnement bruyant},
  Author                   = {Lepauloux, Ludovick},
  School                   = {Université de Rennes 1},
  Year                     = {2010},

  File                     = {Lepauloux2010.pdf:Lepauloux2010.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.10}
}

@Article{Leung2007,
  Title                    = {Compression of auditory space during rapid head turns},
  Author                   = {Leung, Johahn and Alais, David and Carlile, Simon},
  Journal                  = {Proceedings of the National Academy of Sciences of the United States of America},
  Year                     = {2007},
  Number                   = {17},
  Pages                    = {6492-6497},
  Volume                   = {105},

  Doi                      = {10.1073/pnas.0710837105},
  File                     = {Leung2007.pdf:Leung2007.pdf:PDF},
  Journaltitle             = {National Academy of Science of the USA},
  Keywords                 = {audio; head rotation; azimuth; perception; motion;}
}

@Book{Levitin2012,
  Title                    = {Introduction to The Design and Analysis of Algorithms},
  Author                   = {Levitin, Anany},
  Editor                   = {Pearson Education},
  Publisher                = {Pearson},
  Year                     = {2012},

  File                     = {Levitin2012.pdf:Levitin2012.pdf:PDF},
  Keywords                 = {development; data structures; algorithms},
  Owner                    = {mattberjon},
  Timestamp                = {2016.10.14}
}

@Article{Lewald2006,
  Title                    = {Horizontal and vertical effects of eye-position on sound localization},
  Author                   = {Lewald, Jörg. and Getzmann, Stephan},
  Journal                  = {Hearing Research},
  Year                     = {2006},
  Number                   = {1-2},
  Pages                    = {99-106},
  Volume                   = {213},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The effect of gaze direction on the localization of sound sources was investigated in the azimuthal and elevational dimension using a pointing task. In both dimensions, eccentric eye-position induced a significant shift in sound localization that was opposite to the direction of eccentricity. This finding is in accordance with the view that the azimuthal and elevational components of the auditory spatial information are processed in common neural substrates.},
  Doi                      = {10.1016/j.heares.2006.01.001},
  File                     = {Lewald2006.pdf:Lewald2006.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{Lewald2001,
  Title                    = {Sound lateralization during passive whole-body rotation},
  Author                   = {Lewald, Jörg and Karnath, Hans-Otto},
  Journal                  = {European Journal of Neuroscience},
  Year                     = {2001},
  Number                   = {12},
  Pages                    = {2268-2272},
  Volume                   = {13},

  Abstract                 = {The effect of passive whole-body rotation about the earth-vertical axis on the lateralization of dichotic sound was investigated in human subjects. Pure-tone pulses (1 kHz; 0.1 s duration) with various interaural time differences were presented via headphones during brief, low-amplitude rotation (angular acceleration 400°/s2; maximum velocity 90°/s; maximum displacement 194°). Subjects made two-alternative forced-choice (left/right) judgements on the acoustic stimuli. The auditory median plane of the head was shifted opposite to the direction of rotation, indicating a shift of the intracranial auditory percept in the direction of rotation. The mean magnitude of the shift was 10.7 µs. This result demonstrates a slight, but significant, influence of rotation on sound lateralization, suggesting that vestibular information is taken into account by the brain for accurate localization of stationary sound sources during natural head and body motion.},
  Doi                      = {10.1046/j.0953-816x.2001.01608.x},
  File                     = {Lewald2001.pdf:Lewald2001.pdf:PDF},
  Journaltitle             = {European Journal of Neuroscience},
  Keywords                 = {head motion: motion; audio; azimuth; perception;}
}

@Article{Lewis2000,
  Title                    = {A Comparison of Visual and Auditory Motion Processing in Human Cerebral Cortex},
  Author                   = {Lewis, James W. and Beauchamp, Michael S. and DeYoe, Edgar A.},
  Journal                  = {Cerebral Cortex},
  Year                     = {2000},
  Number                   = {9},
  Pages                    = {873-888},
  Volume                   = {10},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Visual and auditory motion information can be used together to provide complementary information about the movement of objects. To investigate the neural substrates of such cross-modal integration, functional magnetic resonance imaging was used to assess brain activation while subjects performed separate visual and auditory motion discrimination tasks. Areas of unimodal activation included the primary and/or early sensory cortex for each modality plus additional sites extending toward parietal cortex. Areas conjointly activated by both tasks included lateral parietal cortex, lateral frontal cortex, anterior midline and anterior insular cortex. The parietal site encompassed distinct, but partially overlapping, zones of activation in or near the intraparietal sulcus (IPS). A subsequent task requiring an explicit cross-modal speed comparison revealed several foci of enhanced activity relative to the unimodal tasks. These included the IPS, anterior midline, and anterior insula but not frontal cortex. During the unimodal auditory motion task, portions of the dorsal visual motion system showed signals depressed below resting baseline. Thus, interactions between the two systems involved either enhancement or suppression depending on the stimuli present and the nature of the perceptual task. Together, these results identify human cortical regions involved in polysensory integration and the attentional selection of cross-modal motion information.},
  Doi                      = {10.1093/cercor/10.9.873},
  File                     = {Lewis2000.pdf:Lewis2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.30}
}

@Book{Linden1994,
  Title                    = {Expert C programming: Deep secrets},
  Author                   = {van der Linden, Peter},
  Editor                   = {Prentice Hall},
  Publisher                = {Prentice Hall},
  Year                     = {1994},

  File                     = {Linden1994.pdf:Linden1994.pdf:PDF},
  Keywords                 = {programming; C;}
}

@Article{Loomis2005,
  Title                    = {Personal guidance system for people with visual impairment: a comparison of spatial displays for route guidance},
  Author                   = {Loomis, J. M. AND Marston, J. R. AND Golledge, R. G. AND Klatzky, R. L.},
  Journal                  = {Journal of Visual Impairment and Blindness},
  Year                     = {2005},
  Number                   = {4},
  Pages                    = {219-32},
  Volume                   = {99},

  File                     = {Loomis2005.pdf:Loomis2005.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.04.22}
}

@Article{Lutfi1999,
  Title                    = {Correlational analysis of acoustic cues for the discrimination of auditory motion},
  Author                   = {Lutfi, Robert A. and Wang, Wen},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1999},
  Number                   = {2},
  Pages                    = {919-928},
  Volume                   = {106},

  Abstract                 = {The sound of a source moving in a straight path and passing directly in front of the listener on the azimuthal plane was synthesized over headphones to include three dynamic cues for motion: Doppler effect, overall intensity, and interaural time difference. Discriminability of a change in displacement, velocity, and acceleration of this source was measured using a standard two-interval, forced-choice procedure. In each case, the relative reliance or weight given to the three acoustic cues was estimated from correlations of the listener’s response with small independent perturbations imposed on cues from trial to trial. Group estimates of threshold agreed well with results from past studies, while the obtained pattern of weights depended on the individual, starting velocity, and discrimination task. For the discrimination of displacement at moderate velocity (10 m/s), responses were most highly correlated with intensity or interaural time difference. For the discrimination of velocity and, to a lesser extent, acceleration, responses were most highly correlated with Doppler effect. At higher velocity (50 m/s) responses in all discrimination tasks were most strongly correlated with Doppler effect with few exceptions. Randomizing source spectrum or roving distance of the source from trial to trial did not significantly affect the pattern of results. The results suggest that motion perception is mutable, and not in all cases based on a single invariant acoustic cue.},
  Doi                      = {10.1121/1.428033},
  File                     = {Lutfi1999.pdf:Lutfi1999.pdf:PDF},
  Journaltitle             = {Journal of Acoustical Society of America},
  Keywords                 = {motion; audio; source motion; azimuth; perception;}
}

@Manual{Machanick1994,
  Title                    = {C and C++ in 5 days},
  Author                   = {Machanick, Philip},
  Organization             = {University of the Witwatersrand},
  Year                     = {1994},

  File                     = {Machanick1994.pdf:Machanick1994.pdf:PDF}
}

@MastersThesis{Mackensen2004,
  Title                    = {Auditive Localization. Head movements, an additional cue in Localization},
  Author                   = {Mackensen, Philip},
  School                   = {Technischen Universität Berlin},
  Year                     = {2004},

  File                     = {Mackensen2004.pdf:Mackensen2004.pdf:PDF},
  Keywords                 = {audio; head motion; localisation; azimuth; elevation; perception;}
}

@Conference{Macpherson2009,
  Title                    = {Stimulus continuity is not necessary for the salience of dynamic sound localization cues},
  Author                   = {Macpherson, Erwan A.},
  Booktitle                = {157th meeting of the ASA},
  Year                     = {2009},

  Address                  = {Portland, OR, USA},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08}
}

@Conference{Macpherson2008,
  Title                    = {The salience of dynamic sound localization cues as a function of head velocity and stimulus frequency},
  Author                   = {Macpherson, Erwan A. AND Kerr, D.},
  Booktitle                = {APCAM, Auditory Perception Cognition and Action Meeting},
  Year                     = {2008},

  Address                  = {Chicago, IL, USA},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.07}
}

@Article{Macpherson2002,
  Title                    = {Listener weighting of cues for lateral angle: The duplex theory of sound localization revisited},
  Author                   = {Macpherson, Ewan A. and Middlebrooks, John C.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {2002},
  Number                   = {5},
  Pages                    = {2219-2236},
  Volume                   = {111},

  Abstract                 = {The virtual auditory space technique was used to quantify the relative strengths of interaural time difference (ITD), interaural level difference (ILD), and spectral cues in determining the perceived lateral angle of wideband, low-pass, and high-pass noise bursts. Listeners reported the apparent locations of virtual targets that were presented over headphones and filtered with listeners’ own directional transfer functions. The stimuli were manipulated by delaying or attenuating the signal to one ear (by up to 600 μs or 20 dB) or by altering the spectral cues at one or both ears. Listener weighting of the manipulated cues was determined by examining the resulting localization response biases. In accordance with the Duplex Theory defined for pure-tones, listeners gave high weight to ITD and low weight to ILD for low-pass stimuli, and high weight to ILD for high-pass stimuli. Most (but not all) listeners gave low weight to ITD for high-pass stimuli. This weight could be increased by amplitude-modulating the stimuli or reduced by lengthening stimulus onsets. For wideband stimuli, the ITD weight was greater than or equal to that given to ILD. Manipulations of monaural spectral cues and the interaural level spectrum had little influence on lateral angle judgements.},
  Doi                      = {10.1121/1.1471898},
  File                     = {Macpherson2002.pdf:Macpherson2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.30}
}

@Article{Magezi2013,
  Title                    = {Electrical neuroimaging during auditory motion aftereffects reveals that auditory motion processing is motion sensitive but not direction selective},
  Author                   = {Magezi, David A. AND Buetler, Karin A. AND Chouiter, Leila AND Annoni, Jean-Marie AND Spierer, Lucas},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {321-331},
  Volume                   = {109},

  Doi                      = {10.​1152/​jn.​00625.​2012},
  File                     = {Magezi2013.pdf:Magezi2013.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01}
}

@Article{Malmierca2005,
  Title                    = {The Inferior Colliculus: A Center for Convergence of Ascending and Descending Auditory Information},
  Author                   = {Malmierca, Manuel S.},
  Journal                  = {Neuroembryology and Aging},
  Year                     = {2005},
  Number                   = {4},
  Pages                    = {215-229},
  Volume                   = {3},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {A major goal in auditory research is to understand completely how we hear, the physiology of the human auditory system and to identify the causes and treatments for hearing impairment. By understanding all the elements of the ‘auditory scaffold’ we will begin to achieve these important goals. The inferior colliculus (IC) occupies a strategic position in the central auditory system and may be considered a central hub or an interface between the lower auditory pathway, the auditory cortex and motor systems. The IC is the site for termination of the ascending fibers of the lateral lemniscus and also receives a heavy innervation from the auditory cortex. Furthermore, the IC receives crossed projections from its counterpart and possesses a dense network of local connections. Thus, the IC is the main site of auditory integration at the midbrain level. Anatomical and physiological experiments demonstrate that the IC is involved in a great diversity of functional roles in the auditory system, and that most of the interesting auditory features might already be extracted from incoming sounds by this midbrain nucleus.},
  Doi                      = {10.1159/000096799},
  File                     = {Malmierca2005.pdf:Malmierca2005.pdf:PDF},
  Keywords                 = {Auditory midbrain; Hearing; Inferior colliculus; Laminar organization; Tonotopic organization},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Mamassian2005,
  Title                    = {Auditory tones influence perceived speed in apparent motion},
  Author                   = {Mamassian, Pascal},
  Journal                  = {Journal of Vision},
  Year                     = {2005},
  Number                   = {8},
  Pages                    = {877},
  Volume                   = {5},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Several cross-modal studies show an interaction when two modalities provide converging evidence for a given attribute, for instance an estimate of spatial location in the ventriloquist effect. Which modality dominates depends on the reliability of each modality for that particular attribute. For a stimulus that varies across both space and time, we therefore anticipate that vision will have a predominant role over its spatial properties and audition a predominant role over its temporal properties. We tested this prediction on the perceived speed of an apparent motion display in presence of fluttering tones. We hypothesized that the temporal frequency of the auditory signal could influence the perceived temporal frequency of the visual display, and in turn affect its perceived speed. Visual stimuli were two Gabors presented on either side of the fixation cross, moving in opposite directions (either inwards or outwards). The spatial envelope stayed stationary and the motion was produced by shifting the carrier's phase by 90deg at a rate of 19Hz. This visual display was presented simultaneously with a fluttering sequence of tones at a rate of 16 or 22Hz. Observers had to decide whether this bimodal stimulus appeared to move faster or slower than a purely visual stimulus whose phase was varied between trials. The point of subjective equality was taken as a measure of the perceived speed of the bimodal stimulus. The rate of the auditory tones influenced the perceived speed of the visual display: the slow auditory rate slowed down the perceived speed, and the fast rate accelerated it. These results suggest that the integration between auditory and visual temporal signals occurs before the estimation of speed.},
  Doi                      = {10.1167/5.8.877},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@Article{Manfredi2015a,
  Title                    = {Voice analysis: Technological and clinical research together again},
  Author                   = {Manfredi, Claudia},
  Journal                  = {Biomedical Signal Processing and Control},
  Year                     = {2015},

  Month                    = {March},
  Pages                    = {1-2},
  Volume                   = {17},

  Doi                      = {10.1016/j.bspc.2015.02.004},
  File                     = {Manfredi2015a.pdf:Manfredi2015a.pdf:PDF}
}

@Article{Manfredi2015,
  Title                    = {Automatic Assessment of Acoustic Parameters of the Singing Voice: Application to Professional Western Operatic and Jazz Singers},
  Author                   = {Manfredi, Claudia AND Barbagallo, Davide AND Baracca, Giovanna AND Orlandi, Silvia AND Bandini, Andrea AND Dejonckere, Philippe H.},
  Journal                  = {Journal of Voice},
  Year                     = {2015},

  Month                    = {July},
  Number                   = {4},
  Pages                    = {517},
  Volume                   = {29},

  Doi                      = {10.1016/j.jvoice.2014.09.014},
  File                     = {Manfredi2015.pdf:Manfredi2015.pdf:PDF}
}

@Book{Marat1792,
  Title                    = {L'ami du peuple},
  Author                   = {Marat, Jean-Paul},
  Publisher                = {Groupe international de lecteur veramente},
  Year                     = {1792},

  File                     = {Marat1792.pdf:Marat1792.pdf:PDF},
  Keywords                 = {philosophy}
}

@Article{McBeath2002,
  Title                    = {The Doppler effect is not what you think it is: dramatic pitch change due to dynamic intensity change},
  Author                   = {McBeath, M.K and Neuhoff, J.G},
  Journal                  = {Psychon. Bull Rev},
  Year                     = {2002},
  Pages                    = {306-313},
  Volume                   = {9},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.12}
}

@Article{Mehrgardt1977,
  Title                    = {Transformation characteristics of the external human ear},
  Author                   = {Mehrgardt, S. AND Mellert, V.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1977},
  Number                   = {6},
  Pages                    = {1567-1576},
  Volume                   = {61},

  Doi                      = {10.1121/1.381470},
  File                     = {Mehrgardt1977.pdf:Mehrgardt1977.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.04.19}
}

@Article{Melcher2012,
  Title                    = {Remapping of the line motion illusion across eye movements},
  Author                   = {Melcher, David and Fracasso, Alessio},
  Journal                  = {Experimental Brain Research},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {503-514},
  Volume                   = {218},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Although motion processing in the brain has been classically studied in terms of retinotopically defined receptive fields, recent evidence suggests that motion perception can occur in a spatiotopic reference frame. We investigated the underlying mechanisms of spatiotopic motion perception by examining the role of saccade metrics as well as the capacity of trans-saccadic motion. To this end, we used the line motion illusion (LMI), in which a straight line briefly shown after a high contrast stimulus (inducer) is perceived as expanding away from the inducer position. This illusion provides an interesting test of spatiotopic motion because the neural correlates of this phenomenon have been found early in the visual cortex and the effect does not require focused attention. We measured the strength of LMI both with stable fixation and when participants were asked to perform a 10° saccade during the blank ISI between the inducer and the line. A strong motion illusion was found across saccades in spatiotopic coordinates. When the inducer was presented near in time to the saccade cue, saccadic latencies were longer, saccade amplitudes were shorter, and the strength of reported LMI was consistently reduced. We also measured the capacity of the trans-saccadic LMI by varying the number of inducers. In contrast to a visual-spatial memory task, we found that the LMI was largely eliminated by saccades when two or more inducers were displayed. Together, these results suggest that motion perceived in non-retinotopic coordinates depends on an active, saccade-dependent remapping process with a strictly limited capacity.},
  Doi                      = {10.1007/s00221-012-3043-6},
  Owner                    = {mattberjon},
  Timestamp                = {2012.05.09}
}

@Article{Mergner1991,
  Title                    = {Human perception of horizontal trunk and head rotation in space during vestibular and neck stimulation},
  Author                   = {Mergner, T. and Siebold, C. and Schweigart, G. and Becker, W.},
  Journal                  = {Experimental Brain Research},
  Year                     = {1991},
  Pages                    = {389-404},
  Volume                   = {85},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The vestibular signal of head motion in space must be complemented by a neck signal of the trunk-to-head excursion in order to provide the individual with information on trunk motion in space. This consideration led us to study psychophysically the role of vestibular-neck interaction for human self-motion perception. Subjects (Ss) were presented with passive horizontal rotations of their trunk and/or head (sinusoidal rotations, f = 0.025-0.4 Hz) in the dark for vestibular and neck stimulation, as well as for combinations of both. Ss' perception was evaluated in terms of gain (veridical perception of stimulus magnitude, G = 1), phase, and detection threshold. (1) Perception of trunk rotation in space. During vestibular stimulation (whole-body rotation) and neck stimulation (trunk rotation with the head kept stationary) the frequency-transfer characteristics underlying this perception were very similar. The gain fell short; it was only about 0.7 at 0.4 and 0.2 Hz stimulus frequency and was further attenuated with decreasing frequency. In contrast, the phase was close to that of actual trunk position. The gain attenuation was found to be a function of the peak angular velocity of the stimulus, a fact, which we related to a 'velocity threshold' of the order of 1 deg/s. During the various vestibular-neck combinations used, Ss' perception was again erroneous, reflecting essentially the sum of its two non-ideal constituents. However, there was one noticeable exception; during the combination 'head rotation on stationary trunk', Ss veridically perceived their trunk as stationary (compatible with the notion that the sum yielded 'zero'). (2) Perception of head rotation in space. During vestibular stimulation, Ss' estimates showed the same non-ideal gain-vs.-frequency characteristics as described above for the trunk. Neck stimulation induced an illusion as if the head had been rotated in space. This neck contribution was such that, when it was combined with its vestibular counterpart during head rotation on stationary trunk, the perception became almost veridical. On closer inspection, however, this neck contribution was found to reflect the sum of two components; one was the non-ideal neck signal contributing to the perception of 'trunk in space', the other was an almost ideal neck signal of head-on-trunk rotation. (3) The results could be described by a simple model. In this model, the erroneous vestibular signal 'head in space' is primarily used to create an internal representation of 'trunk in space'. To this end, it is combined with the closely matching neck signal of 'trunk to head'. The perception of head rotation in space is achieved by summing this 'trunk in space' signal with the almost ideal 'head on trunk' signal, again of nuchal origin. These seeming complex interactions have two implications: (i) the head is referred to trunk coordinates, whereas the trunk is referred to space coordinates; (ii) there is at least one condition in the dark where orientation is correct (despite an erroneous vestibular signal), i.e., during head rotation on stationary trunk.},
  File                     = {Mergner1991.pdf:unsort/Mergner1991.pdf:PDF},
  Journaltitle             = {Experimental Brain Research}
}

@Article{Meyer2001,
  Title                    = {Cross-modal integration of auditory and visual motion signals},
  Author                   = {Meyer, GF and Wuerger, SM},
  Journal                  = {Neuroreport},
  Year                     = {2001},
  Number                   = {9},
  Pages                    = {2557-2560},
  Volume                   = {12},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Real-world moving objects are usually defined by correlated information in multiple sensory modalities such as vision and hearing. The aim of our study was to assess whether simultaneous auditory supra-threshold motion introduces a bias or affects the sensitivity in a visual motion detection task. We demonstrate a bias in the perceived direction of visual motion that is consistent with the direction of the auditory motion (audio-visual motion capture). This bias effect is robust and occurs even if the auditory and visual motion signals come from different locations or move at different speeds. We also show that visual motion detection thresholds are higher for consistent auditory motion than for inconsistent motion, provided the stimuli move at the same speed and are colocalised.},
  Doi                      = {10.1097/00001756-200108080-00053},
  File                     = {Meyer2001.pdf:Meyer2001.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@Article{Meyer2005,
  Title                    = {Low-level integration of auditory and visual motion signals requires spatial co-localisation},
  Author                   = {Meyer, Georg F AND Wuerger, Sophie M. AND Röhrbein, Florian AND Zetzsche, Christoph},
  Journal                  = {Experimental Brain Research},
  Year                     = {2005},
  Number                   = {3-4},
  Pages                    = {538-547},
  Volume                   = {166},

  Doi                      = {10.1007/s00221-005-2394-7},
  File                     = {Meyer2005.pdf:Meyer2005.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.11}
}

@Article{Middlebrooks1991,
  Title                    = {Sound localization by human listeners},
  Author                   = {Middlebrooks, John C. and Green, David M.},
  Journal                  = {Annu. Rev. Psychol.},
  Year                     = {1991},
  Pages                    = {135-159},
  Volume                   = {42},

  Doi                      = {10.1146/annurev.psych.42.1.135},
  File                     = {Middlebrooks1991.pdf:Middlebrooks1991.pdf:PDF},
  Keywords                 = {audio; localisation; azimuth; elevation; perception;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{Mills1958,
  Title                    = {On the minimum audible angle},
  Author                   = {Mills, A. W.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1958},
  Number                   = {4},
  Pages                    = {237-246},
  Volume                   = {30},

  Abstract                 = {The difference limen for the azimuth of a source of pure tones was measured as a function of the frequency of the tone and the direction of the source. Tone pulses between 250 and 10 000 cps were sounded in the horizontal plane around the head of a subject seated in an anechoic chamber. The smallest angular separation that can be detected between the sources of two successive tone pulses (the minimum audible angle) was determined for each of three subjects. These threshold angles are analyzed in terms of the corresponding threshold changes in the phase, time, and intensity of the tone at the ears of the subject. A comparison of these thresholds with those reported for dichotic stimulation indicates that the resolution of the direction of a source is determined, at frequencies below about 1400 cps, by interaural differences in phase or time, and at higher frequencies by differences in intensity. When the conditions are optimal for temporal discrimination, the threshold for an interaural difference in time is about 10μsec, and when the conditions are optimal for intensity discrimination, the threshold for an interaural difference in intensity is about 0.5 db.},
  Doi                      = {10.1121/1.1909553},
  File                     = {Mills1958.pdf:Mills1958.pdf:PDF},
  Journaltitle             = {Journal of Acoustical Society of America},
  Keywords                 = {localisation; audio; azimuth; perception;}
}

@Article{Moore1986,
  Title                    = {A Comparison of Two-Channel and Single-Channel Compression},
  Author                   = {Moore, Brian C.J. AND Glasberg, Brian R.},
  Journal                  = {Audiology},
  Year                     = {1986},

  Month                    = {April},
  Number                   = {4-5},
  Pages                    = {210-226},
  Volume                   = {25},

  Doi                      = {10.3109/00206098609078387},
  File                     = {Moore1986.pdf:Moore1986.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Moore1983,
  Title                    = {Suggested formulae for calculating auditory-filter bandwidths and excitation patterns},
  Author                   = {Moore, B. C. J. AND Glasberg, B. R.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1983},
  Number                   = {3},
  Pages                    = {750-753},
  Volume                   = {74},

  Doi                      = {10.1121/1.389861},
  File                     = {Moore1983.pdf:Moore1983.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.24}
}

@Conference{Moore2008,
  Title                    = {Exploiting human spatial resolution in surround sound decoder design},
  Author                   = {Moore, David AND Wakefield, Jonathan},
  Booktitle                = {Audio Engineering Society Convention 125},
  Year                     = {2008},
  Month                    = {10},

  File                     = {Moore2008.pdf:Moore2008.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.08}
}

@Article{Nakamura2013,
  Title                    = {Effects of dynamic luminance modulation on visually induced self-motion perception: Observers’ perception of illumination is important in perceiving self-motion},
  Author                   = {Nakamura, Shinji AND Seno, Takeharu AND Ito, Hiroyuki AND Sunaga, Shoji},
  Journal                  = {Perception},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {153 - 162},
  Volume                   = {42},

  Doi                      = {10.1068/p7321},
  File                     = {Nakamura2013.pdf:Nakamura2013.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.15}
}

@Article{Nakayama1984,
  Title                    = {Biological image motion processing: A review},
  Author                   = {Nakayama, Ken},
  Journal                  = {Vision Res.},
  Year                     = {1984},
  Number                   = {5},
  Pages                    = {625-660},
  Volume                   = {25},

  Doi                      = {10.1016/0042-6989(85)90171-3},
  File                     = {Nakayama1984.pdf:Nakayama1984.pdf:PDF},
  Keywords                 = {vision; motion; source motion; azimuth; elevation; perception; neuroscience; review; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.24}
}

@Article{Neuhoff2001,
  Title                    = {An adaptive bias in the perception of looming auditory motion},
  Author                   = {Neuhoff, JG},
  Journal                  = {Ecological Psychology},
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {87-110},
  Volume                   = {13},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Rising acoustic intensity can indicate movement of a sound source toward a listener. Perceptual overestimation of intensity change could provide a selective advantage by indicating that the source is closer than it actually is, providing a better opportunity for the listener to prepare for the source's arrival. In Experiment 1, listeners heard equivalent rising and falling level sounds and indicated whether one demonstrated a greater change in loudness than the other. In 2 subsequent experiments listeners heard equivalent approaching and receding sounds and indicated perceived starting and stopping points of the auditory motion. Results indicate that rising intensity changed in loudness more than equivalent falling intensity, and approaching sounds were perceived as starting and stopping closer than equidistant receding sounds. Both effects were greater for tones than for noise, Evidence is presented that suggests that an asymmetry in the neural coding of egocentric auditory motion is an adaptation that provides advanced warning of looming acoustic sources.},
  Doi                      = {10.1207/S15326969ECO1302_2},
  File                     = {Neuhoff2001.pdf:Neuhoff2001.pdf:PDF},
  Keywords                 = {DORSAL COCHLEAR NUCLEUS; DIRECTION SENSITIVITY; AMPLITUDE-MODULATION; DISTANCE PERCEPTION; INFERIOR COLLICULUS; SIGNAL BANDWIDTH; NARROW-BAND; PURE-TONES; LOCALIZATION; FREQUENCY},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Neuhoff1998,
  Title                    = {Perceptual bias in rising tones},
  Author                   = {Neuhoff, J.},
  Journal                  = {Nature},
  Year                     = {1998},
  Pages                    = {123-124},
  Volume                   = {395},

  __markedentry            = {[mattberjon:]},
  File                     = {Neuhoff1998.pdf:Neuhoff1998.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@InBook{Neuhoff2004,
  Title                    = {Ecological Psychoacoustics},
  Author                   = {Neuhoff, John G.},
  Chapter                  = {Auditory motion and localization},
  Editor                   = {illustrated},
  Pages                    = {89-106},
  Publisher                = {Elsevier Academic press},
  Year                     = {2004},

  __markedentry            = {[mattberjon:]},
  Language                 = {en},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.22},
  Url                      = {http://www.amazon.com/Ecological-Psychoacoustics-John-G-Neuhoff/dp/0125158513?tag=duckduckgo-d-20#reader_0125158513}
}

@Article{Neuhoff2009,
  Title                    = {Adaptive sex differences in auditory motion perception: Looming sounds are special},
  Author                   = {Neuhoff, John G. and Planisek, Rianna and Seifritz, Erich},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {2009},
  Number                   = {1},
  Pages                    = {225-234},
  Volume                   = {35},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {In 4 experiments, the authors examined sex differences in audiospatial perception of sounds that moved toward and away from the listener. Experiment 1 showed that both men and women underestimated the time-to-arrival of full-cue looming sounds. However, this perceptual bias was significantly stronger among women than among men. In Experiment 2, listeners estimated the terminal distance of sounds that approached but stopped before reaching them. Women perceived the looming sounds as closer than did men. However, in Experiment 3, with greater statistical power, the authors found no sex difference in the perceived distance of sounds that traveled away from the listener, demonstrating a sex-based specificity for auditory looming perception. Experiment 4 confirmed these results using equidistant looming and receding sounds. The findings suggest that sex differences in auditory looming perception are not due to general differences in audiospatial ability, but rather illustrate the environmental salience and evolutionary importance of perceiving looming objects.},
  Doi                      = {10.1037/a0013159},
  File                     = {Neuhoff2009.pdf:Neuhoff2009.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{OConnor2010,
  Title                    = {Age, eye movement and motion discrimination},
  Author                   = {O'Connor, Emer AND Margrain, Tom H. AND Freeman, Tom C. A.},
  Journal                  = {Vision Res.},
  Year                     = {2010},
  Number                   = {23},
  Pages                    = {2588-2599},
  Volume                   = {50},

  Doi                      = {10.1016/j.visres.2010.08.015},
  File                     = {OConnor2010.pdf:OConnor2010.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.31}
}

@Book{Paker2002,
  Title                    = {Low power digital signal processing},
  Author                   = {Paker, Özgün},
  Year                     = {2002},
  Month                    = {June},

  File                     = {Paker2002.pdf:Paker2002.pdf:PDF},
  Keywords                 = {ewo; hardware},
  School                   = {Technical University of Danemark},
  Url                      = {http://orbit.dtu.dk/fedora/objects/orbit:83355/datastreams/file_5266238/content}
}

@Book{Palmer1999,
  Title                    = {Vision Science: Photons to Phenomenology},
  Author                   = {Palmer, S.E.},
  Publisher                = {MIT Press},
  Year                     = {1999},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.13}
}

@Conference{Parks2011,
  Title                    = {The effect of head movement on perceived listener envelopment and apparent source width},
  Author                   = {Parks, Anthony and Braasch, Jonas},
  Booktitle                = {Audio Engineering Society Convention 131},
  Year                     = {2011},
  Month                    = {10},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {This study investigates the effect of head movement in the evaluation of LEV and ASW under 15 different concert hall conditions simulated over eight loudspeakers using Virtual Microphone Control. The conditions consist of varying ratios of front-to-back energy and varying levels of cross-correlated reverberant energy. Head movements are monitored in terms of angular rotation using a head tracker while listeners are prompted to assign subjective ratings of LEV and ASW. The tests are repeated while listeners are asked to keep their heads fixed. Head movements are analysed and results of the tests are compared.},
  File                     = {Parks2011.pdf:Parks2011.pdf:PDF},
  Journal                  = {Journal of Audio Engineering Society},
  Owner                    = {mattberjon},
  Timestamp                = {2012.01.19}
}

@Article{Pastore2011,
  Title                    = {Magnitude judgments of loudness change for discrete, dynamic, and hybrid stimuli},
  Author                   = {Pastore, Richard E. AND Flint, Jesse},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {886-907},
  Volume                   = {73},

  Abstract                 = {Recent investigations of loudness change within stimuli have identified differences as a function of direction of change and power range (e.g., Canévet, Acustica, 62, 2136–2142, 1986; Neuhoff, Nature, 395, 123–124, 1998), with claims of differences between dynamic and static stimuli. Experiment 1 provides the needed direct empirical evaluation of loudness change across static, dynamic, and hybrid stimuli. Consistent with recent findings for dynamic stimuli, quantitative and qualitative differences in pattern of loudness change were found as a function of power change direction. With identical patterns of loudness change, only quantitative differences were found across stimulus type. In Experiment 2, Points of Subjective loudness Equality (PSE) provided additional information about loudness judgments for the static and dynamic stimuli. Because the quantitative differences across stimulus type exceed the magnitude that could be expected based upon temporal integration by the auditory system, other factors need to be, and are, considered.},
  Doi                      = {10.3758/s13414-010-0056-8},
  File                     = {Pastore2011.pdf:Pastore2011.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.20}
}

@Article{Perrett1997,
  Title                    = {The effect of head rotations on vertical plane sound localization},
  Author                   = {Perrett, Stephen and Noble, William},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1997},
  Number                   = {4},
  Pages                    = {2325-2332},
  Volume                   = {102},

  Abstract                 = {Current understanding gives predominant weight to stationary cues for auditory localization. Two experiments were conducted to investigate the possible existence of a dynamic cue. The first experiment involved localization of concealed sources in the upper median vertical plane (MVP) and showed, as expected, that elevation was not detectable with motionless listening when high-frequency energy was absent or when normal pinna function was distorted. Elevation under such conditions did become detectable with horizontal head rotations, provided low-frequency energy was present in the signal. This indicates that the basis of the dynamic cue is variation in the rate of transformation of low-frequency interaural time/phase differences. The second experiment involved localization of sources arrayed throughout upper and lower regions of the MVP and in the left lateral vertical plane (LVP); it showed that upper hemisphere sources can be distinguished somewhat from those in the lower hemisphere, even in motionless listening conditions, but more so with rotation. The greatest benefit for localization from rotation of the head appears to be gained for sources positioned in the front MVP.},
  Doi                      = {10.1121/1.419642},
  File                     = {Perrett1997.pdf:Perrett1997.pdf:PDF},
  Journaltitle             = {Journal of Acoustical Society of America},
  Keywords                 = {audio; head motion; localisation; elevation; perception;}
}

@Article{Perrett1997a,
  Title                    = {The contribution of head motion cues to localization of a low-pass noise},
  Author                   = {Perrett, Stephen and Noble, William},
  Journal                  = {Perception and Psychophysics},
  Year                     = {1997},
  Number                   = {7},
  Pages                    = {1018-1026},
  Volume                   = {59},

  Abstract                 = {Localization of low-pass sounds was tested in relation to aspects of Wallach's (1939, 1940) hypotheses about the role of head movement in front/back and elevation discrimination. With a 3-sec signal, free movement of the head offered only small advantage over a single rotation through 45 degrees for detecting elevation differences. Very slight rotation, as observed using a 0.5-sec signal, seemed sufficient to prevent front/back confusion. Cluster analysis showed that, in detecting elevation, some listeners benefited from rotation, some benefited from natural movement, and some from both. Evidence was found indicating that a moving auditory system generates information for the whereabouts of sounds, even when the movement does not result in the listener facing the source. Results offer significant if partial support for Wallach's hypotheses.},
  Doi                      = {10.3758/BF03205517},
  File                     = {Perrett1997a.pdf:Perrett1997a.pdf:PDF},
  Journaltitle             = {Perception and Psychophysics},
  Keywords                 = {audio; motion; head motion; localisation; azimuth; perception;}
}

@Article{Perrott1979,
  Title                    = {Dynamic auditory localization: systematic replication of the auditory velocity function},
  Author                   = {Perrott, D.R. and Buck, V. and Waugh, W. and Strybel, T.Z.},
  Journal                  = {The Journal of auditory research},
  Year                     = {1979},
  Pages                    = {277-285},
  Volume                   = {19},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Two experiments explored the capability of normal-hearing adults to judge the apparent velocity of an unseen moving sound source. In exper. I, 9 naive and, 1 experienced S judged the velocity of a moving source emitting a .5-kc/s tone at 50 db SPL. S's head was in the center of a circle of 1.88-m radius swept by a small loudspeaker. In exper. II the sound was a low-pass-filtered (0.1-1 kc/s) noise at 50 db sound spectrum level. In both experiments perceived velocity was directly proportional to the actual velocity of the source. These results support out initial observations (Waugh et al, J. Aud. Res., 1979, 19, 103-1 10) that auditory velocity discrimination can be described as a power function with an exponent of 1.0. In exper. II the Ss also varied the sound source velocity by means of a variable resistor to produce a perceived velocity of 100 degrees/sec. Performance on the adaptive velocity production task was successfully predicted from the data of the absolute velocity judgment task. The Weber fraction was .052 for relatively fast-moving sound sources (100 degrees/sec). The ability to discriminate sound source velocity appears to be a well-defined feature of the dynamic binaural spatial system.},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.12}
}

@Article{Perrott1993,
  Title                    = {Discrimination of moving events which accelerate or decelerate over the listening interval},
  Author                   = {Perrott, David R. AND Costantino, Brian AND Ball, Jennifer},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1993},
  Number                   = {2},
  Pages                    = {1053-1057},
  Volume                   = {93},

  Doi                      = {10.1121/1.405553},
  File                     = {Perrott1993.pdf:Perrott1993.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.10}
}

@Article{Perrott1988a,
  Title                    = {Minimum Audible Movement Angle: marking the end points of the path traveled by a moving sound source},
  Author                   = {Perrott, David R. AND Marlborough, Kent},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1988},
  Number                   = {4},
  Pages                    = {1773-1775},
  Volume                   = {85},

  Doi                      = {10.1121/1.397968},
  File                     = {Perrott1988a.pdf:Perrott1988a.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Perrott1977,
  Title                    = {Minimum auditory movement angle: binaural localisation of moving sound sources},
  Author                   = {Perrott, D. R. AND Musicant, A. D.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1977},
  Number                   = {6},
  Pages                    = {1463-1466},
  Volume                   = {62},

  Doi                      = {10.1121/1.381675},
  File                     = {Perrott1977.pdf:Perrott1977.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Perrott1990,
  Title                    = {Minimum audible angle thresholds for sources varying in both elevation and azimuth},
  Author                   = {Perrott, David R. and Saberi, Kourosh},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1990},
  Number                   = {4},
  Pages                    = {1728-1731},
  Volume                   = {87},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Minimum audible angle (MAA) thresholds were obtained for four subjects in a two‐alternative, forced‐choice, three up/one down, adaptive paradigm as a function of the orientation of the array of sources. With sources distributed on the horizontal plane, the mean MAA threshold was 0.97°. With the sources distributed on the vertical plane (array rotated 90°), the mean MAA threshold was 3.65°. Performance in both conditions was well in line with previous experiments of this type. Tests were also conducted with sources distributed on oblique planes. As the array was rotated from 10°–60° from the horizontal plane, relatively little change in the MAA threshold was observed; the mean MAA thresholds ranged from 0.78° to 1.06°. Only when the array was nearly vertical (80°) was there any appreciable loss in spatial resolution; the MAA threshold had increased to 1.8°. The relevance of these results to research on auditory localization under natural listening conditions, especially in the presence of head movements, is also discussed.},
  Doi                      = {10.1121/1.399421},
  File                     = {Perrott1990.pdf:Perrott1990.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@InBook{Perrott1997,
  Title                    = {Binaural and Spatial Hearing in Real and Virtual Environments},
  Author                   = {Perrott, David R. and Strybel, Thomas Z. and Grantham, D. Westley and Saberi, Kourash and Hafter, Ervin R.},
  Chapter                  = {Motion perception},
  Editor                   = {R. H. Gilkey AND T. R. Andersen},
  Pages                    = {295-313},
  Publisher                = {Lawrence Erlbaum Associates},
  Year                     = {1997},

  __markedentry            = {[mattberjon:]},
  Keywords                 = {motion perception; motion; snapshots; motion without direction; motion discrimination},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.22},
  Url                      = {http://www.questia.com/PM.qst?a=o&d=99131329}
}

@Article{Perrott1988,
  Title                    = {Minimum audible movement angle as a function of signal frequency and the velocity of the source},
  Author                   = {Perrott, David R. and Tucker, Juliana},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1988},
  Number                   = {4},
  Pages                    = {1522-1527},
  Volume                   = {83},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Thresholds for the detection of the direction of travel of a moving sound source were determined in a single‐interval, forced‐choice paradigm. Both the rate at which the sound source is displaced (8°–128°/s) and the frequency of the signal to be localized (500–3700 Hz) affect dynamic spatial resolution. There is an inverse relationship between spatial resolution and the rate of travel, a finding that replicates an earlier observation on performance with sources displaced at high velocities [Perrott and Musicant, J. Acoust. Soc. Am. 62, 1463–1466 (1977)]. However, the magnitude of this effect depends on the actual velocities employed. Relatively small changes in spatial resolution are apparent for velocities below approximately 32°/s. The significant frequency effect can be summarized as follows: Dynamic spatial resolution is better for signals below 1000 Hz than for signals above this value (within the range tested). Particularly poor resolution is evident for signals between 1300–2000 Hz. The present results indicate that signal frequency affects dynamic spatial resolution in a fashion similiar to that which has been observed in the more common ‘‘static’’ localization test situation. There is no indication of an interaction between these two variables. These results provide additional support for the hypothesis that both static and dynamic spatial discrimination functions are dependent upon the same underlying mechanisms. The effects of velocity upon the spatial resolution problem, a unique aspect of the dynamic paradigm, can probably be explained without the necessity of additional hypothetical mechanisms in the auditory system (e.g., a specialized motion detector).},
  Doi                      = {10.1121/1.395908},
  File                     = {Perrott1988.pdf:Perrott1988.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{Popper1997,
  Title                    = {Evolution of the ear and hearing: Issues and questions},
  Author                   = {Popper, A. N. and Fay, R. R.},
  Journal                  = {Brain behavior and evolution},
  Year                     = {1997},
  Pages                    = {213-221},
  Volume                   = {50},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The ear appears to have arisen early in the evolution of the vertebrates. While there are significant interspecific differences in ear structure, it appears that receptor cell structure and the basic function of the ear and auditory system are similar among all vertebrate groups. In this paper we present the evolution of the sensory hair cells of the ear, the origins of the ear itself, and selected functions of the sense of hearing. We argue that there have been strong selective pressures in most vertebrate groups for the sorts of sound encoding and processing abilities that result in the efficient detection, localization, and identification of sound sources in noisy environments. Many of the encoding and processing strategies underlying these functions are shared as well.},
  Keywords                 = {fish; amphibian; mammal; bird ear; otolithic organ; frequency analysis; hearing; sound localization},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.25}
}

@Article{Pritchard2012,
  Title                    = {The effect of luminance on simulated driving speed},
  Author                   = {Pritchard, Sarah J. AND Hammett, Stephen T.},
  Journal                  = {Vision Res.},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {54-60},
  Volume                   = {52},

  Doi                      = {10.1016/j.visres.2011.10.014},
  File                     = {Pritchard2012.pdf:Pritchard2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.19}
}

@Book{Proakis1996,
  Title                    = {Digital Signal Processing: Principles, Algorithms, and Application},
  Author                   = {Proakis, John G. AND Manolakis, Dimitris G.},
  Editor                   = {Prentice Hall},
  Publisher                = {Prentice Hall},
  Year                     = {1996},
  Edition                  = {3rd edition},

  File                     = {Proakis1996.pdf:Proakis1996.pdf:PDF},
  Keywords                 = {digital signal processing; audio; algorithms},
  Owner                    = {mattberjon},
  Timestamp                = {2016.10.22}
}

@Article{Pulkki1997,
  Title                    = {Virtual sound source positionning using Vector Base Amplitude Panning},
  Author                   = {Pulkki, Ville},
  Journal                  = {J. Audio Eng. Soc.},
  Year                     = {1997},
  Number                   = {6},
  Pages                    = {456-466},
  Volume                   = {45},

  Abstract                 = {A vector-based reformulation of amplitude panning is derived, which leads to simple and computationally efficient equations for virtual sound source positioning. Using the method, vector base amplitude panning (VBAP), it is possible to create two- or three-dimensional sound fields where any number of loudspeakers can be placed arbitrarily. The method produces virtual sound sources that are as sharp as is possible with current loudspeaker configuration and amplotude panning methods. A digital tool that implements two- and three-dimensional VBAP with eight inputs and outputs has been realized.},
  File                     = {Pulkki1997.pdf:Pulkki1997.pdf:PDF},
  Journaltitle             = {Journal of Audio Engineering Society},
  Keywords                 = {audio; localisation; azimuth; elevation; signal processing;}
}

@Book{Purkyne1819,
  Title                    = {Beobachtungen und Versuche zur Physiologie der Sinne},
  Author                   = {Purkyně, Jan Evangelista},
  Editor                   = {Zweite unveränderte Auflage},
  Publisher                = {Calve},
  Year                     = {1819},
  Number                   = {1},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Article{Rayleigh1907,
  Title                    = {On our perception of sound direction},
  Author                   = {Lord Rayleigh},
  Journal                  = {Philosophical Magazine},
  Year                     = {1907},
  Number                   = {74},
  Pages                    = {214-232},
  Volume                   = {13},

  Doi                      = {10.1080/14786440709463595},
  File                     = {Rayleigh1907.pdf:Rayleigh1907.pdf:PDF},
  Keywords                 = {audio; localisation; azimuth; elevation; perception;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.24}
}

@Article{Rayleigh1876,
  Title                    = {Our perception of the direction of a source of sound},
  Author                   = {Rayleigh, L.},
  Journal                  = {Nature},
  Year                     = {1876},
  Pages                    = {32-33},
  Volume                   = {14},

  Doi                      = {10.1038/014032a0},
  File                     = {Rayleigh1876.pdf:Rayleigh1876.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.05}
}

@Proceedings{Rayleigh1876a,
  Title                    = {Our perception of the direction of a source of sound - discussion},
  Year                     = {1876},
  Publisher                = {Royal Musical Association},

  Author                   = {Rayleigh, L.},
  File                     = {Rayleigh1876a.pdf:Rayleigh1876a.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.05},
  Url                      = {http://www.jstor.org/stable/765209}
}

@Book{Reek1997,
  Title                    = {Pointers on C},
  Author                   = {Reek, Kenneth},
  Editor                   = {Pearson},
  Publisher                = {Pearson},
  Year                     = {1997},
  Edition                  = {1st edition},

  File                     = {Reek1997.pdf:Reek1997.pdf:PDF},
  Keywords                 = {programming; C; pointers}
}

@Book{Reichardt1961,
  Title                    = {Autocorrelation, a principle for the evaluation of sensory information by the central nervous system},
  Author                   = {Reichardt, Werner},
  Editor                   = {Sensory Communications},
  Publisher                = {M.I.T. Press, Cambridge 39, Mass., New York 16},
  Year                     = {1961},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Article{Reichardt1987,
  Title                    = {Evaluation of optical motion information by movement detectors},
  Author                   = {Reichardt, Werner},
  Journal                  = {Journal of comparative Physiology A: neurotheology, sensory, neural and behavioral physiology},
  Year                     = {1987},
  Number                   = {4},
  Pages                    = {533-547},
  Volume                   = {161},

  Doi                      = {10.1007/BF00603660},
  File                     = {Reichardt1987.pdf:Reichardt1987.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Article{Rosenblum1987,
  Title                    = {Relative effectiveness of three stimulus variables for locating a moving sound source},
  Author                   = {Rosenblum, L.D and Carello, C. and Pastore, R.E},
  Journal                  = {Perception},
  Year                     = {1987},
  Number                   = {2},
  Pages                    = {175-186},
  Volume                   = {16},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {A study is reported in which it is shown that observers can use at least three types of acoustic variables that indicate reliably when a moving sound source is passing: interaural temporal differences, the Doppler effect, and amplitude change. Each of these variables was presented in isolation and each was successful in indicating when a (simulated) moving sound source passed an observer. These three variables were put into competition (with each indicating that closest passage occurred at a different time) in an effort to determine their relative importance. It was found that amplitude change dominated interaural temporal differences which, in turn, dominated the Doppler effect stimulus variable. The results are discussed in terms of two interpretations. First, it is possible that subjects based their judgements on the potential discriminability of each stimulus variable. However, because the stimuli used involved easily discriminable changes, subjects may instead have based their judgements on the independence of a stimulus variable from different environmental situation conditions. The dominance ordering obtained supports the second interpretation.},
  Doi                      = {10.1068/p160175},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.12}
}

@Book{Rossi1988,
  Title                    = {Acoustics and electroacoustics},
  Author                   = {Rossi, Mario},
  Publisher                = {Artech House},
  Year                     = {1988},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.12}
}

@Book{Rousseau1762,
  Title                    = {Du contrat social ou principes du droit politique},
  Author                   = {Rousseau, Jean-Jacques},
  Editor                   = {Union générale d'Edition},
  Publisher                = {Union générale d'Edition},
  Year                     = {1762},

  File                     = {Rousseau1762.pdf:Rousseau1762.pdf:PDF}
}

@Article{Royden2012,
  Title                    = {Use of speed cues in the detection of moving objects by moving observers},
  Author                   = {Royden, Constance S. and Moore, Kathleen D.},
  Journal                  = {Vision Res.},
  Year                     = {2012},
  Pages                    = {17–24},
  Volume                   = {59},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {When an observer moves through an environment containing stationary and moving objects, he or she must be able to determine which objects are moving relative to the others in order to navigate successfully and avoid collisions. We investigated whether image speed can be used as a cue to detect a moving object in the scene. Our results show that image speed can be used to detect moving objects as long as the object is moving sufficiently faster or slower than it would if it were part of the stationary scene.},
  Doi                      = {10.1016/j.visres.2012.02.006},
  File                     = {Royden2012.pdf:Royden2012.pdf:PDF},
  Keywords                 = {Optic flow; Heading; Motion; Moving object detection},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.20}
}

@Book{Rumsey2012,
  Title                    = {Spatial audio},
  Author                   = {Rumsey, Francis},
  Publisher                = {Taylor \& Francis},
  Year                     = {2012},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.04}
}

@InBook{Saberi1997,
  Title                    = {Binaural and spatial hearing in real and virtual environment},
  Author                   = {Saberi, K. AND Hafter, E. R.},
  Chapter                  = {Experiments on auditory motion discrimination},
  Editor                   = {Robert H. Gilkey, Timothy R. Anderson},
  Pages                    = {375-327},
  Publisher                = {Lawrence Erlbaum Associates},
  Year                     = {1997},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.21}
}

@Article{Saberi1990,
  Title                    = {Minimum audible movement angles as a function of sound source trajectory},
  Author                   = {Saberi, Kourosh and Perrott, David R.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1990},
  Number                   = {6},
  Pages                    = {2639-2644},
  Volume                   = {88},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Auditory resolution of moving sound sources was determined in a simulated motion paradigm for sources traveling along horizontal, vertical, or oblique orientations in the subjects’s frontal plane. With motion restricted to the horizontal orientation, minimum audible movement angles (MAMA) ranged from about 1.7° at the lowest velocity (1.8°/s) to roughly 10° at the highest velocity (320°/s). With the sound moving along an oblique orientation (rotated 45° relative to the horizontal) MAMAs generally matched those of the horizontal condition. When motion was restricted to the vertical, MAMAs were substantially larger at all velocities (often exceeding 8°). Subsequent tests indicated that MAMAs are a U‐shaped function of velocity, with optimum resolution obtained at about 2°/s for the horizontal (and oblique) and 7–11°/s for the vertical orientation. Additional tests conducted at a fixed velocity of 1.8°/s along oblique orientations of 80° and 87° indicated that even a small deviation from the vertical had a significant impact on MAMAs. A displacement of 10° from the vertical orientation (a slope of 80°) was sufficient to reduce thresholds (obtained at a velocity of 1.8°/s) from about 11° to approximately 2° (a fivefold increase in acuity). These results are in good agreement with our previous study of minimum audible angles long oblique planes [Perrott and Saberi, J. Acoust. Soc. Am. 87, 1728–1731 (1990)]. In summary, the results suggest that: (1) the ability to detect motion is essentially independent of the path traveled by the source, with one noted exception, sources moving within a few degrees of the vertical plane and (2) auditory resolution of sound sources in motion is a U‐shaped function of velocity with resolution degrading as velocities increase or decrease beyond an optical velocity range.},
  Doi                      = {10.1121/1.399984},
  File                     = {Saberi1990.pdf:Saberi1990.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{Sabin2012,
  Title                    = {Perceptual learning of auditory spectral modulation detection},
  Author                   = {Sabin, Andrew T. and Eddins, D. A. and Wright, B. A.},
  Journal                  = {Experimental Brain Research},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {567-577},
  Volume                   = {218},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Normal sensory perception requires the ability to detect and identify patterns of activity distributed across the receptor surface. In the visual system, the ability to perceive these patterns across the retina improves with training. This learning differs in magnitude for different trained stimuli and does not generalize to untrained spatial frequencies or retinal locations. Here, we asked whether training to detect patterns of activity across the cochlea yields learning with similar characteristics. Differences in learning between the visual and auditory systems would be inconsistent with the suggestion that the ability to detect these patterns is limited by similar constraints in these two systems. We trained three groups of normal-hearing listeners to detect spectral envelopes with a sinusoidal shape (spectral modulation) at 0.5, 1, or 2 cycles/octave and compared the performance of each group to that of a separate group that received no training. On average, as the trained spectral modulation frequency increased, the magnitude of training-induced improvement and the time to reach asymptotic performance decreased, while the tendency for performance to worsen within a training session increased. The training-induced improvements did not generalize to untrained spectral modulation frequencies or untrained carrier spectra. Thus, for both visual-spatial and auditory spectral modulation detection, learning depended upon and was specific to analogous features of the trained stimulus. Such similarities in learning could arise if, as has been suggested, similar constraints limit the ability to detect patterns across the receptor surface between the auditory and visual systems.},
  Doi                      = {10.1007/s00221-012-3049-0},
  Owner                    = {mattberjon},
  Timestamp                = {2012.05.09}
}

@Article{Sabin2005,
  Title                    = {Human sound localization at near-threshold levels},
  Author                   = {Sabin, Andrew T. and Macpherson, Ewan A. and Middlebrooks, John C.},
  Journal                  = {Hearing Research},
  Year                     = {2005},
  Number                   = {1-2},
  Pages                    = {124-134},
  Volume                   = {199},

  Abstract                 = {Physiological studies of spatial hearing show that the spatial receptive fields of cortical neurons typically are narrow at near-threshold levels, broadening at moderate levels. The apparent loss of neuronal spatial selectivity at increasing sound levels conflicts with the accurate performance of human subjects localizing at moderate sound levels. In the present study, human sound localization was evaluated across a wide range of sensation levels, extending down to the detection threshold. Listeners reported whether they heard each target sound and, if the target was audible, turned their heads to face the apparent source direction. Head orientation was tracked electromagnetically. At near-threshold levels, the lateral (left/right) components of responses were highly variable and slightly biased towards the midline, and front vertical components consistently exhibited a strong bias towards the horizontal plane. Stimulus levels were specified relative to the detection threshold for a front-positioned source, so low-level rear targets often were inaudible. As the sound level increased, first lateral and then vertical localization neared asymptotic levels. The improvement of localization over a range of increasing levels, in which neural spatial receptive fields presumably are broadening, indicates that sound localization does not depend on narrow spatial receptive fields of cortical neurons.},
  Doi                      = {10.1016/j.heares.2004.08.001},
  File                     = {Sabin2005.pdf:Sabin2005.pdf:PDF},
  Keywords                 = {localisation; audio; azimuth; perception;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.12.05}
}

@Book{Sale2014,
  Title                    = {Testing Python: applying unit testing, TDD, BDD, and acceptance testing},
  Author                   = {Sale, David},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2014},

  File                     = {Sale2014.pdf:Sale2014.pdf:PDF},
  Keywords                 = {python; development; testing},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.04}
}

@Article{Sandel1955,
  Title                    = {Localization of sound from single and paired sources},
  Author                   = {Sandel, T. T. AND Teas, D. C. AND Feddersen, W. E. AND Jeffress, L. A.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1955},
  Number                   = {5},
  Pages                    = {842-852},
  Volume                   = {27},

  Doi                      = {10.1121/1.1908052},
  File                     = {Sandel1955.pdf:Sandel1955.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.12}
}

@Article{Santen1985,
  Title                    = {Elaborated Reichardt detectors},
  Author                   = {Santen, Jan P. H. van AND Sperling, George},
  Journal                  = {Journal of the Optical Society of America},
  Year                     = {1985},
  Number                   = {2},
  Pages                    = {300-320},
  Volume                   = {2},

  Doi                      = {10.1364/JOSAA.2.000300},
  File                     = {Santen1985.pdf:Santen1985.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01}
}

@Article{Sarmiento2011,
  Title                    = {Audiovisual interactions depend on context of congruency},
  Author                   = {Sarmiento, Beatriz R. and Shore, David I. and Milliken, Bruce and Sanabria, Daniel},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {563-574},
  Volume                   = {74},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {In this study, we addressed how the particular context of stimulus congruency influences audiovisual interactions. We combined an audiovisual congruency task with a proportion-of-congruency manipulation. In Experiment 1, we demonstrated that the perceived duration of a visual stimulus is modulated by the actual duration of a synchronously presented auditory stimulus. In the following experiments, we demonstrated that this crossmodal congruency effect is modulated by the proportion of congruent trials between (Exp. 2) and within (Exp. 4) blocks. In particular, the crossmodal congruency effect was reduced in the context with a high proportion of incongruent trials. This effect was attributed to changes in participants’ control set as a function of the congruency context, with greater control applied in the context where the majority of the trials were incongruent. These data contribute to the ongoing debate concerning crossmodal interactions and attentional processes. In sum, context can provide a powerful cue for selective attention to modulate the interaction between stimuli from different sensory modalities.},
  Doi                      = {10.3758/s13414-011-0249-9},
  File                     = {Sarmiento2011.pdf:Sarmiento2011.pdf:PDF},
  Keywords                 = {Crossmodal interactions, Visual perception, Audition, Congruency context, Multisensory processing},
  Owner                    = {mattberjon},
  Timestamp                = {2012.03.20}
}

@Article{Savitzky1964,
  Title                    = {Smoothing and differenciation of data by simplified least squares procedures},
  Author                   = {Savitzky, Abraham AND Golay, Marcel J. E.},
  Journal                  = {Analytical Chemistry},
  Year                     = {1964},
  Number                   = {8},
  Pages                    = {1627-1639},
  Volume                   = {36},

  File                     = {Savitzky1964.pdf:Savitzky1964.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.07.29}
}

@Article{Schafer2011,
  Title                    = {What is a Savitzky-Golay filter?},
  Author                   = {Ronald W. Schafer},
  Journal                  = {IEEE Signal Processing Magazine},
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {111 - 117},
  Volume                   = {28},

  Doi                      = {10.1109/MSP.2011.941097},
  File                     = {Schafer2011.pdf:Schafer2011.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.08.13}
}

@Article{Schechtman2012,
  Title                    = {Spatial localisation of auditory stimuli in hulan auditory cortex is based on both head-independent and head-centered coordinate systems},
  Author                   = {Schechtman, Eitan AND Shrem Talia and Deouell, Leon Y.},
  Journal                  = {The journal of Neuroscience},
  Year                     = {2012},
  Number                   = {39},
  Pages                    = {13501-13509},
  Volume                   = {32},

  Doi                      = {10.1523/JNEUROSCI.1315-12.2012},
  File                     = {Schechtman2012.pdf:Schechtman2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.15}
}

@Book{Schreiner1993,
  Title                    = {Object-oriented Programming with ANSI-C},
  Author                   = {Schreiner, Axel Tobias},
  Year                     = {1993},
  Edition                  = {First edition},

  File                     = {Schreiner1993.pdf:Schreiner1993.pdf:PDF},
  Keywords                 = {programming; C}
}

@Book{Sedgewick2011,
  Title                    = {Algorithms},
  Author                   = {Sedgewick, Robert AND Wayne, Kevin},
  Editor                   = {Pearson Education},
  Publisher                = {Pearson},
  Year                     = {2011},
  Edition                  = {4th edition},

  File                     = {Sedgewick2011.pdf:Sedgewick2011.pdf:PDF},
  Keywords                 = {algorithms; developtment, data structures},
  Owner                    = {mattberjon},
  Timestamp                = {2016.10.14}
}

@Article{Sekuler1967,
  Title                    = {A model for after-effects of seen movement},
  Author                   = {Sekuler, Robert AND Pantle, Allan},
  Journal                  = {Vision Research},
  Year                     = {1967},
  Number                   = {5-6},
  Pages                    = {427–439},
  Volume                   = {7},

  Doi                      = {10.1016/0042-6989(67)90050-8},
  File                     = {Sekuler1967.pdf:Sekuler1967.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.11}
}

@Article{Sekuler1997,
  Title                    = {Sound alters visual motion perception},
  Author                   = {Sekuler, R and Sekuler, AB and Lau, R},
  Journal                  = {Nature},
  Year                     = {1997},
  Number                   = {6614},
  Pages                    = {308-308},
  Volume                   = {385},

  __markedentry            = {[mattberjon:]},
  Doi                      = {10.1038/385308a0},
  File                     = {Sekuler1997.pdf:Sekuler1997.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@InBook{Sekuler2002,
  Title                    = {Perception},
  Author                   = {Sekuler, R. AND Watamaniuk, S.N.J. AND Blake, R.},
  Chapter                  = {Motion perception},
  Pages                    = {121-176},
  Publisher                = {McGraw-Hill Higher Education},
  Year                     = {2002},

  File                     = {Sekuler2002.pdf:Sekuler2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.13}
}

@InBook{Sekuler1975,
  Title                    = {Handbook of perception},
  Author                   = {Sekuler, Robert William},
  Chapter                  = {11 (Visual motion perception)},
  Editor                   = {Carteretta, E. AND Friedman, M.},
  Pages                    = {-},
  Publisher                = {McGraw-Hill Higher Education},
  Year                     = {1975},
  Volume                   = {5},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Article{Sekuler1963,
  Title                    = {Aftereffect of Seen Motion with a Stabilized Retinal Image},
  Author                   = {Sekuler, Robert William AND Ganz, Leo},
  Journal                  = {Science},
  Year                     = {1963},
  Number                   = {3553},
  Pages                    = {419},
  Volume                   = {139},

  Doi                      = {10.1126/science.139.3553.419},
  File                     = {Sekuler1963.pdf:Sekuler1963.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Article{Shinn-Cunningham2000,
  Title                    = {Tori of confusion: binaural localization cues for sources within reach a listener},
  Author                   = {Shinn-Cunningham, Barbara G. AND Santarelli, Scott AND Kopco, Norbert},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {2000},
  Number                   = {3},
  Pages                    = {1627-1636},
  Volume                   = {107},

  Doi                      = {10.1121/1.428447},
  File                     = {Shinn-Cunningham2000.pdf:Shinn-Cunningham2000.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.12}
}

@Article{Simpson1973,
  Title                    = {Head movements does not facilitate perception of the distance of source of sound.},
  Author                   = {Simpson, W. E. AND Stanton, L. D.},
  Journal                  = {The American Journal of Psychology},
  Year                     = {1973},
  Number                   = {1},
  Pages                    = {151-159},
  Volume                   = {86},

  Doi                      = {10.2307/1421856},
  File                     = {Simpson1973.pdf:Simpson1973.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.25}
}

@Article{Smith2004,
  Title                    = {Human cortical auditory motion areas are not motion selective},
  Author                   = {Smith, Kevin R. and Okada, Kayoko and Saberi, Kourosh and Hickok, Gregory},
  Journal                  = {NeuroReport},
  Year                     = {2004},
  Number                   = {9},
  Pages                    = {1523-1526},
  Volume                   = {15},

  Doi                      = {10.1097/01.wnr.0000130233.43788.4b},
  File                     = {Smith2004.pdf:Smith2004.pdf:PDF},
  Keywords                 = {Auditory motion; fMRI; Imaging; Motion selection; Right parietal; STG},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.30}
}

@Book{Smith2011,
  Title                    = {The Scientist and Engineer's Guide to Digital Signal Processing},
  Author                   = {Smith, Steven W.},
  Editor                   = {Self-Edited},
  Publisher                = {California Technical Publishing},
  Year                     = {2011},

  File                     = {Smith2011.pdf:Smith2011.pdf:PDF},
  Keywords                 = {dsp},
  Url                      = {http://www.dspguide.com/}
}

@Article{Soto-Faraco2003,
  Title                    = {Multisensory contributions to the perception of motion},
  Author                   = {Soto-Faraco, S and Kingstone, A and Spence, C},
  Journal                  = {Perception},
  Year                     = {2003},
  Number                   = {13},
  Pages                    = {1847-1862},
  Volume                   = {41},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The ability to process motion is crucial for coherent perception and action. While the majority of studies have focused on the unimodal factors that influence motion perception (see, for example, the other chapters in this Special Issue), some researchers have also investigated the extent to which information presented in one sensory modality can affect the perception of motion for stimuli presented in another modality. Although early studies often gave rise to mixed results, the development of increasingly sophisticated psychophysical paradigms are now enabling researchers to determine the spatiotemporal constraints on multisensory interactions in the perception of motion. Recent findings indicate that these interactions stand over-and-above the multisensory interactions documented previously for static stimuli, such as the oft-cited 'ventriloquism' effect. Neuroimaging and neuropsychological studies are also beginning to elucidate the network of neural structures responsible for the processing of motion information in the different sensory modalities, an important first step that will ultimately lead to the determination of the neural substrates underlying these multisensory contributions to motion perception.},
  Doi                      = {10.1016/S0028-3932(03)00185-4},
  File                     = {Soto-Faraco2003.pdf:Soto-Faraco2003.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.28}
}

@Article{Sovijaervi1974,
  Title                    = {Auditory cortical neurons in the cat sensitive to the direction of sound source movement},
  Author                   = {Sovijärvi, Anssi R.A. AND Hyvärinen, Juhani},
  Journal                  = {Brain Research},
  Year                     = {1974},
  Number                   = {3},
  Pages                    = {455-471},
  Volume                   = {73},

  Doi                      = {10.1016/0006-8993(74)90669-6},
  File                     = {Sovijaervi1974.pdf:Sovijaervi1974.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.01}
}

@Article{Soyka2012,
  Title                    = {Modeling direction discrimination thresholds for yaw rotations around an earth-vertical axis for arbitrary motion profiles},
  Author                   = {Soyka, Florian and Giordano, Paolo Robuffo and Barnett-Cowan, Michael and Bülthoff, Heinrich H.},
  Journal                  = {Experimental Brain Research},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {89-99},
  Volume                   = {220},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Understanding the dynamics of vestibular perception is important, for example, for improving the realism of motion simulation and virtual reality environments or for diagnosing patients suffering from vestibular problems. Previous research has found a dependence of direction discrimination thresholds for rotational motions on the period length (inverse frequency) of a transient (single cycle) sinusoidal acceleration stimulus. However, self-motion is seldom purely sinusoidal, and up to now, no models have been proposed that take into account non-sinusoidal stimuli for rotational motions. In this work, the influence of both the period length and the specific time course of an inertial stimulus is investigated. Thresholds for three acceleration profile shapes (triangular, sinusoidal, and trapezoidal) were measured for three period lengths (0.3, 1.4, and 6.7 s) in ten participants. A two-alternative forced-choice discrimination task was used where participants had to judge if a yaw rotation around an earth-vertical axis was leftward or rightward. The peak velocity of the stimulus was varied, and the threshold was defined as the stimulus yielding 75 % correct answers. In accordance with previous research, thresholds decreased with shortening period length (from ~2 deg/s for 6.7 s to ~0.8 deg/s for 0.3 s). The peak velocity was the determining factor for discrimination: Different profiles with the same period length have similar velocity thresholds. These measurements were used to fit a novel model based on a description of the firing rate of semi-circular canal neurons. In accordance with previous research, the estimates of the model parameters suggest that velocity storage does not influence perceptual thresholds.},
  Doi                      = {10.1007/s00221-012-3120-x},
  File                     = {Soyka2012.pdf:Soyka2012.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.26}
}

@Article{Spitzer1993,
  Title                    = {Responses of inferior colliculus neurons to tome-varying interaural phase disparity: effects of shifting the locus of virtual motion},
  Author                   = {Spitzer, M. W. AND Semple, M. N.},
  Journal                  = {J. Neurophysiol.},
  Year                     = {1993},
  Number                   = {4},
  Pages                    = {1245-1263},
  Volume                   = {69},

  Abstract                 = {1. Motion of sound sources results in temporal variation of the binaural cues for sound localization. We evaluated the influence of virtual motion on neural tuning to one of these cues, interaural phase disparity (IPD). Responses to dichotic stimuli were recorded from single units in the inferior colliculus of the anesthetized cat and gerbil (Meriones unguiculatus). Static IPDs were generated by presenting dichotic tone pairs with a constant phase offset maintained for the duration of the stimulus. Time-varying IPDs were generated by simultaneously presenting a pure tone to one ear and a phase-modulated tone to the other ear. Sets of time-varying stimuli consisted of modulations through partially overlapping ranges of IPD, corresponding to movement of a sound source through partially overlapping arcs in the horizontal plane.

2. In agreement with previous results, neuronal discharge was typically a peaked function of static IPD resulting from both binaural facilitation at favorable IPDs and binaural suppression at unfavorable IPDs. Responses to time-varying IPD stimuli appeared to be shaped by the same facilitative and inhibitory mechanisms that underlie static IPD tuning. Modulation toward the peak of binaural facilitation increased the probability of discharge, and modulation toward the peak of binaural suppression decreased the probability of discharge. However, it was also clear that IPD tuning could be significantly altered by the temporal context of the stimulus. For the vast majority of units in response to modulation through partially overlapping ranges of IPD the discharge rate profiles were generally nonoverlapping. This shift in IPD tuning induced by the virtual motion reflects the fact that the binaural interaction associated with a given IPD depends on the recent history of stimulation. In addition, modulation in opposite directions through the same range of IPDs often elicited asymmetric responses. These nonlinearities imply that most inferior colliculus neurons do not unambiguously encode a specific IPD, but instead may encode small changes of IPD occurring virtually anywhere within their receptive fields. In a few cases modulation through overlapping ranges of IPD elicited contiguous response profiles, indicating that for these units responses were determined entirely by instantaneous IPD.

3. The nonlinearity of responses to time-varying IPD stimuli could not be attributed to monaural entrainment to the phase-modulated signals, did not depend on the phase modulation waveform, and occurred irrespective of which ear received the phase-modulated signal. Responses were similar in cats and gerbils, suggesting that the underlying mechanisms are common to binaural processing in diverse mammalian species.

4. The consistent shifts in IPD tuning displayed by most neurons in our sample suggests that sensitivity to dynamic spatial cues is a general property of neurons in the inferior colliculus. A measure was developed to quantify the magnitude of the shifts in IPD tuning across a large sample of units. This index of motion sensitivity was distributed continuously across the sample of units and was independent of frequency tuning, preferred static IPD, and sharpness of tuning to static IPD.

5. The initial neural encoding of IPD is believed to occur through a process of coincidence detection or cross-correlation at the superior olivary complex. The present finding that IPD tuning in the inferior colliculus is so dependent on the dynamic context suggests that the output of the original cross-correlator must be modified in the ascending auditory pathway. These data reveal that within the inferior colliculus the neural representation of IPD, and consequently sound location, is influenced by movement of a sound source.},
  File                     = {Spitzer1993.pdf:Spitzer1993.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11},
  Url                      = {http://jn.physiology.org/content/69/4/1245.abstract}
}

@Article{Spitzer1991,
  Title                    = {Interaural phase coding in auditory midbrain: influence of dynamic stimulus features},
  Author                   = {Spitzer, M. W. AND Semple, M. N.},
  Journal                  = {Science},
  Year                     = {1991},
  Number                   = {5032},
  Pages                    = {721-724},
  Volume                   = {254},

  Abstract                 = {A laterally located sound source stimulates the two ears at slightly different times, generating interaural phase disparities (IPDs) that are used for sound localization. Under natural conditions, such interaural cues are likely to be constantly changing, or dynamic. In the inferior colliculus of gerbils and cats, the nonlinearities in the coding of dynamic interaural phase cues are demonstrated. Responses to ecologically realistic phase cues are more reflective of the change of IPD than of the absolute IPDs over which that change occurs. This observation is inconsistent with the established view that directional information is coded in terms of absolute IPD.},
  Doi                      = {10.1126/science.1948053},
  File                     = {Spitzer1991.pdf:Spitzer1991.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.11}
}

@Article{Stern2005,
  Title                    = {Eye and head movements in the acquisition of visual information},
  Author                   = {Stern, JA and Brown, TB and Wang, L and Russo, MB},
  Journal                  = {Psychologia},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {133-145},
  Volume                   = {48},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Much of the literature dealing with the measurement of eye movements is restricted to data collected under conditions where the head is "stabilized". Since in the "real world" such restrictions cannot readily be imposed on operators, we here review the literature dealing with the use of head movements in the acquisition and processing of visually presented information. Task difficulty is associated with an increase in the likelihood of using head movements to acquire visually presented information. Such head movements have been described with visual information subtending as little as 5-10 degrees of arc.

The present study, requiring subjects to identify and process information presented at 10 degree eccentricity, determined that such head movements do occur. Head movements were not measured directly but inferred from differences in eye movement amplitude as measured with clectrooculography, and gaze shift measured with video camera technology. We raise the issue of generalizability of results obtained under conditions where the head is "stabilized" to conditions where it is free to move.},
  Doi                      = {10.2117/psysoc.2005.133},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.22}
}

@Article{Stevens1936,
  Title                    = {The localisation of actual sources of sound},
  Author                   = {Stevens, S. S. AND Newman, E. B.},
  Journal                  = {American Journal of Psychology},
  Year                     = {1936},
  Number                   = {2},
  Pages                    = {297-306},
  Volume                   = {48},

  Doi                      = {10.2307/1415748},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.12}
}

@Article{Stoffregen2009,
  Title                    = {Coupling of head and body movement with motion of the audible environment},
  Author                   = {Stoffregen, Thomas A. and Villard, Sebastien and ChungGon, Kim and Kiyohide, Ito and Bardy, BenoÎt G.},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {2009},
  Number                   = {4},
  Pages                    = {1221-1231},
  Volume                   = {35},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The authors asked whether standing posture could be controlled relative to audible oscillation of the environment. Blindfolded sighted adults were exposed to acoustic flow in a moving room, and were asked to move so as to maintain a constant distance between their head and the room. Acoustic flow had direct (source) and indirect (reflected) components. Participants exhibited strong coupling of postural motion with room motion, even when direct information about room motion was masked and was available only in reflected sound. Patterns of hip–ankle coordination closely resembled patterns observed in previous research involving coupling of sway with a visible moving room. The results demonstrate that blindfolded adults can control the dynamics of stance relative to motion of the audible environment.},
  Doi                      = {10.1037/a0014251},
  File                     = {Stoffregen2009.pdf:Stoffregen2009.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Strybel1992,
  Title                    = {Minimum Audible Movement Angle as a function of the azimuth and elevation of the source},
  Author                   = {Strybel, T. Z. and Manligas, C. L. and Perrott, D. R.},
  Journal                  = {Human Factors},
  Year                     = {1992},
  Pages                    = {267-275},
  Volume                   = {34},

  Abstract                 = {In the future auditory directional cues may enhance situational awareness in cockpits with head-coupled displays. This benefit would depend, however, on the pilot's ability to detect the direction of moving sounds at different locations in space. The present investigation examined this ability. Auditory motion acuity was measured by the minimum audible movement angle (MAMA): the minimum angle of travel required for detection of the direction of sound movement. Five experienced listeners were instructed to indicate the direction of travel of a sound source (broadband noise at 50 dBA) that moved at a velocity of 20 deg/s. Nine azimuth positions were tested at 0 deg elevation. Five elevations were then tested at 0 deg azimuth. Finally two azimuth positions were tested at an elevation of 80 deg. The position of the source did not significantly affect the MAMA for azimuth locations between +40 and -40 deg and elevations below 80 deg. Within this area the MAMA ranged between 1 and 2 deg. Outside this area the MAMA increased to 3 to 10 deg.},
  File                     = {Strybel1992.pdf:Strybel1992.pdf:PDF},
  Keywords                 = {localisation; audio; azimuth; elevation; perception; source motion;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28},
  Url                      = {http://apps.webofknowledge.com/full_record.do?product=WOS&search_mode=GeneralSearch&qid=4&SID=S15k8IbfkIBAkPmBc34&page=2&doc=17}
}

@Article{Strybel1998,
  Title                    = {The effect of timing and spatial separation on the velocity of auditory motion},
  Author                   = {Strybel, Thomas Z. and Span, Sherry A. and Witty, April M.},
  Journal                  = {Perception and Psychophysics},
  Year                     = {1998},
  Number                   = {8},
  Pages                    = {1441-1451},
  Volume                   = {60},

  Abstract                 = {Previously, it was shown that the minimum conditions for the illusion of auditory apparent motion (AAM) depend on stimulus timing but not spatial separation. In the present experiment, the effects of stimulus timing and source separation on the perceived velocity of AAM were examined. Eight listeners estimated the velocity, duration, and distance traveled of AAM, using a no-modulus, magnitude estimation procedure. Four burst durations (25, 50, 100, and 300 msec), 10 stimulus onset asynchronies (SOAs; 30, 40, 50, 60, 70, 80, 90, 100, 110, and 120 msec) and two separations (10 degrees and 40 degrees) were tested. Perceived velocity estimates were related to the total duration (burst duration + SOA) of the stimulus sequence. The effect of separation on velocity was extremely small but statistically significant. These results are similar to those obtained previously on the minimum conditions for AAM. Duration estimates were related only to total duration, but separation estimates were related to both separation and total duration. These results suggest that velocity is possibly a primary dimension of AAM that is independent of source separation.},
  Doi                      = {10.3758/BF03208004},
  File                     = {Strybel1998.pdf:Strybel1998.pdf:PDF},
  Journaltitle             = {Perception and Psychophysics},
  Keywords                 = {apparent motion; motion; audio; perception; azimuth;}
}

@Book{Summerfield2010,
  Title                    = {Programming in Python 3: a complete introduction to the Python language},
  Author                   = {Summerfield, Mark},
  Editor                   = {Addison},
  Publisher                = {Addison - Wesley},
  Year                     = {2010},
  Edition                  = {2nd edition},

  File                     = {Summerfield2010.pdf:Summerfield2010.pdf:PDF},
  Keywords                 = {development; python},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.23}
}

@Article{Taylor2015,
  Title                    = {Does Current Hearing Aid Technology Meet the Needs of Healthy Aging?},
  Author                   = {Taylor, Brian AND Hayes, Donald},
  Journal                  = {The Hearing Review},
  Year                     = {2015},

  File                     = {Taylor2015.pdf:Taylor2015.pdf:PDF},
  Keywords                 = {ewo}
}

@Article{Thompson1981,
  Title                    = {Velocity after-effects: the effects of adaptation to moving stimuli on the perception of subsequently seen moving stimuli},
  Author                   = {Thompson, Peter},
  Journal                  = {Vision Res.},
  Year                     = {1981},
  Number                   = {3},
  Pages                    = {337-345},
  Volume                   = {21},

  Doi                      = {10.1016/0042-6989(81)90161-9},
  File                     = {Thompson1981.pdf:Thompson1981.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.02}
}

@Article{Thompson2006,
  Title                    = {Speed can go up as well as down at low constrast: implications for model of motion perception},
  Author                   = {Thompson, Peter AND Brooks, Kevin AND Hammett, Stephen T.},
  Journal                  = {Vision Res.},
  Year                     = {2006},
  Number                   = {6-7},
  Pages                    = {782-786},
  Volume                   = {46},

  Doi                      = {10.1016/j.visres.2005.08.005},
  File                     = {Thompson2006.pdf:Thompson2006.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.02}
}

@Article{Thompson1892,
  Title                    = {On the function of the two ears in the perception of space},
  Author                   = {Thompson, S. P.},
  Journal                  = {Philosophical Magazine},
  Year                     = {1892},
  Pages                    = {320-334},
  Volume                   = {13},

  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.22}
}

@Article{Thurlow1967a,
  Title                    = {Head Movements During Sound Localization},
  Author                   = {Thurlow, Willard R. and Mangels, John W. and Runge, Philip S.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1967},
  Number                   = {2},
  Pages                    = {489-493},
  Volume                   = {42},

  Abstract                 = {Subjects were photographed with a moving‐picture camera as they attempted to localize each of 10 sound sources in an anechoic room. High‐ and low‐bandpass thermal noise stimuli of 5‐sec duration were used. Changes in angular position of the head (and thus the ears) were measured from the film. Rotation movements of the head about a vertical axis (turning, left or right) were most commonly found—alone, in combination with tipping movement (nose up or down), or in combination with both tipping and pivot movements. (A “pivot” movement involves an increase in vertical height of one ear and a decrease in vertical height of the other.) A number of subjects also showed reversals in movement. The reversals were most prominent in the case of rotation movements. Quantitative summaries of observed movements are given.},
  Doi                      = {10.1121/1.1910605},
  File                     = {Thurlow1967a.pdf:Thurlow1967a.pdf:PDF},
  Keywords                 = {head motion; localisation; audio; azimuth; perception;},
  Publisher                = {ASA}
}

@Article{Thurlow1967,
  Title                    = {Effect of Induced Head Movements on Localization of Direction of Sounds},
  Author                   = {Thurlow, Willard R. and Runge, Philip S.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1967},
  Number                   = {2},
  Pages                    = {480-488},
  Volume                   = {42},

  Abstract                 = {Localization of direction of sound sources was studied as a function of induced head movements. High‐ and low‐frequency noise and pulse stimuli were used. Subjects had had no special training and were blindfolded to remove visual cues. Sources were located to the right and left of the subject, in front and behind, and above and below the horizontal plane through the ears of the subject. Induced head rotation was found to be especially effective in reducing horizontal localization error. Rotation, pivot, and rotate‐pivot movements caused a small but significant reduction in vertical localization error for low‐frequency noise stimuli.},
  Doi                      = {10.1121/1.1910604},
  File                     = {Thurlow1967.pdf:Thurlow1967.pdf:PDF},
  Keywords                 = {head motion; localisation; audio; azimuth; perception;},
  Publisher                = {ASA}
}

@Article{Triggs1982,
  Title                    = {Estimation of automobile speed under day and night conditions},
  Author                   = {Triggs, T.J. AND Berenyi, J.S.},
  Journal                  = {Human Factors},
  Year                     = {1982},
  Number                   = {1},
  Pages                    = {111-114},
  Volume                   = {24},

  Doi                      = {10.1177/001872088202400111},
  File                     = {Triggs1982.pdf:Triggs1982.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.19}
}

@Article{Turano2001,
  Title                    = {Nonlinear contribution of eye velocity to motion perception},
  Author                   = {Turano, Kathleen A. AND Massof, Robert W.},
  Journal                  = {Vision Res.},
  Year                     = {2001},
  Number                   = {3},
  Pages                    = {385-395},
  Volume                   = {41},

  Doi                      = {10.1016/S0042-6989(00)00255-8},
  File                     = {Turano2001.pdf:Turano2001.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.22}
}

@Book{Ullman1989,
  Title                    = {Rigidity and smoothness of motion},
  Author                   = {Ullman, S. AND Yuille, A.},
  Editor                   = {W. R. E. S. Ullman},
  Publisher                = {Nordwood: Ablex Publishing Corporation},
  Year                     = {1989},

  File                     = {Ullman1989.pdf:Ullman1989.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.11}
}

@Article{Valjamae2009,
  Title                    = {Auditorily-induced illusory self-motion: A review},
  Author                   = {Väljamäe, Aleksander},
  Journal                  = {Brain Research Review},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {240-255},
  Volume                   = {61},

  Abstract                 = {The aim of this paper is to provide a first review of studies related to auditorily-induced self-motion (vection). These studies have been scarce and scattered over the years and over several research communities including clinical audiology, multisensory perception of self-motion and its neural correlates, ergonomics, and virtual reality. The reviewed studies provide evidence that auditorily-induced vection has behavioral, physiological and neural correlates. Although the sound contribution to self-motion perception appears to be weaker than the visual modality, specific acoustic cues appear to be instrumental for a number of domains including posture prosthesis, navigation in unusual gravitoinertial environments (in the air, in space, or underwater), non-visual navigation, and multisensory integration during self-motion. A number of open research questions are highlighted opening avenue for more active and systematic studies in this area.},
  Doi                      = {10.1016/j.brainresrev.2009.07.001},
  File                     = {Valjamae2009.pdf:Valjamae2009.pdf:PDF},
  Journaltitle             = {Brain Research Reviews},
  Keywords                 = {audio; motion, azimuth; elevation; perception; neuroscience; localisation; motion; review; source motion;},
  Owner                    = {mattberjon}
}

@Article{VanBarneveld2011a,
  Title                    = {Absence of compensation for vestibular-evoked passive head rotations in human sound localization},
  Author                   = {Van Barneveld, Denise C. P. B. M. and Binkhorst, Floor and Van Opstal, A. John},
  Journal                  = {European Journal of Neuroscience},
  Year                     = {2011},
  Number                   = {7},
  Pages                    = {1149-1160},
  Volume                   = {34},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {A world‐fixed sound presented to a moving head produces changing sound‐localization cues, from which the audiomotor system could infer sound movement relative to the head. When appropriately combined with self‐motion signals, sound localization remains spatially accurate. Indeed, free‐field orienting responses fully incorporate intervening eye‐head movements under open‐loop localization conditions. Here we investigate the default strategy of the audiomotor system when localizing sounds in the absence of efferent and proprioceptive head‐movement signals. Head‐ and body‐restrained listeners made saccades in total darkness toward brief (3, 10 or 100 ms) broadband noise bursts, while being rotated sinusoidally (f = 1/9 Hz, Vpeak=112 deg/s) around the vertical body axis. As the loudspeakers were attached to the chair, the 100 ms sounds might be perceived as rotating along with the chair, and localized in head‐centred coordinates. During 3 and 10 ms stimuli, however, the amount of chair rotation remained well below the minimum audible movement angle. These brief sounds would therefore be perceived as stationary in space and, as in open‐loop gaze orienting, expected to be localized in world‐centred coordinates. Analysis of the saccades shows, however, that all stimuli were accurately localized on the basis of imposed acoustic cues, but remained in head‐centred coordinates. These results suggest that, in the absence of motor planning, the audio motor system keeps sounds in head‐centred coordinates when unsure about sound motion relative to the head. To that end, it ignores vestibular canal signals of passive‐induced head rotation, but incorporates intervening eye displacements from vestibular nystagmus during the saccade‐reaction time.},
  Doi                      = {10.1111/j.1460-9568.2011.07844.x},
  File                     = {VanBarneveld2011a.pdf:VanBarneveld2011a.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.28}
}

@Article{VanBarneveld2011,
  Title                    = {The effect of head roll on perceived auditory zenith},
  Author                   = {Van Barneveld, Denise C. P. B. M. and Van Grootel, Tom J. and Alberts, Bart and Van Opstal, A. John},
  Journal                  = {Experimental Brain Research},
  Year                     = {2011},
  Number                   = {2-3},
  Pages                    = {235-243},
  Volume                   = {213},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {We studied the influence of static head roll on the perceived auditory zenith in head-centred and world-centred coordinates. Subjects sat either upright, or with their head left/right rolled sideways by about 35° relative to gravity, whilst judging whether a broadband sound was heard left or right from the head-centred or world-centred zenith. When upright, these reference frames coincide. Results show that subjects judged the zenith accurately within different planes, although response variability increased for the midsagittal plane. With the head rolled, head-centred auditory zenith shifted by the same amount and was located as accurately as for upright, indicating unaltered localisation cues by head-on-body roll. Interestingly, when judging world-centred zenith subjects made large systematic errors (10–15°) in the direction of head roll, and response variability increased, which resembles the visual Aubert effect. These results demonstrate a significant influence of the vestibular-collic system on auditory spatial awareness, which sheds new light on the mechanisms underlying multisensory integration and spatial updating in sound localisation behaviour.},
  Doi                      = {10.1007/s00221-011-2741-9},
  File                     = {VanBarneveld2011.pdf:VanBarneveld2011.pdf:PDF},
  Keywords                 = {Spatial updating; Audio-vestibular integration; Aubert effect; Sound localisation; Vestibular-collic reflex; Reference frames},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{VanMaanen2012,
  Title                    = {Similarity and number of alternatives in the random-dot motion paradigm},
  Author                   = {Van Maanen, Leendert and Grasman, Raoul P. P. P. and Forstmann, Birte U. and Keuken, Max C. and Brown, Scott D. and Wagenmakers, Eric-Jan},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {739-753},
  Volume                   = {74},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The popular random-dot motion (RDM) task has recently been applied to multiple-choice perceptual decision-making. However, changes in the number of alternatives on an RDM display lead to changes in the similarity between the alternatives, complicating the study of multiple-choice effects. To disentangle the effects of similarity and number of alternatives, we analyzed behavior in the RDM task using an optimal-observer model. The model applies Bayesian principles to give an account of how changes in the stimulus influence the decision-making process. A possible neural implementation of the optimal-observer model is discussed, and we provide behavioral data that support the model. We verify the predictions from the optimal-observer model by fitting a descriptive model of choice behavior (the linear ballistic accumulator model) to the behavioral data. The results show that (a) there is a natural interaction in the RDM task between similarity and the number of alternatives; (b) the number of alternatives influences “response caution”, whereas the similarity between the alternatives influences “drift rate”; and (c) decisions in the RDM task are near optimal when participants are presented with multiple alternatives.},
  Doi                      = {10.3758/s13414-011-0267-7},
  File                     = {VanMaanen2012.pdf:VanMaanen2012.pdf:PDF},
  Keywords                 = {Bayesian modeling – Decision making – Response time models},
  Owner                    = {mattberjon},
  Timestamp                = {2012.04.16}
}

@Article{Vanhecke2015,
  Title                    = {Physiology and Acoustics of Inspiratory Phonation},
  Author                   = {Vanhecke, Françoise AND Lebacq, Jean AND Moerman, Mieke AND Manfredi, Claudia AND Raes, Godfried-Willem AND DeJonckere, Philippe H.},
  Journal                  = {Journal of Voice},
  Year                     = {2015},

  __markedentry            = {[mattberjon:1]},
  Doi                      = {10.1016/j.jvoice.2015.11.001},
  File                     = {Vanhecke2015.pdf:Vanhecke2015.pdf:PDF}
}

@Article{Vaziri-Pashkam2008,
  Title                    = {Apparent speed increases at low luminance},
  Author                   = {Vaziri-Pashkam, Maryam AND Cavanagh, Patrick},
  Journal                  = {Journal of Vision},
  Year                     = {2008},
  Number                   = {16},
  Pages                    = {1-12},
  Volume                   = {8},

  Doi                      = {10.1167/8.16.9},
  File                     = {Vaziri-Pashkam2008.pdf:Vaziri-Pashkam2008.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.05}
}

@Conference{Viemeister1990,
  Title                    = {An Overview of Psychoacoustics and Auditory Perception},
  Author                   = {Viemeister, Neil F.},
  Booktitle                = {Audio Engineering Society Conference: 8th International Conference: The Sound of Audio},
  Year                     = {1990},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {This paper surveys experimental and theoretical work on the psychology of hearing, particularly those aspects that are, or may be relevant to audio reproduction. The general areas considered include: (1) auditory sensitivity and dynamic range; (2) temporal aspects of hearing; (3) frequency and pitch perception; (4) intensity and loudness perception. Current work and directions will be discussed and particular attention will be devoted to the neural and mechanical correlates of these psychological phenomenon.},
  File                     = {Viemeister1990.pdf:Viemeister1990.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.27}
}

@Article{Wagner1997,
  Title                    = {Principles of acoustic motion detection in animals and man},
  Author                   = {Wagner, Hermann AND Kautz, Dirk AND Poganiatz, Iris},
  Journal                  = {Trends in Neurosciences},
  Year                     = {1997},
  Number                   = {12},
  Pages                    = {583–588},
  Volume                   = {20},

  Doi                      = {10.1016/S0166-2236(97)01110-7},
  File                     = {Wagner1997.pdf:Wagner1997.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.13}
}

@Article{Wallach1940,
  Title                    = {The role of head movements and vestibular and visual cues in sound localization},
  Author                   = {Wallach, Hans},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1940},
  Number                   = {4},
  Pages                    = {339-368},
  Volume                   = {27},

  Abstract                 = {Experiments of synthetic production of sound directions are reported which show that either vestibular cues or visual cues can replace head movements as such. In one group of experiments the blindfolded subject localized the sound while he was passively turned on a revolving chair, and in the other group the subject observed the direction of sound while seated inside a revolving screen. The results indicate that (1) fairly accurate representation of the actual displacement of the head is furnished by vestibular stimulation and that (2) visual stimulation, equivalent to that which actual displacement of the head would give, suffices to determine the direction of sound.},
  Doi                      = {10.1037/h0054629},
  File                     = {Wallach1940.pdf:Wallach1940.pdf:PDF},
  Journaltitle             = {Journal of Experimental Psychology},
  Keywords                 = {head motion; perception; azimuth; localisation;}
}

@Article{Wallach1939,
  Title                    = {On sound localization},
  Author                   = {Wallach, Hans},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1939},
  Number                   = {4},
  Pages                    = {270-274},
  Volume                   = {10},

  Doi                      = {10.1121/1.1915985},
  File                     = {Wallach1939.pdf:Wallach1939.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.02}
}

@Article{Wang1994,
  Title                    = {Thresholds for detection of a change in displacement, velocity, and acceleration of a synthetized sound-emitting source},
  Author                   = {Wang, Wen and Lutfi, Robert A.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1994},
  Number                   = {5},
  Pages                    = {2897-2897},
  Volume                   = {95},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {An experiment was conducted to determine if listeners, when judging the velocity and acceleration of a sound‐emitting source, merely infer these quantities from overall source displacement. The acoustic waveform of a high‐velocity source was reconstructed over headphones using principles of sound radiation and propagation from the moving source, an interaural time difference method, and a diffraction model of a spherical head. An adaptive 2IFC procedure was used to measure thresholds for detection of a change in the displacement, velocity, and acceleration of the source passing directly in front of the listener in a linear trajectory from left to right. The source traveled at 50 m/s for 4 s, at a distance of 5 m from the center of the head, point of closest approach. Thresholds for a rightward displacement showed little variability across listeners, averaging about 7 m. Velocity and acceleration thresholds varied from one listener to the next, but were in some cases less than the minimum value that could be inferred given the 7‐m threshold for displacement. The results are discussed in terms of cues for discrimination related to changes in intensity, interaural delay, and Doppler effect.},
  Doi                      = {10.1121/1.409304},
  File                     = {Wang1994.pdf:Wang1994.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.22}
}

@Article{Watamaniuk1993,
  Title                    = {Dependence of speed and direction perception on cinematogram dot density},
  Author                   = {Watamaniuk, Scott N. J. AND Grzywacz, Norberto M. AND Yuille Alan L.},
  Journal                  = {Vision Res.},
  Year                     = {1993},
  Number                   = {5-6},
  Pages                    = {849-859},
  Volume                   = {33},

  Doi                      = {10.1016/0042-6989(93)90204-A},
  File                     = {Watamaniuk1993.pdf:Watamaniuk1993.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.10.15}
}

@Article{Watson1985,
  Title                    = {Model of human visual-motion sensing},
  Author                   = {Watson, Andrew B. AND Ahumada, Albert J.},
  Journal                  = {Journal of the Optical Society of America},
  Year                     = {1985},
  Number                   = {2},
  Pages                    = {322-342},
  Volume                   = {2},

  Doi                      = {10.1364/JOSAA.2.000322},
  File                     = {Watson1985.pdf:Watson1985.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.08.18}
}

@Article{Watson1990,
  Title                    = {The method of constant stimuli is inefficient},
  Author                   = {Watson, Andrew B. and Fitzhugh, Andrew},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {87-91},
  Volume                   = {47},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {Simpson (1988) has argued that the method of constant stimuli is as efficient as adaptive methods of threshold estimation, and has supported this claim with simulations. We show that Simpson’s simulations are not a reasonable model of the experimental process, and that more plausible simulations confirm that adaptive methods are much more efficient than the method of constant stimuli.},
  Doi                      = {10.3758/BF03208169},
  File                     = {Watson1990.pdf:Watson1990.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.07.12}
}

@Article{Wenzel1993,
  Title                    = {Localization using non-individualized Head-Related Transfer Functions},
  Author                   = {Wenzel, E. M. AND Arruda, M. AND Kistler, D. J. AND Wightman, F. L.},
  Journal                  = {J. Acoust. Soc. Am.},
  Year                     = {1993},
  Number                   = {1},
  Pages                    = {111-123},
  Volume                   = {94},

  Abstract                 = {A recent development in human-computer interfaces is the virtual acoustic display, a device that synthesizes three-dimensional, spatial auditory information over headphones using digital filters constructed from head-related transfer functions (HRTFs). The utility of such a display depends on the accuracy with which listeners can localize virtual sound sources. A previous study [F. L. Wightman and D. J. Kistler, J. Acoust. Soc. Am. 85, 868-878 (1989)] observed accurate localization by listeners for free-field sources and for virtual sources generated from the subjects' own HRTFs. In practice, measurement of the HRTFs of each potential user of a spatial auditory display may not be feasible. Thus, a critical research question is whether listeners can obtain adequate localization cues from stimuli based on nonindividualized transforms. Here, inexperienced listeners judged the apparent direction (azimuth and elevation) of wideband noisebursts presented in the free-field or over headphones; headphone stimuli were synthesized using HRTFs from a representative subject of Wightman and Kistler. When confusions were resolved, localization of virtual sources was quite accurate and comparable to the free-field sources for 12 of the 16 subjects. Of the remaining subjects, 2 showed poor elevation accuracy in both stimulus conditions, and 2 showed degraded elevation accuracy with virtual sources. Many of the listeners also showed high rates of front-back and up-down confusions that increased significantly for virtual sources compared to the free-field stimuli. These data suggest that while the interaural cues to horizontal location are robust, the spectral cues considered important for resolving location along a particular cone-of-confusion are distorted by a synthesis process that uses nonindividualized HRTFs.},
  Doi                      = {10.1121/1.407089},
  File                     = {Wenzel1993.pdf:Wenzel1993.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.08.12}
}

@Article{Wertheim1994,
  Title                    = {Motion perception during selfmotion: The direct versus inferentiql controversy revisited},
  Author                   = {Wertheim, Alexander H.},
  Journal                  = {Behavioral and Brain Sciences},
  Year                     = {1994},
  Number                   = {2},
  Pages                    = {293-311},
  Volume                   = {17},

  Doi                      = {10.1017/S0140525X00034646},
  File                     = {Wertheim1994.pdf:Wertheim1994.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.11.22}
}

@Article{Wertheim1987,
  Title                    = {Retinal and extraretinal information in movement perception: how to invert Filehne illusion},
  Author                   = {Wertheim, Alexander H.},
  Journal                  = {Perception},
  Year                     = {1987},
  Number                   = {3},
  Pages                    = {299-308},
  Volume                   = {16},

  Abstract                 = {During a pursuit eye movement made in darkness across a small stationary stimulus, the stimulus is perceived as moving in the opposite direction to the eyes. This so-called Filehne illusion is usually explained by assuming that during pursuit eye movements the extraretinal signal (which informs the visual system about eye velocity so that retinal image motion can be interpreted) falls short. A study is reported in which the concept of an extraretinal signal is replaced by the concept of a reference signal, which serves to inform the visual system about the velocity of the retinae in space. Reference signals are evoked in response to eye movements, but also in response to any stimulation that may yield a sensation of self-motion, because during self-motion the retinae also move in space. Optokinetic stimulation should therefore affect reference signal size. To test this prediction the Filehne illusion was investigated with stimuli of different optokinetic potentials. As predicted, with briefly presented stimuli (no optokinetic potential) the usual illusion always occurred. With longer stimulus presentation times the magnitude of the illusion was reduced when the spatial frequency of the stimulus was reduced (increased optokinetic potential). At very low spatial frequencies (strongest optokinetic potential) the illusion was inverted. The significance of the conclusion, that reference signal size increases with increasing optokinetic stimulus potential, is discussed. It appears to explain many visual illusions, such as the movement aftereffect and center-surround induced motion, and it may bridge the gap between direct Gibsonian and indirect inferential theories of motion perception.},
  Doi                      = {10.1068/p160299},
  File                     = {Wertheim1987.pdf:Wertheim1987.pdf:PDF},
  Keywords                 = {vision; source motion; perception; motion; azimuth; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.21}
}

@Article{Wichmann2001,
  Title                    = {The psychometric function: I. Fitting, sampling, and goodness of fit},
  Author                   = {Wichmann, Felix A. and Hill, N. Jeremy},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2001},
  Number                   = {8},
  Pages                    = {1293-1313},
  Volume                   = {63},

  __markedentry            = {[mattberjon:]},
  Abstract                 = {The psychometric function relates an observer’s performance to an independent variable, usually some physical quantity of a stimulus in a psychophysical task. This paper, together with its companion paper (Wichmann & Hill, 2001), describes an integrated approach to (1) fitting psychometric functions, (2) assessing the goodness of fit, and (3) providing confidence intervals for the function’s parameters and other estimates derived from them, for the purposes of hypothesis testing. The present paper deals with the first two topics, describing a constrained maximum-likelihood method of parameter estimation and developing several goodness-of-fit tests. Using Monte Carlo simulations, we deal with two specific difficulties that arise when fitting functions to psychophysical data. First, we note that human observers are prone to stimulus-independent errors (orlapses). We show that failure to account for this can lead to serious biases in estimates of the psychometric function’s parameters and illustrate how the problem may be overcome. Second, we note that psychophysical data sets are usually rather small by the standards required by most of the commonly applied statistical tests. We demonstrate the potential errors of applying traditionalX 2 methods to psychophysical data and advocate use of Monte Carlo resampling techniques that do not rely on asymptotic theory. We have made available the software to implement our methods.},
  Doi                      = {10.3758/BF03194544},
  File                     = {Wichmann2001.pdf:Wichmann2001.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.29}
}

@Article{Wichmann2001a,
  Title                    = {The Psychometric Function: II. Bootstrap-Based Confidence Intervals and Sampling},
  Author                   = {Wichmann, F. A. and Hill, N. J.},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2001},
  Number                   = {8},
  Pages                    = {1314-1329},
  Volume                   = {63},

  __markedentry            = {[mattberjon:]},
  Doi                      = {10.3758/BF03194545},
  File                     = {Wichmann2001a.pdf:Wichmann2001a.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.07.12}
}

@Article{Wightman1999,
  Title                    = {Resolution of front–back ambiguity in spatial hearing by listener and source movement},
  Author                   = {Wightman, Frederic L. AND Kistler, Doris J.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1999},
  Number                   = {5},
  Pages                    = {2841-2853},
  Volume                   = {105},

  Doi                      = {10.1121/1.426899},
  File                     = {Wightman1999.pdf:Wightman1999.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.01.15}
}

@Article{Wightman1992,
  Title                    = {The dominant role of low-frequency intaural time differences in sound localization},
  Author                   = {Wightman, Frederic L. AND Kistler, Doris J.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1992},
  Number                   = {3},
  Pages                    = {1648-1661},
  Volume                   = {91},

  Doi                      = {10.1121/1.402445},
  File                     = {Wightman1992.pdf:Wightman1992.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.12.12}
}

@Article{Wightman1989,
  Title                    = {Headphone simulation of free‐field listening. I: Stimulus synthesis},
  Author                   = {Wightman, Frederic L. AND Kistler, Doris J.},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {1989},
  Number                   = {2},
  Pages                    = {858-867},
  Volume                   = {85},

  Doi                      = {10.1121/1.397557},
  File                     = {Wightman1989.pdf:Wightman1989.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.04.19}
}

@Article{Wilson2016,
  Title                    = {Good Enough Practices in Scientific Computing},
  Author                   = {Wilson, Greg AND Bryan, Jennifer AND Cranston, Karen AND Kitzes, Justin AND Nederbragt, Lex AND Teal, Tracy K.},
  Journal                  = {PLOS},
  Year                     = {2016},

  Month                    = {October},
  Pages                    = {1-20},

  File                     = {Wilson2016.pdf:Wilson2016.pdf:PDF},
  Keywords                 = {development; good practices},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.02}
}

@Book{Wohlgemuth1911,
  Title                    = {On the aftereffect of seen movement},
  Author                   = {Wohlgemuth, Adolf b.},
  Editor                   = {British journal of psychology: Monograph supplements},
  Publisher                = {Cambridge University Press},
  Year                     = {1911},
  Volume                   = {1},

  File                     = {Wohlgemuth1911.pdf:Wohlgemuth1911.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.07}
}

@Book{Woodworth1954,
  Title                    = {Experimental psychology},
  Author                   = {Woodworth, Robert S. AND Schlosberg, Harold},
  Editor                   = {New York},
  Publisher                = {Holt},
  Year                     = {1954},
  Edition                  = {3rd},

  Owner                    = {mattberjon},
  Pages                    = {948},
  Timestamp                = {2012.12.13}
}

@Article{Wuerger2010,
  Title                    = {Motion extrapolation of auditory-visual targets},
  Author                   = {Wuerger, Sophie and Meyer, Georg and Hofbauer, Markus and Zetzsche, Christoph and Schill, Kerstin},
  Journal                  = {Information Fusion},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {45-50},
  Volume                   = {11},

  Abstract                 = {Many tasks involve the precise estimation of speed and position of moving objects, for instance to catch or avoid objects that cohabit in our environment. Many of these objects are characterised by signal representations in more than one modality, such as hearing and vision. The aim of this study was to investigate the extent to which the simultaneous presentation of auditory and visual signals enhances the estimation of motion speed and instantaneous position. Observers are asked to estimate the instant when a moving object arrives at a target spatial position by pressing a response button. This task requires observers to estimate the speed of the moving object and to calibrate the timing of their manual response such that it coincides with the true arrival time of the moving object. When both visual and auditory motion signals are available, the variability in estimating the arrival time of the moving object is significantly reduced compared to the variability in the unimodal conditions. This reduction in variability is consistent with optimal integration of the auditory and visual speed signals. The average bias in the estimated arrival times depends on the motion speed: for medium speeds (17 deg/s) observers' subjective arrival times are earlier than the true arrival times; for high speeds (47 deg/s) observers exhibit a (much smaller) bias in the other direction. This speed-dependency suggests that the bias is due to an error in estimating the motion speeds rather than an error in calibrating the timing of the motor response. Finally, in this temporal localization task, the bias and variability show similar patterns for motion defined by vision, audition or both.},
  Doi                      = {10.1016/j.inffus.2009.04.005},
  File                     = {Wuerger2010.pdf:Wuerger2010.pdf:PDF},
  Keywords                 = {audiovisual; apparent motion; source motion; azimuth; perception; localisation; motion; eyes movement;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.20}
}

@Book{Yantis2002,
  Title                    = {Stevens' handbook of experimental psychology},
  Author                   = {Yantis, S. AND Pashler, H.E. AND Medin, D.},
  Publisher                = {Wiley},
  Year                     = {2002},

  File                     = {Yantis2002.pdf:Yantis2002.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2012.09.13}
}

@Article{Yin1983,
  Title                    = {Binaural interaction in low-frequency neurons in inferior colliculus of the cat. II. Effects of changing rate and direction of interaural phase},
  Author                   = {Yin, T. C. AND Kuwada, S.},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {1983},
  Number                   = {4},
  Pages                    = {1000-1019},
  Volume                   = {50},

  File                     = {Yin1983.pdf:Yin1983.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.03.11}
}

@Article{Yost2015,
  Title                    = {Psychoacoustics: A brief historical overview},
  Author                   = {Yost, William A.},
  Journal                  = {Acoustics Today},
  Year                     = {2015},
  Number                   = {3},
  Pages                    = {46-53},
  Volume                   = {11},

  File                     = {Yost2015.pdf:Yost2015.pdf:PDF},
  Owner                    = {mattberjon},
  Timestamp                = {2016.11.13}
}

@Article{Young1931,
  Title                    = {The role of head movements in auditory localisation},
  Author                   = {Young, P.T.},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1931},
  Number                   = {2},
  Pages                    = {95-124},
  Volume                   = {14},

  Abstract                 = {AB : A series of studies intended as a check on the previous work by the author on the acoustical transposition of the ears. Four questions are attacked: (1) the lateral character of the phantom tone; (2) binaural direction: (3) monaural localization, and (4) the binaural estimation of distance. (1) Two hard rubber ear trumpets were adjusted in a frame and connected to ear pieces by means of rubber tubing. Clicks and a 400-cycle tone were used as stimuli. The axis of the trumpets could be placed in any position in space with respect to the S. No relation was found between trumpet axis and aural axis. 2. The phantom was localized upon an arc in the rear of the head outside the field of vision; the angle with respect to the vertical varies with the individual and is independent of the binaural stimulus pattern. There are well defined individual differences in the restriction of the phantom's course and in its displacement to R or L. (3) When head movements are rendered ineffective to change the monaural stimulus S can discriminate between R and L, but objectively accurate estimations of direction apart from mere R and L are impossible. (4) Distance estimation varies with individuals and with practice and depends somewhat on the energy relations of the binaural stimulus. Failure to control head movements, even in small degree, has been an instrumental defect of many previous studies. When head movements are effective in changing the binaural stimulus pattern the auditory field is unrestricted and coextensive with visualtactual space, and objectively reliable localizations are possible in three dimensions. When head movements are ineffective the auditory field is restricted to a single arc outside the visual field and objective accuracy is limited to two dimensions.},
  Doi                      = {10.1037/h0075721},
  File                     = {Young1931.pdf:Young1931.pdf:PDF},
  Keywords                 = {localisation; motion; audio; perception; head motion; azimuth; elevation;},
  Owner                    = {mattberjon},
  Timestamp                = {2012.06.25}
}

@Article{Zahorik2002,
  Title                    = {Assessing auditory distance perception using virtual acoustics},
  Author                   = {Zahorik, Pavel},
  Journal                  = {Journal of the Acoustical Society of America},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {1832-1846},
  Volume                   = {111},

  Doi                      = {10.1121/1.1458027},
  File                     = {Zahorik2002.pdf:Zahorik2002.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.04}
}

@Article{Zahorik2005,
  Title                    = {Auditory Distance Perception in Humans: A Summary of Past and Present Research},
  Author                   = {Zahorik, Pavel AND Brungart, Douglas S. AND Bronkhorst, Adelbert W.},
  Journal                  = {Acta Acustica united with Acustica},
  Year                     = {2005},
  Number                   = {12},
  Pages                    = {409-420},
  Volume                   = {91},

  File                     = {Zahorik2005.pdf:Zahorik2005.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.02.22}
}

@InProceedings{Zakis2001,
  Title                    = {A High Performance Digital Hearing Aid for Advanced Sound Processing Research},
  Author                   = {Zakis,Justin A. AND McDermott, Hugh J. AND Fisher, Michael},
  Booktitle                = {IEEE Engineering in Medicine and Biology Society Conference},
  Year                     = {2001},
  Month                    = {Fabruary},
  Organization             = {Monash University},

  File                     = {Zakis2001.pdf:Zakis2001.pdf:PDF},
  Keywords                 = {ewo; hardware},
  Url                      = {http://eng.monash.edu.au/non-cms/ecse/ieee/ieeebio2001/justinzakis.pdf}
}

@Manual{Zmoelnig2007,
  Title                    = {How to write an External for PureData},
  Author                   = {Zmölnig, Johannes M.},
  Organization             = {Institut for Electronic Music and Acoustics},
  Year                     = {2007},

  Abstract                 = {pd is a graphical realtime-computermusicsystem that follows the tradition of IRCAMs ISPW-max.
Although plenty of functions are built into pd, it is sometimes a pain or simply impossible to create a patch with a certain functionality out of the given primitives and combinations of these.
Therefore, pd can be extended with selfmade primitives (``objects'') that are written in complex programming-languages, like C/C++.
This document aims to explain, how to write such primitives in C, the popular language that was used to realize pd.},
  File                     = {Zmoelnig2007.pdf:Zmoelnig2007.pdf:PDF},
  Keywords                 = {pure data; c programming; c; externals},
  Owner                    = {mattberjon},
  Timestamp                = {2012.02.12},
  Url                      = {http://iem.at/pd/externals-HOWTO/}
}

@Proceedings{Spiegle1993,
  Title                    = {Auditory distance perception by translating observers.},
  Year                     = {1993},
  Editor                   = {Spiegle, J.M. AND Loomis, J.M.},

  __markedentry            = {[mattberjon:]},
  Owner                    = {mattberjon},
  Timestamp                = {2011.11.12}
}

@Manual{Motu2013,
  Title                    = {Motu PCI-424},
  Note                     = {Manual},
  Organization             = {Motu},
  Year                     = {2013},

  File                     = {Motu2013.pdf:Motu2013.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08}
}

@Manual{Vivitek2013,
  Title                    = {Qumi Q2},
  Note                     = {Data sheet},
  Organization             = {Vivitek},
  Year                     = {2013},

  File                     = {Vivitek2013.pdf:Vivitek2013.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08}
}

@Manual{Cambridge2013,
  Title                    = {Minx Min 10 loudspeaker},
  Note                     = {Technical specifications},
  Organization             = {Cambridge Audio},
  Year                     = {2011},

  File                     = {Cambridge2013.pdf:Cambridge2013.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08},
  Url                      = {http://www.cambridgeaudio.com}
}

@Manual{Microsoft2011,
  Title                    = {LifeCam HD-3000},
  Note                     = {Technical data sheet},
  Organization             = {Microsoft},
  Year                     = {2011},

  File                     = {Microsoft2011.pdf:Microsoft2011.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08}
}

@Manual{Ascension2004,
  Title                    = {The Flock of Birds},
  Note                     = {Installation and operating guide},
  Organization             = {Ascension},
  Year                     = {2004},

  File                     = {Ascension2004.pdf:Ascension2004.pdf:PDF},
  Owner                    = {mattberjon},
  Quality                  = {1},
  Timestamp                = {2013.05.08},
  Url                      = {ftp://ftp.ascension-tech.com/MANUALS/Flock_of_Birds_Manual-RevC.pdf}
}

@comment{jabref-meta: pdfDirectory:/home/mattberjon/phd/papers;}

@comment{jabref-meta: fileDirectory:/home/mattberjon/phd/papers;}

